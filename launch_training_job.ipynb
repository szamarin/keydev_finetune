{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq sagemaker\n",
    "%pip install -Uq datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "boto3_session=boto3.session.Session()\n",
    "# boto3_session=boto3.session.Session()\n",
    "\n",
    "smr = boto3_session.client(\"sagemaker-runtime\") # sagemaker runtime client for invoking the endpoint\n",
    "sm = boto3_session.client(\"sagemaker\") # sagemaker client for creating the endpoint\n",
    "s3_rsr = boto3_session.resource(\"s3\")\n",
    "# role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "role = \"arn:aws:iam::152804913371:role/service-role/AmazonSageMaker-ExecutionRole-20200526T152070\"\n",
    "\n",
    "sess = sagemaker.session.Session(boto3_session, sagemaker_client=sm, sagemaker_runtime_client=smr)  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(input_path, output_path):\n",
    "    with open(input_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    with open(output_path, \"w\") as f:\n",
    "        for record in data:\n",
    "            new_record = {\"prompt_id\": record[\"prompt_id\"]}\n",
    "            conversation = []\n",
    "            for turn in record[\"messages\"]:\n",
    "                conversation.append({\"role\": turn[\"role\"], \"value\": turn[\"content\"]})\n",
    "        \n",
    "            new_record[\"conversations\"] = conversation\n",
    "            f.write(json.dumps(new_record))\n",
    "            \n",
    "process_file(\"hf3k_train.json\", \"hf3k_train_processed.jsonl\")\n",
    "process_file(\"hf3k_test.json\", \"hf3k_test_processed.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prefix = \"Mistral-7B\"\n",
    "s3_model_path = f\"s3://{bucket}/{model_prefix}\"\n",
    "!aws s3 sync s3://jumpstart-cache-prod-$region/huggingface-llm/huggingface-llm-mistral-7b/artifacts/inference/v1.0.0/ $s3_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data and upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_data = sess.upload_data(path=\"hf3k_train_processed.jsonl\", bucket=bucket, key_prefix=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.debugger import TensorBoardOutputConfig\n",
    "\n",
    "# tb_output_config = TensorBoardOutputConfig(s3_output_path=f\"s3://{bucket}/llama7b/tensorboard/\",\n",
    "#     container_local_output_path=\"/opt/ml/output/tensorboard\")\n",
    "\n",
    "# hyperparameters = {\n",
    "#     \"config_file\": \"qlora-34b.yml\",\n",
    "#     \"deepspeed\": \"axolotl/deepspeed/zero2.json\"\n",
    "# }\n",
    "\n",
    "hyperparameters = {\n",
    "    \"config\": \"qlora.yml\",\n",
    "}\n",
    "\n",
    "# estimator = PyTorch(\n",
    "#     source_dir = \"src\",\n",
    "#     entry_point=\"axol_launcher_dist.py\",\n",
    "#     sagemaker_session=sess,\n",
    "#     role=role,\n",
    "#     instance_count=2, \n",
    "#     hyperparameters=hyperparameters,\n",
    "#     instance_type=\"ml.g5.2xlarge\", \n",
    "#     framework_version=\"2.0.1\",\n",
    "#     py_version=\"py310\",\n",
    "#     disable_profiler=True,\n",
    "#     max_run=60*60*24*2,\n",
    "#     keep_alive_period_in_seconds=3600,\n",
    "#     tensorboard_output_config=tb_output_config,\n",
    "#     environment = {\"HUGGINGFACE_HUB_CACHE\": \"/tmp\", \n",
    "#                     \"LIBRARY_PATH\": \"/opt/conda/lib/\",\n",
    "#                     \"TRANSFORMERS_CACHE\": \"/tmp\"}\n",
    "# )\n",
    "\n",
    "estimator = PyTorch(\n",
    "    source_dir = \"src\",\n",
    "    entry_point=\"axolotl/src/axolotl/cli/train.py\",\n",
    "    sagemaker_session=sess,\n",
    "    role=role,\n",
    "    instance_count=4, \n",
    "    hyperparameters=hyperparameters,\n",
    "    instance_type=\"ml.g5.2xlarge\", \n",
    "    framework_version=\"2.3.0\",\n",
    "    py_version=\"py311\",\n",
    "    disable_profiler=True,\n",
    "    max_run=60*60*24*2,\n",
    "    keep_alive_period_in_seconds=3600,\n",
    "    # tensorboard_output_config=tb_output_config,\n",
    "    environment = {\"HUGGINGFACE_HUB_CACHE\": \"/tmp\", \n",
    "                    \"LIBRARY_PATH\": \"/opt/conda/lib/\",\n",
    "                    \"TRANSFORMERS_CACHE\": \"/tmp\",\n",
    "                    \"NCCL_P2P_LEVEL\": \"NVL\"},\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}} \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2024-07-08-18-02-56-581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-08 18:03:49 Starting - Starting the training job...\n",
      "2024-07-08 18:03:55 Downloading - Downloading input data................................bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-07-08 18:09:25,455 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-07-08 18:09:25,473 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:09:25,484 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-07-08 18:09:25,486 sagemaker_pytorch_container.training INFO     Invoking TorchDistributed...\n",
      "2024-07-08 18:09:25,486 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-07-08 18:09:25,371 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-07-08 18:09:25,389 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:09:25,399 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-07-08 18:09:25,402 sagemaker_pytorch_container.training INFO     Invoking TorchDistributed...\n",
      "2024-07-08 18:09:25,402 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-07-08 18:09:25,375 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-07-08 18:09:25,393 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:09:25,403 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-07-08 18:09:25,406 sagemaker_pytorch_container.training INFO     Invoking TorchDistributed...\n",
      "2024-07-08 18:09:25,406 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-07-08 18:09:25,336 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-07-08 18:09:25,353 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:09:25,364 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-07-08 18:09:25,366 sagemaker_pytorch_container.training INFO     Invoking TorchDistributed...\n",
      "2024-07-08 18:09:25,366 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2024-07-08 18:09:28,798 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.11 -m pip install -r requirements.txt\n",
      "2024-07-08 18:09:28,545 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.11 -m pip install -r requirements.txt\n",
      "Obtaining file:///opt/ml/code/axolotl\n",
      "Preparing metadata (setup.py): started\n",
      "2024-07-08 18:09:28,542 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.11 -m pip install -r requirements.txt\n",
      "Obtaining file:///opt/ml/code/axolotl\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.11.1.1)\n",
      "Collecting fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe (from axolotl==0.4.1)\n",
      "Cloning https://github.com/lm-sys/FastChat.git (to revision 27a05b04a35510afb1d767ae7e5990cbd278f8fe) to /tmp/pip-install-_rma8_h2/fschat_ac95ed8cdce64721abd57ea36e8684a6\n",
      "Running command git clone --filter=blob:none --quiet https://github.com/lm-sys/FastChat.git /tmp/pip-install-_rma8_h2/fschat_ac95ed8cdce64721abd57ea36e8684a6\n",
      "2024-07-08 18:09:28,545 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.11 -m pip install -r requirements.txt\n",
      "Obtaining file:///opt/ml/code/axolotl\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.11.1.1)\n",
      "Collecting fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe (from axolotl==0.4.1)\n",
      "Cloning https://github.com/lm-sys/FastChat.git (to revision 27a05b04a35510afb1d767ae7e5990cbd278f8fe) to /tmp/pip-install-n5cixr75/fschat_75456697512949ea9bbddbce4b9c7ea4\n",
      "Running command git clone --filter=blob:none --quiet https://github.com/lm-sys/FastChat.git /tmp/pip-install-n5cixr75/fschat_75456697512949ea9bbddbce4b9c7ea4\n",
      "Obtaining file:///opt/ml/code/axolotl\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.11.1.1)\n",
      "Collecting fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe (from axolotl==0.4.1)\n",
      "Cloning https://github.com/lm-sys/FastChat.git (to revision 27a05b04a35510afb1d767ae7e5990cbd278f8fe) to /tmp/pip-install-b52cgf72/fschat_7b55096207aa4467b7cad11450368677\n",
      "Running command git clone --filter=blob:none --quiet https://github.com/lm-sys/FastChat.git /tmp/pip-install-b52cgf72/fschat_7b55096207aa4467b7cad11450368677\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.11.1.1)\n",
      "Collecting fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe (from axolotl==0.4.1)\n",
      "Cloning https://github.com/lm-sys/FastChat.git (to revision 27a05b04a35510afb1d767ae7e5990cbd278f8fe) to /tmp/pip-install-xpacndxl/fschat_ad5950c0ec0c4002ba1ebbbc9c077ef8\n",
      "Running command git clone --filter=blob:none --quiet https://github.com/lm-sys/FastChat.git /tmp/pip-install-xpacndxl/fschat_ad5950c0ec0c4002ba1ebbbc9c077ef8\n",
      "Running command git rev-parse -q --verify 'sha^27a05b04a35510afb1d767ae7e5990cbd278f8fe'\n",
      "Running command git fetch -q https://github.com/lm-sys/FastChat.git 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
      "Running command git rev-parse -q --verify 'sha^27a05b04a35510afb1d767ae7e5990cbd278f8fe'\n",
      "Running command git fetch -q https://github.com/lm-sys/FastChat.git 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
      "Running command git checkout -q 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
      "Running command git rev-parse -q --verify 'sha^27a05b04a35510afb1d767ae7e5990cbd278f8fe'\n",
      "Running command git fetch -q https://github.com/lm-sys/FastChat.git 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
      "Running command git checkout -q 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
      "Resolved https://github.com/lm-sys/FastChat.git to commit 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
      "Installing build dependencies: started\n",
      "Running command git checkout -q 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
      "Resolved https://github.com/lm-sys/FastChat.git to commit 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
      "Installing build dependencies: started\n",
      "Resolved https://github.com/lm-sys/FastChat.git to commit 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
      "Installing build dependencies: started\n",
      "Running command git rev-parse -q --verify 'sha^27a05b04a35510afb1d767ae7e5990cbd278f8fe'\n",
      "Running command git fetch -q https://github.com/lm-sys/FastChat.git 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
      "Running command git checkout -q 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
      "Resolved https://github.com/lm-sys/FastChat.git to commit 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
      "Installing build dependencies: started\n",
      "Installing build dependencies: finished with status 'done'\n",
      "Getting requirements to build wheel: started\n",
      "Installing build dependencies: finished with status 'done'\n",
      "Getting requirements to build wheel: started\n",
      "Installing build dependencies: finished with status 'done'\n",
      "Getting requirements to build wheel: started\n",
      "Getting requirements to build wheel: finished with status 'done'\n",
      "Preparing metadata (pyproject.toml): started\n",
      "Getting requirements to build wheel: finished with status 'done'\n",
      "Preparing metadata (pyproject.toml): started\n",
      "Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9 (from axolotl==0.4.1)\n",
      "Cloning https://github.com/huggingface/trl.git (to revision f18253bf2d747f68acc9cd89da95c85ebf59dbb9) to /tmp/pip-install-xpacndxl/trl_9c2d4e5155684efb999d426acd28a456\n",
      "Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-install-xpacndxl/trl_9c2d4e5155684efb999d426acd28a456\n",
      "Running command git rev-parse -q --verify 'sha^f18253bf2d747f68acc9cd89da95c85ebf59dbb9'\n",
      "Running command git fetch -q https://github.com/huggingface/trl.git f18253bf2d747f68acc9cd89da95c85ebf59dbb9\n",
      "Running command git checkout -q f18253bf2d747f68acc9cd89da95c85ebf59dbb9\n",
      "Getting requirements to build wheel: finished with status 'done'\n",
      "Preparing metadata (pyproject.toml): started\n",
      "Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9 (from axolotl==0.4.1)\n",
      "Cloning https://github.com/huggingface/trl.git (to revision f18253bf2d747f68acc9cd89da95c85ebf59dbb9) to /tmp/pip-install-_rma8_h2/trl_a406b319f2954d9d8acf810ea6f73e21\n",
      "Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-install-_rma8_h2/trl_a406b319f2954d9d8acf810ea6f73e21\n",
      "Running command git rev-parse -q --verify 'sha^f18253bf2d747f68acc9cd89da95c85ebf59dbb9'\n",
      "Running command git fetch -q https://github.com/huggingface/trl.git f18253bf2d747f68acc9cd89da95c85ebf59dbb9\n",
      "Running command git checkout -q f18253bf2d747f68acc9cd89da95c85ebf59dbb9\n",
      "Installing build dependencies: finished with status 'done'\n",
      "Getting requirements to build wheel: started\n",
      "Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9 (from axolotl==0.4.1)\n",
      "Cloning https://github.com/huggingface/trl.git (to revision f18253bf2d747f68acc9cd89da95c85ebf59dbb9) to /tmp/pip-install-b52cgf72/trl_5665bf8add6b4225acf03ee08be5a9b5\n",
      "Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-install-b52cgf72/trl_5665bf8add6b4225acf03ee08be5a9b5\n",
      "Running command git rev-parse -q --verify 'sha^f18253bf2d747f68acc9cd89da95c85ebf59dbb9'\n",
      "Running command git fetch -q https://github.com/huggingface/trl.git f18253bf2d747f68acc9cd89da95c85ebf59dbb9\n",
      "Running command git checkout -q f18253bf2d747f68acc9cd89da95c85ebf59dbb9\n",
      "Resolved https://github.com/huggingface/trl.git to commit f18253bf2d747f68acc9cd89da95c85ebf59dbb9\n",
      "Installing build dependencies: started\n",
      "Resolved https://github.com/huggingface/trl.git to commit f18253bf2d747f68acc9cd89da95c85ebf59dbb9\n",
      "Installing build dependencies: started\n",
      "Resolved https://github.com/huggingface/trl.git to commit f18253bf2d747f68acc9cd89da95c85ebf59dbb9\n",
      "Installing build dependencies: started\n",
      "Getting requirements to build wheel: finished with status 'done'\n",
      "Preparing metadata (pyproject.toml): started\n",
      "Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9 (from axolotl==0.4.1)\n",
      "Cloning https://github.com/huggingface/trl.git (to revision f18253bf2d747f68acc9cd89da95c85ebf59dbb9) to /tmp/pip-install-n5cixr75/trl_182a6f5623304e678a0628948d2936fa\n",
      "Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-install-n5cixr75/trl_182a6f5623304e678a0628948d2936fa\n",
      "Running command git rev-parse -q --verify 'sha^f18253bf2d747f68acc9cd89da95c85ebf59dbb9'\n",
      "Running command git fetch -q https://github.com/huggingface/trl.git f18253bf2d747f68acc9cd89da95c85ebf59dbb9\n",
      "Running command git checkout -q f18253bf2d747f68acc9cd89da95c85ebf59dbb9\n",
      "Resolved https://github.com/huggingface/trl.git to commit f18253bf2d747f68acc9cd89da95c85ebf59dbb9\n",
      "Installing build dependencies: started\n",
      "Installing build dependencies: finished with status 'done'\n",
      "Getting requirements to build wheel: started\n",
      "Getting requirements to build wheel: finished with status 'done'\n",
      "Preparing metadata (pyproject.toml): started\n",
      "Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting peft==0.11.1 (from axolotl==0.4.1)\n",
      "Installing build dependencies: finished with status 'done'\n",
      "Getting requirements to build wheel: started\n",
      "Getting requirements to build wheel: finished with status 'done'\n",
      "Preparing metadata (pyproject.toml): started\n",
      "Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting peft==0.11.1 (from axolotl==0.4.1)\n",
      "Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
      "Installing build dependencies: finished with status 'done'\n",
      "Getting requirements to build wheel: started\n",
      "Getting requirements to build wheel: finished with status 'done'\n",
      "Preparing metadata (pyproject.toml): started\n",
      "Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting peft==0.11.1 (from axolotl==0.4.1)\n",
      "Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers==4.42.3 (from axolotl==0.4.1)\n",
      "Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 4.8 MB/s eta 0:00:00\n",
      "Collecting tokenizers==0.19.1 (from axolotl==0.4.1)\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting bitsandbytes==0.43.1 (from axolotl==0.4.1)\n",
      "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: accelerate==0.30.1 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.30.1)\n",
      "Collecting pydantic==2.6.3 (from axolotl==0.4.1)\n",
      "Downloading pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.4/84.4 kB 5.1 MB/s eta 0:00:00\n",
      "Collecting addict (from axolotl==0.4.1)\n",
      "Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting fire (from axolotl==0.4.1)\n",
      "Downloading fire-0.6.0.tar.gz (88 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.4/88.4 kB 4.9 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML>=6.0 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (2.32.2)\n",
      "Collecting transformers==4.42.3 (from axolotl==0.4.1)\n",
      "Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 5.9 MB/s eta 0:00:00\n",
      "Collecting tokenizers==0.19.1 (from axolotl==0.4.1)\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting bitsandbytes==0.43.1 (from axolotl==0.4.1)\n",
      "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: accelerate==0.30.1 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.30.1)\n",
      "Collecting pydantic==2.6.3 (from axolotl==0.4.1)\n",
      "Downloading pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.4/84.4 kB 15.5 MB/s eta 0:00:00\n",
      "Collecting addict (from axolotl==0.4.1)\n",
      "Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting fire (from axolotl==0.4.1)\n",
      "Downloading fire-0.6.0.tar.gz (88 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.4/88.4 kB 18.2 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML>=6.0 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (2.32.2)\n",
      "Collecting datasets==2.19.1 (from axolotl==0.4.1)\n",
      "Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentencepiece (from axolotl==0.4.1)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Installing build dependencies: finished with status 'done'\n",
      "Getting requirements to build wheel: started\n",
      "Getting requirements to build wheel: finished with status 'done'\n",
      "Preparing metadata (pyproject.toml): started\n",
      "Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting peft==0.11.1 (from axolotl==0.4.1)\n",
      "Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers==4.42.3 (from axolotl==0.4.1)\n",
      "Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers==4.42.3 (from axolotl==0.4.1)\n",
      "Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 5.3 MB/s eta 0:00:00\n",
      "Collecting tokenizers==0.19.1 (from axolotl==0.4.1)\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting bitsandbytes==0.43.1 (from axolotl==0.4.1)\n",
      "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: accelerate==0.30.1 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.30.1)\n",
      "Collecting pydantic==2.6.3 (from axolotl==0.4.1)\n",
      "Downloading pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.4/84.4 kB 13.6 MB/s eta 0:00:00\n",
      "Collecting addict (from axolotl==0.4.1)\n",
      "Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting fire (from axolotl==0.4.1)\n",
      "Downloading fire-0.6.0.tar.gz (88 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.4/88.4 kB 10.4 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML>=6.0 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (2.32.2)\n",
      "Collecting datasets==2.19.1 (from axolotl==0.4.1)\n",
      "Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting datasets==2.19.1 (from axolotl==0.4.1)\n",
      "Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentencepiece (from axolotl==0.4.1)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting wandb (from axolotl==0.4.1)\n",
      "Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.8.0)\n",
      "Collecting xformers==0.0.26.post1 (from axolotl==0.4.1)\n",
      "Downloading xformers-0.0.26.post1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting optimum==1.16.2 (from axolotl==0.4.1)\n",
      "Downloading optimum-1.16.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting hf_transfer (from axolotl==0.4.1)\n",
      "Downloading hf_transfer-0.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.4.6)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.59.1)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (1.26.4)\n",
      "Collecting evaluate==0.4.1 (from axolotl==0.4.1)\n",
      "Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (1.13.1)\n",
      "Collecting scikit-learn==1.2.2 (from axolotl==0.4.1)\n",
      "Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pynvml (from axolotl==0.4.1)\n",
      "Downloading pynvml-11.5.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting art (from axolotl==0.4.1)\n",
      "Downloading art-6.2-py3-none-any.whl.metadata (69 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 69.2/69.2 kB 10.5 MB/s eta 0:00:00\n",
      "Collecting gradio==3.50.2 (from axolotl==0.4.1)\n",
      "Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (2.16.2)\n",
      "Collecting python-dotenv==1.0.1 (from axolotl==0.4.1)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.4.2)\n",
      "Collecting gcsfs (from axolotl==0.4.1)\n",
      "Downloading gcsfs-2024.6.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting zstandard==0.22.0 (from axolotl==0.4.1)\n",
      "Downloading zstandard-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fastcore in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (1.5.38)\n",
      "Requirement already satisfied: torch==2.3.0 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (2.3.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate==0.30.1->axolotl==0.4.1) (5.9.8)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.11/site-packages (from accelerate==0.30.1->axolotl==0.4.1) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from accelerate==0.30.1->axolotl==0.4.1) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (3.14.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (16.1.0)\n",
      "Collecting pyarrow-hotfix (from datasets==2.19.1->axolotl==0.4.1)\n",
      "Collecting wandb (from axolotl==0.4.1)\n",
      "Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.8.0)\n",
      "Collecting xformers==0.0.26.post1 (from axolotl==0.4.1)\n",
      "Downloading xformers-0.0.26.post1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting optimum==1.16.2 (from axolotl==0.4.1)\n",
      "Downloading optimum-1.16.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting hf_transfer (from axolotl==0.4.1)\n",
      "Downloading hf_transfer-0.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.4.6)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.59.1)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (1.26.4)\n",
      "Collecting evaluate==0.4.1 (from axolotl==0.4.1)\n",
      "Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (1.13.1)\n",
      "Collecting scikit-learn==1.2.2 (from axolotl==0.4.1)\n",
      "Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pynvml (from axolotl==0.4.1)\n",
      "Downloading pynvml-11.5.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting art (from axolotl==0.4.1)\n",
      "Downloading art-6.2-py3-none-any.whl.metadata (69 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 69.2/69.2 kB 14.2 MB/s eta 0:00:00\n",
      "Collecting gradio==3.50.2 (from axolotl==0.4.1)\n",
      "Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (2.16.2)\n",
      "Collecting python-dotenv==1.0.1 (from axolotl==0.4.1)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.4.2)\n",
      "Collecting gcsfs (from axolotl==0.4.1)\n",
      "Downloading gcsfs-2024.6.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting zstandard==0.22.0 (from axolotl==0.4.1)\n",
      "Downloading zstandard-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fastcore in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (1.5.38)\n",
      "Requirement already satisfied: torch==2.3.0 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (2.3.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate==0.30.1->axolotl==0.4.1) (5.9.8)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.11/site-packages (from accelerate==0.30.1->axolotl==0.4.1) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from accelerate==0.30.1->axolotl==0.4.1) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (3.14.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (16.1.0)\n",
      "Collecting pyarrow-hotfix (from datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (4.66.4)\n",
      "Collecting xxhash (from datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (0.70.16)\n",
      "Collecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting tokenizers==0.19.1 (from axolotl==0.4.1)\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting bitsandbytes==0.43.1 (from axolotl==0.4.1)\n",
      "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: accelerate==0.30.1 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.30.1)\n",
      "Collecting pydantic==2.6.3 (from axolotl==0.4.1)\n",
      "Downloading pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.4/84.4 kB 10.6 MB/s eta 0:00:00\n",
      "Collecting addict (from axolotl==0.4.1)\n",
      "Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting fire (from axolotl==0.4.1)\n",
      "Downloading fire-0.6.0.tar.gz (88 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.4/88.4 kB 14.4 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML>=6.0 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (2.32.2)\n",
      "Collecting datasets==2.19.1 (from axolotl==0.4.1)\n",
      "Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentencepiece (from axolotl==0.4.1)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting wandb (from axolotl==0.4.1)\n",
      "Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting sentencepiece (from axolotl==0.4.1)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting wandb (from axolotl==0.4.1)\n",
      "Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.8.0)\n",
      "Collecting xformers==0.0.26.post1 (from axolotl==0.4.1)\n",
      "Downloading xformers-0.0.26.post1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting optimum==1.16.2 (from axolotl==0.4.1)\n",
      "Downloading optimum-1.16.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting hf_transfer (from axolotl==0.4.1)\n",
      "Downloading hf_transfer-0.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.4.6)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.59.1)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (1.26.4)\n",
      "Collecting evaluate==0.4.1 (from axolotl==0.4.1)\n",
      "Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (1.13.1)\n",
      "Collecting scikit-learn==1.2.2 (from axolotl==0.4.1)\n",
      "Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pynvml (from axolotl==0.4.1)\n",
      "Downloading pynvml-11.5.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting art (from axolotl==0.4.1)\n",
      "Downloading art-6.2-py3-none-any.whl.metadata (69 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 69.2/69.2 kB 9.5 MB/s eta 0:00:00\n",
      "Collecting gradio==3.50.2 (from axolotl==0.4.1)\n",
      "Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (2.16.2)\n",
      "Collecting python-dotenv==1.0.1 (from axolotl==0.4.1)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.4.2)\n",
      "Collecting gcsfs (from axolotl==0.4.1)\n",
      "Downloading gcsfs-2024.6.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (4.66.4)\n",
      "Collecting xxhash (from datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (0.70.16)\n",
      "Collecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting responses<0.19 (from evaluate==0.4.1->axolotl==0.4.1)\n",
      "Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting fastapi (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ffmpy (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "Preparing metadata (setup.py): started\n",
      "Collecting aiohttp (from datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting responses<0.19 (from evaluate==0.4.1->axolotl==0.4.1)\n",
      "Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting fastapi (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ffmpy (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gradio-client==0.6.1 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (3.8.4)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.8.0)\n",
      "Collecting xformers==0.0.26.post1 (from axolotl==0.4.1)\n",
      "Downloading xformers-0.0.26.post1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting optimum==1.16.2 (from axolotl==0.4.1)\n",
      "Downloading optimum-1.16.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting hf_transfer (from axolotl==0.4.1)\n",
      "Downloading hf_transfer-0.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.4.6)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.59.1)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (1.26.4)\n",
      "Collecting evaluate==0.4.1 (from axolotl==0.4.1)\n",
      "Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (1.13.1)\n",
      "Collecting scikit-learn==1.2.2 (from axolotl==0.4.1)\n",
      "Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pynvml (from axolotl==0.4.1)\n",
      "Downloading pynvml-11.5.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting art (from axolotl==0.4.1)\n",
      "Downloading art-6.2-py3-none-any.whl.metadata (69 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 69.2/69.2 kB 9.6 MB/s eta 0:00:00\n",
      "Collecting gradio==3.50.2 (from axolotl==0.4.1)\n",
      "Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (2.16.2)\n",
      "Collecting python-dotenv==1.0.1 (from axolotl==0.4.1)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (0.4.2)\n",
      "Collecting gcsfs (from axolotl==0.4.1)\n",
      "Downloading gcsfs-2024.6.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting zstandard==0.22.0 (from axolotl==0.4.1)\n",
      "Downloading zstandard-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fastcore in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (1.5.38)\n",
      "Requirement already satisfied: torch==2.3.0 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (2.3.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate==0.30.1->axolotl==0.4.1) (5.9.8)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.11/site-packages (from accelerate==0.30.1->axolotl==0.4.1) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from accelerate==0.30.1->axolotl==0.4.1) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (3.14.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (16.1.0)\n",
      "Collecting pyarrow-hotfix (from datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (4.66.4)\n",
      "Collecting xxhash (from datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (0.70.16)\n",
      "Collecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting zstandard==0.22.0 (from axolotl==0.4.1)\n",
      "Downloading zstandard-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fastcore in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (1.5.38)\n",
      "Requirement already satisfied: torch==2.3.0 in /opt/conda/lib/python3.11/site-packages (from axolotl==0.4.1) (2.3.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate==0.30.1->axolotl==0.4.1) (5.9.8)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.11/site-packages (from accelerate==0.30.1->axolotl==0.4.1) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from accelerate==0.30.1->axolotl==0.4.1) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (3.14.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (16.1.0)\n",
      "Collecting pyarrow-hotfix (from datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (4.66.4)\n",
      "Collecting xxhash (from datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets==2.19.1->axolotl==0.4.1) (0.70.16)\n",
      "Collecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting responses<0.19 (from evaluate==0.4.1->axolotl==0.4.1)\n",
      "Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting fastapi (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ffmpy (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gradio-client==0.6.1 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (3.8.4)\n",
      "Collecting orjson~=3.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading orjson-3.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.4/50.4 kB 7.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (10.3.0)\n",
      "Collecting pydub (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (4.11.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting coloredlogs (from optimum==1.16.2->axolotl==0.4.1)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from optimum==1.16.2->axolotl==0.4.1) (1.12)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic==2.6.3->axolotl==0.4.1) (0.7.0)\n",
      "Collecting orjson~=3.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading orjson-3.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.4/50.4 kB 9.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (10.3.0)\n",
      "Collecting pydub (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (4.11.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting coloredlogs (from optimum==1.16.2->axolotl==0.4.1)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from optimum==1.16.2->axolotl==0.4.1) (1.12)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic==2.6.3->axolotl==0.4.1) (0.7.0)\n",
      "Collecting aiohttp (from datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting responses<0.19 (from evaluate==0.4.1->axolotl==0.4.1)\n",
      "Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting fastapi (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ffmpy (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gradio-client==0.6.1 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (3.8.4)\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gradio-client==0.6.1 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (3.8.4)\n",
      "Collecting orjson~=3.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading orjson-3.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.4/50.4 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (10.3.0)\n",
      "Collecting pydub (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (4.11.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting coloredlogs (from optimum==1.16.2->axolotl==0.4.1)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic==2.6.3->axolotl==0.4.1)\n",
      "Downloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.2.2->axolotl==0.4.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.2.2->axolotl==0.4.1) (3.5.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.3.0->axolotl==0.4.1) (3.3)\n",
      "Collecting huggingface-hub (from accelerate==0.30.1->axolotl==0.4.1)\n",
      "Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic==2.6.3->axolotl==0.4.1)\n",
      "Downloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.2.2->axolotl==0.4.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.2.2->axolotl==0.4.1) (3.5.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.3.0->axolotl==0.4.1) (3.3)\n",
      "Collecting huggingface-hub (from accelerate==0.30.1->axolotl==0.4.1)\n",
      "Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.42.3->axolotl==0.4.1)\n",
      "Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 6.7 MB/s eta 0:00:00\n",
      "Collecting deepspeed@ git+https://github.com/microsoft/DeepSpeed.git@bc48371c5e1fb8fd70fc79285e66201dbb65679b (from axolotl==0.4.1)\n",
      "Cloning https://github.com/microsoft/DeepSpeed.git (to revision bc48371c5e1fb8fd70fc79285e66201dbb65679b) to /tmp/pip-install-_rma8_h2/deepspeed_26eaf00deb3044d9b1581f8a33b16dbe\n",
      "Running command git clone --filter=blob:none --quiet https://github.com/microsoft/DeepSpeed.git /tmp/pip-install-_rma8_h2/deepspeed_26eaf00deb3044d9b1581f8a33b16dbe\n",
      "Collecting orjson~=3.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading orjson-3.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.4/50.4 kB 6.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (10.3.0)\n",
      "Collecting pydub (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50.2->axolotl==0.4.1) (4.11.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting coloredlogs (from optimum==1.16.2->axolotl==0.4.1)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from optimum==1.16.2->axolotl==0.4.1) (1.12)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic==2.6.3->axolotl==0.4.1) (0.7.0)\n",
      "\n",
      "2024-07-08 18:09:24 Training - Training image download completed. Training in progress.Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from optimum==1.16.2->axolotl==0.4.1) (1.12)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic==2.6.3->axolotl==0.4.1) (0.7.0)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic==2.6.3->axolotl==0.4.1)\n",
      "Downloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.2.2->axolotl==0.4.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.2.2->axolotl==0.4.1) (3.5.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.3.0->axolotl==0.4.1) (3.3)\n",
      "Collecting huggingface-hub (from accelerate==0.30.1->axolotl==0.4.1)\n",
      "Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.42.3->axolotl==0.4.1)\n",
      "Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 5.9 MB/s eta 0:00:00\n",
      "Collecting deepspeed@ git+https://github.com/microsoft/DeepSpeed.git@bc48371c5e1fb8fd70fc79285e66201dbb65679b (from axolotl==0.4.1)\n",
      "Cloning https://github.com/microsoft/DeepSpeed.git (to revision bc48371c5e1fb8fd70fc79285e66201dbb65679b) to /tmp/pip-install-xpacndxl/deepspeed_aa7720d8592c48a2902e112cb491b88f\n",
      "Running command git clone --filter=blob:none --quiet https://github.com/microsoft/DeepSpeed.git /tmp/pip-install-xpacndxl/deepspeed_aa7720d8592c48a2902e112cb491b88f\n",
      "Collecting pydantic-core==2.16.3 (from pydantic==2.6.3->axolotl==0.4.1)\n",
      "Downloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.2.2->axolotl==0.4.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.2.2->axolotl==0.4.1) (3.5.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.3.0->axolotl==0.4.1) (3.3)\n",
      "Collecting huggingface-hub (from accelerate==0.30.1->axolotl==0.4.1)\n",
      "Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.42.3->axolotl==0.4.1)\n",
      "Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 6.8 MB/s eta 0:00:00\n",
      "Collecting deepspeed@ git+https://github.com/microsoft/DeepSpeed.git@bc48371c5e1fb8fd70fc79285e66201dbb65679b (from axolotl==0.4.1)\n",
      "Cloning https://github.com/microsoft/DeepSpeed.git (to revision bc48371c5e1fb8fd70fc79285e66201dbb65679b) to /tmp/pip-install-n5cixr75/deepspeed_928fe5e0643742c9bf4dc48b8a4e2413\n",
      "Running command git clone --filter=blob:none --quiet https://github.com/microsoft/DeepSpeed.git /tmp/pip-install-n5cixr75/deepspeed_928fe5e0643742c9bf4dc48b8a4e2413\n",
      "Collecting regex!=2019.12.17 (from transformers==4.42.3->axolotl==0.4.1)\n",
      "Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting deepspeed@ git+https://github.com/microsoft/DeepSpeed.git@bc48371c5e1fb8fd70fc79285e66201dbb65679b (from axolotl==0.4.1)\n",
      "Cloning https://github.com/microsoft/DeepSpeed.git (to revision bc48371c5e1fb8fd70fc79285e66201dbb65679b) to /tmp/pip-install-b52cgf72/deepspeed_2962d5da41834936939fe233dcd44deb\n",
      "Running command git clone --filter=blob:none --quiet https://github.com/microsoft/DeepSpeed.git /tmp/pip-install-b52cgf72/deepspeed_2962d5da41834936939fe233dcd44deb\n",
      "Running command git rev-parse -q --verify 'sha^bc48371c5e1fb8fd70fc79285e66201dbb65679b'\n",
      "Running command git fetch -q https://github.com/microsoft/DeepSpeed.git bc48371c5e1fb8fd70fc79285e66201dbb65679b\n",
      "Running command git rev-parse -q --verify 'sha^bc48371c5e1fb8fd70fc79285e66201dbb65679b'\n",
      "Running command git fetch -q https://github.com/microsoft/DeepSpeed.git bc48371c5e1fb8fd70fc79285e66201dbb65679b\n",
      "Running command git rev-parse -q --verify 'sha^bc48371c5e1fb8fd70fc79285e66201dbb65679b'\n",
      "Running command git fetch -q https://github.com/microsoft/DeepSpeed.git bc48371c5e1fb8fd70fc79285e66201dbb65679b\n",
      "Running command git checkout -q bc48371c5e1fb8fd70fc79285e66201dbb65679b\n",
      "Running command git checkout -q bc48371c5e1fb8fd70fc79285e66201dbb65679b\n",
      "Resolved https://github.com/microsoft/DeepSpeed.git to commit bc48371c5e1fb8fd70fc79285e66201dbb65679b\n",
      "Running command git submodule update --init --recursive -q\n",
      "Preparing metadata (setup.py): started\n",
      "Resolved https://github.com/microsoft/DeepSpeed.git to commit bc48371c5e1fb8fd70fc79285e66201dbb65679b\n",
      "Running command git submodule update --init --recursive -q\n",
      "Preparing metadata (setup.py): started\n",
      "Running command git checkout -q bc48371c5e1fb8fd70fc79285e66201dbb65679b\n",
      "Resolved https://github.com/microsoft/DeepSpeed.git to commit bc48371c5e1fb8fd70fc79285e66201dbb65679b\n",
      "Running command git submodule update --init --recursive -q\n",
      "Preparing metadata (setup.py): started\n",
      "Running command git rev-parse -q --verify 'sha^bc48371c5e1fb8fd70fc79285e66201dbb65679b'\n",
      "Running command git fetch -q https://github.com/microsoft/DeepSpeed.git bc48371c5e1fb8fd70fc79285e66201dbb65679b\n",
      "Running command git checkout -q bc48371c5e1fb8fd70fc79285e66201dbb65679b\n",
      "Resolved https://github.com/microsoft/DeepSpeed.git to commit bc48371c5e1fb8fd70fc79285e66201dbb65679b\n",
      "Running command git submodule update --init --recursive -q\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting flash-attn==2.5.8 (from axolotl==0.4.1)\n",
      "Downloading flash_attn-2.5.8.tar.gz (2.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 93.2 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting flash-attn==2.5.8 (from axolotl==0.4.1)\n",
      "Downloading flash_attn-2.5.8.tar.gz (2.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 85.2 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting flash-attn==2.5.8 (from axolotl==0.4.1)\n",
      "Downloading flash_attn-2.5.8.tar.gz (2.5 MB)\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting flash-attn==2.5.8 (from axolotl==0.4.1)\n",
      "Downloading flash_attn-2.5.8.tar.gz (2.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 75.3 MB/s eta 0:00:00\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 79.5 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting deepspeed-kernels (from axolotl==0.4.1)\n",
      "Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl.metadata (680 bytes)\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting deepspeed-kernels (from axolotl==0.4.1)\n",
      "Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl.metadata (680 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (2024.2.2)\n",
      "Collecting hjson (from deepspeed@ git+https://github.com/microsoft/DeepSpeed.git@bc48371c5e1fb8fd70fc79285e66201dbb65679b->axolotl==0.4.1)\n",
      "Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting py-cpuinfo (from deepspeed@ git+https://github.com/microsoft/DeepSpeed.git@bc48371c5e1fb8fd70fc79285e66201dbb65679b->axolotl==0.4.1)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: cmake>=3.24 in /opt/conda/lib/python3.11/site-packages (from deepspeed-kernels->axolotl==0.4.1) (3.29.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from fire->axolotl==0.4.1) (1.16.0)\n",
      "Collecting termcolor (from fire->axolotl==0.4.1)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting markdown2[all] (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading markdown2-2.4.13-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting nh3 (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (3.0.42)\n",
      "Requirement already satisfied: rich>=10.0.0 in /opt/conda/lib/python3.11/site-packages (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (13.7.1)\n",
      "Collecting shortuuid (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tiktoken (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: decorator>4.1.2 in /opt/conda/lib/python3.11/site-packages (from gcsfs->axolotl==0.4.1) (5.1.1)\n",
      "INFO: pip is looking at multiple versions of gcsfs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting gcsfs (from axolotl==0.4.1)\n",
      "Downloading gcsfs-2024.6.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gcsfs-2024.5.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gcsfs-2024.3.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting google-auth>=1.2 (from gcsfs->axolotl==0.4.1)\n",
      "Downloading google_auth-2.31.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib (from gcsfs->axolotl==0.4.1)\n",
      "Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-storage (from gcsfs->axolotl==0.4.1)\n",
      "Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->axolotl==0.4.1) (0.42.0)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /opt/conda/lib/python3.11/site-packages (from s3fs->axolotl==0.4.1) (1.34.112)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (1.64.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (3.6)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (68.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (3.0.3)\n",
      "Collecting tyro>=0.5.11 (from trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9->axolotl==0.4.1)\n",
      "Downloading tyro-0.8.5-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb->axolotl==0.4.1) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->axolotl==0.4.1)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->axolotl==0.4.1)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb->axolotl==0.4.1) (4.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (2024.2.2)\n",
      "Collecting hjson (from deepspeed@ git+https://github.com/microsoft/DeepSpeed.git@bc48371c5e1fb8fd70fc79285e66201dbb65679b->axolotl==0.4.1)\n",
      "Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting py-cpuinfo (from deepspeed@ git+https://github.com/microsoft/DeepSpeed.git@bc48371c5e1fb8fd70fc79285e66201dbb65679b->axolotl==0.4.1)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: cmake>=3.24 in /opt/conda/lib/python3.11/site-packages (from deepspeed-kernels->axolotl==0.4.1) (3.29.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from fire->axolotl==0.4.1) (1.16.0)\n",
      "Collecting termcolor (from fire->axolotl==0.4.1)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting markdown2[all] (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading markdown2-2.4.13-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting nh3 (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (3.0.42)\n",
      "Requirement already satisfied: rich>=10.0.0 in /opt/conda/lib/python3.11/site-packages (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (13.7.1)\n",
      "Collecting shortuuid (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tiktoken (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: decorator>4.1.2 in /opt/conda/lib/python3.11/site-packages (from gcsfs->axolotl==0.4.1) (5.1.1)\n",
      "INFO: pip is looking at multiple versions of gcsfs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting gcsfs (from axolotl==0.4.1)\n",
      "Downloading gcsfs-2024.6.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gcsfs-2024.5.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gcsfs-2024.3.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting google-auth>=1.2 (from gcsfs->axolotl==0.4.1)\n",
      "Downloading google_auth-2.31.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib (from gcsfs->axolotl==0.4.1)\n",
      "Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-storage (from gcsfs->axolotl==0.4.1)\n",
      "Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->axolotl==0.4.1) (0.42.0)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /opt/conda/lib/python3.11/site-packages (from s3fs->axolotl==0.4.1) (1.34.112)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (1.64.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (3.6)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (68.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (3.0.3)\n",
      "Collecting tyro>=0.5.11 (from trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9->axolotl==0.4.1)\n",
      "Downloading tyro-0.8.5-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb->axolotl==0.4.1) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->axolotl==0.4.1)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->axolotl==0.4.1)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb->axolotl==0.4.1) (4.1.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->axolotl==0.4.1)\n",
      "Downloading sentry_sdk-2.8.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting setproctitle (from wandb->axolotl==0.4.1)\n",
      "Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.19.1->axolotl==0.4.1) (23.2.0)\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting deepspeed-kernels (from axolotl==0.4.1)\n",
      "Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl.metadata (680 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (2024.2.2)\n",
      "Collecting hjson (from deepspeed@ git+https://github.com/microsoft/DeepSpeed.git@bc48371c5e1fb8fd70fc79285e66201dbb65679b->axolotl==0.4.1)\n",
      "Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting py-cpuinfo (from deepspeed@ git+https://github.com/microsoft/DeepSpeed.git@bc48371c5e1fb8fd70fc79285e66201dbb65679b->axolotl==0.4.1)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: cmake>=3.24 in /opt/conda/lib/python3.11/site-packages (from deepspeed-kernels->axolotl==0.4.1) (3.29.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from fire->axolotl==0.4.1) (1.16.0)\n",
      "Collecting termcolor (from fire->axolotl==0.4.1)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting markdown2[all] (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading markdown2-2.4.13-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting nh3 (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (3.0.42)\n",
      "Requirement already satisfied: rich>=10.0.0 in /opt/conda/lib/python3.11/site-packages (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (13.7.1)\n",
      "Collecting shortuuid (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tiktoken (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: decorator>4.1.2 in /opt/conda/lib/python3.11/site-packages (from gcsfs->axolotl==0.4.1) (5.1.1)\n",
      "INFO: pip is looking at multiple versions of gcsfs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting gcsfs (from axolotl==0.4.1)\n",
      "Downloading gcsfs-2024.6.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gcsfs-2024.5.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->axolotl==0.4.1)\n",
      "Downloading sentry_sdk-2.8.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting setproctitle (from wandb->axolotl==0.4.1)\n",
      "Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.19.1->axolotl==0.4.1) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (4.22.0)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from botocore>=1.12.91->s3fs->axolotl==0.4.1) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore>=1.12.91->s3fs->axolotl==0.4.1) (2.9.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->axolotl==0.4.1)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.2->gcsfs->axolotl==0.4.1)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.2->gcsfs->axolotl==0.4.1)\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs->axolotl==0.4.1) (4.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (4.52.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==2.19.1->axolotl==0.4.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==2.19.1->axolotl==0.4.1) (2024.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit>=3.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (2.18.0)\n",
      "Collecting docstring-parser>=0.16 (from tyro>=0.5.11->trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9->axolotl==0.4.1)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (4.22.0)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from botocore>=1.12.91->s3fs->axolotl==0.4.1) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore>=1.12.91->s3fs->axolotl==0.4.1) (2.9.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->axolotl==0.4.1)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.2->gcsfs->axolotl==0.4.1)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.2->gcsfs->axolotl==0.4.1)\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs->axolotl==0.4.1) (4.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (4.52.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==2.19.1->axolotl==0.4.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==2.19.1->axolotl==0.4.1) (2024.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit>=3.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (2.18.0)\n",
      "Collecting docstring-parser>=0.16 (from tyro>=0.5.11->trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9->axolotl==0.4.1)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9->axolotl==0.4.1)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum==1.16.2->axolotl==0.4.1)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting deepspeed-kernels (from axolotl==0.4.1)\n",
      "Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl.metadata (680 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->axolotl==0.4.1) (2024.2.2)\n",
      "Collecting hjson (from deepspeed@ git+https://github.com/microsoft/DeepSpeed.git@bc48371c5e1fb8fd70fc79285e66201dbb65679b->axolotl==0.4.1)\n",
      "Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting py-cpuinfo (from deepspeed@ git+https://github.com/microsoft/DeepSpeed.git@bc48371c5e1fb8fd70fc79285e66201dbb65679b->axolotl==0.4.1)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: cmake>=3.24 in /opt/conda/lib/python3.11/site-packages (from deepspeed-kernels->axolotl==0.4.1) (3.29.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from fire->axolotl==0.4.1) (1.16.0)\n",
      "Collecting termcolor (from fire->axolotl==0.4.1)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting markdown2[all] (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading markdown2-2.4.13-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting nh3 (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (3.0.42)\n",
      "Requirement already satisfied: rich>=10.0.0 in /opt/conda/lib/python3.11/site-packages (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (13.7.1)\n",
      "Collecting shortuuid (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tiktoken (from fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: decorator>4.1.2 in /opt/conda/lib/python3.11/site-packages (from gcsfs->axolotl==0.4.1) (5.1.1)\n",
      "INFO: pip is looking at multiple versions of gcsfs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting gcsfs (from axolotl==0.4.1)\n",
      "Downloading gcsfs-2024.6.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gcsfs-2024.5.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gcsfs-2024.3.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting google-auth>=1.2 (from gcsfs->axolotl==0.4.1)\n",
      "Downloading google_auth-2.31.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib (from gcsfs->axolotl==0.4.1)\n",
      "Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-storage (from gcsfs->axolotl==0.4.1)\n",
      "Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->axolotl==0.4.1) (0.42.0)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /opt/conda/lib/python3.11/site-packages (from s3fs->axolotl==0.4.1) (1.34.112)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (1.64.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (3.6)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (68.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (3.0.3)\n",
      "Collecting tyro>=0.5.11 (from trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9->axolotl==0.4.1)\n",
      "Downloading tyro-0.8.5-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb->axolotl==0.4.1) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->axolotl==0.4.1)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->axolotl==0.4.1)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb->axolotl==0.4.1) (4.1.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->axolotl==0.4.1)\n",
      "Downloading gcsfs-2024.3.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting google-auth>=1.2 (from gcsfs->axolotl==0.4.1)\n",
      "Downloading google_auth-2.31.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib (from gcsfs->axolotl==0.4.1)\n",
      "Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-storage (from gcsfs->axolotl==0.4.1)\n",
      "Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->axolotl==0.4.1) (0.42.0)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /opt/conda/lib/python3.11/site-packages (from s3fs->axolotl==0.4.1) (1.34.112)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (1.64.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (3.6)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (68.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard->axolotl==0.4.1) (3.0.3)\n",
      "Collecting tyro>=0.5.11 (from trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9->axolotl==0.4.1)\n",
      "Downloading tyro-0.8.5-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb->axolotl==0.4.1) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->axolotl==0.4.1)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->axolotl==0.4.1)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb->axolotl==0.4.1) (4.1.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->axolotl==0.4.1)\n",
      "Downloading sentry_sdk-2.8.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting setproctitle (from wandb->axolotl==0.4.1)\n",
      "Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.19.1->axolotl==0.4.1) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting anyio (from httpx->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sniffio (from httpx->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib->gcsfs->axolotl==0.4.1)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.6.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_crc32c-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting wavedrom (from markdown2[all]->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.7/137.7 kB 25.9 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->optimum==1.16.2->axolotl==0.4.1) (1.3.0)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting typer>=0.12.3 (from fastapi-cli>=0.0.2->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->axolotl==0.4.1)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs->axolotl==0.4.1) (0.6.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->axolotl==0.4.1)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading watchfiles-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting svgwrite (from wavedrom->markdown2[all]->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.50.2->axolotl==0.4.1) (1.5.4)\n",
      "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.8/119.8 MB 24.0 MB/s eta 0:00:00\n",
      "Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 542.0/542.0 kB 55.8 MB/s eta 0:00:00\n",
      "Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.1/84.1 kB 15.8 MB/s eta 0:00:00\n",
      "Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.3/20.3 MB 74.3 MB/s eta 0:00:00\n",
      "Downloading optimum-1.16.2-py3-none-any.whl (402 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 402.5/402.5 kB 48.5 MB/s eta 0:00:00\n",
      "Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 251.6/251.6 kB 34.5 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 395.2/395.2 kB 48.6 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.6/9.6 MB 104.6 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9->axolotl==0.4.1)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum==1.16.2->axolotl==0.4.1)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting anyio (from httpx->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sniffio (from httpx->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib->gcsfs->axolotl==0.4.1)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.6.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_crc32c-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting wavedrom (from markdown2[all]->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.7/137.7 kB 23.0 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Downloading sentry_sdk-2.8.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting setproctitle (from wandb->axolotl==0.4.1)\n",
      "Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.19.1->axolotl==0.4.1) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (4.22.0)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from botocore>=1.12.91->s3fs->axolotl==0.4.1) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore>=1.12.91->s3fs->axolotl==0.4.1) (2.9.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->axolotl==0.4.1)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.2->gcsfs->axolotl==0.4.1)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.2->gcsfs->axolotl==0.4.1)\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs->axolotl==0.4.1) (4.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (4.52.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==2.19.1->axolotl==0.4.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==2.19.1->axolotl==0.4.1) (2024.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit>=3.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (2.18.0)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets==2.19.1->axolotl==0.4.1)\n",
      "Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (4.22.0)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from botocore>=1.12.91->s3fs->axolotl==0.4.1) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore>=1.12.91->s3fs->axolotl==0.4.1) (2.9.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->axolotl==0.4.1)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.2->gcsfs->axolotl==0.4.1)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.2->gcsfs->axolotl==0.4.1)\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs->axolotl==0.4.1) (4.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (4.52.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl==0.4.1) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==2.19.1->axolotl==0.4.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==2.19.1->axolotl==0.4.1) (2024.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit>=3.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (2.18.0)\n",
      "Collecting docstring-parser>=0.16 (from tyro>=0.5.11->trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9->axolotl==0.4.1)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9->axolotl==0.4.1)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum==1.16.2->axolotl==0.4.1)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting anyio (from httpx->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->optimum==1.16.2->axolotl==0.4.1) (1.3.0)\n",
      "Collecting docstring-parser>=0.16 (from tyro>=0.5.11->trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9->axolotl==0.4.1)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl@ git+https://github.com/huggingface/trl.git@f18253bf2d747f68acc9cd89da95c85ebf59dbb9->axolotl==0.4.1)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum==1.16.2->axolotl==0.4.1)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting anyio (from httpx->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sniffio (from httpx->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib->gcsfs->axolotl==0.4.1)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.6.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_crc32c-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting wavedrom (from markdown2[all]->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.7/137.7 kB 17.9 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Collecting httpcore==1.* (from httpx->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sniffio (from httpx->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib->gcsfs->axolotl==0.4.1)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.6.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading google_crc32c-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting wavedrom (from markdown2[all]->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.7/137.7 kB 17.0 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting typer>=0.12.3 (from fastapi-cli>=0.0.2->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->axolotl==0.4.1)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs->axolotl==0.4.1) (0.6.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->axolotl==0.4.1)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading watchfiles-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting svgwrite (from wavedrom->markdown2[all]->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.50.2->axolotl==0.4.1) (1.5.4)\n",
      "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->optimum==1.16.2->axolotl==0.4.1) (1.3.0)\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->optimum==1.16.2->axolotl==0.4.1) (1.3.0)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting typer>=0.12.3 (from fastapi-cli>=0.0.2->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->axolotl==0.4.1)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs->axolotl==0.4.1) (0.6.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->axolotl==0.4.1)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.8/119.8 MB 19.8 MB/s eta 0:00:00\n",
      "Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting typer>=0.12.3 (from fastapi-cli>=0.0.2->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->axolotl==0.4.1)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs->axolotl==0.4.1)\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.4.1) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs->axolotl==0.4.1) (0.6.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->axolotl==0.4.1)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading watchfiles-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting svgwrite (from wavedrom->markdown2[all]->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.50.2->axolotl==0.4.1) (1.5.4)\n",
      "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.50.2->axolotl==0.4.1)\n",
      "Downloading watchfiles-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting svgwrite (from wavedrom->markdown2[all]->fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe->axolotl==0.4.1)\n",
      "Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.50.2->axolotl==0.4.1) (1.5.4)\n",
      "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 542.0/542.0 kB 49.7 MB/s eta 0:00:00\n",
      "Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.1/84.1 kB 14.8 MB/s eta 0:00:00\n",
      "Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.3/20.3 MB 75.2 MB/s eta 0:00:00\n",
      "Downloading optimum-1.16.2-py3-none-any.whl (402 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 402.5/402.5 kB 47.2 MB/s eta 0:00:00\n",
      "Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 251.6/251.6 kB 34.9 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 395.2/395.2 kB 41.7 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.6/9.6 MB 85.1 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 93.4 MB/s eta 0:00:00\n",
      "Downloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.3/9.3 MB 105.1 MB/s eta 0:00:00\n",
      "Downloading xformers-0.0.26.post1-cp311-cp311-manylinux2014_x86_64.whl (222.8 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 84.6 MB/s eta 0:00:00\n",
      "Downloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.3/9.3 MB 100.9 MB/s eta 0:00:00\n",
      "Downloading xformers-0.0.26.post1-cp311-cp311-manylinux2014_x86_64.whl (222.8 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.8/119.8 MB 20.6 MB/s eta 0:00:00\n",
      "Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 542.0/542.0 kB 54.6 MB/s eta 0:00:00\n",
      "Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.1/84.1 kB 15.7 MB/s eta 0:00:00\n",
      "Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.8/119.8 MB 16.8 MB/s eta 0:00:00\n",
      "Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 542.0/542.0 kB 31.0 MB/s eta 0:00:00\n",
      "Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.1/84.1 kB 14.4 MB/s eta 0:00:00\n",
      "Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.3/20.3 MB 65.7 MB/s eta 0:00:00\n",
      "Downloading optimum-1.16.2-py3-none-any.whl (402 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 402.5/402.5 kB 32.2 MB/s eta 0:00:00\n",
      "Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 251.6/251.6 kB 31.9 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 395.2/395.2 kB 31.8 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.3/20.3 MB 79.9 MB/s eta 0:00:00\n",
      "Downloading optimum-1.16.2-py3-none-any.whl (402 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 402.5/402.5 kB 49.9 MB/s eta 0:00:00\n",
      "Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 251.6/251.6 kB 35.1 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 395.2/395.2 kB 51.2 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.6/9.6 MB 101.5 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 92.7 MB/s eta 0:00:00\n",
      "Downloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.3/9.3 MB 97.4 MB/s eta 0:00:00\n",
      "Downloading xformers-0.0.26.post1-cp311-cp311-manylinux2014_x86_64.whl (222.8 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.6/9.6 MB 88.4 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 84.1 MB/s eta 0:00:00\n",
      "Downloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.3/9.3 MB 88.9 MB/s eta 0:00:00\n",
      "Downloading xformers-0.0.26.post1-cp311-cp311-manylinux2014_x86_64.whl (222.8 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 222.8/222.8 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading zstandard-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 102.2 MB/s eta 0:00:00\n",
      "Downloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 299.2/299.2 kB 36.8 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 86.3 MB/s eta 0:00:00\n",
      "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Downloading art-6.2-py3-none-any.whl (601 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 601.8/601.8 kB 58.5 MB/s eta 0:00:00\n",
      "Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl (44.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 222.8/222.8 MB 10.5 MB/s eta 0:00:00\n",
      "Downloading zstandard-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 106.4 MB/s eta 0:00:00\n",
      "Downloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 299.2/299.2 kB 45.5 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 96.8 MB/s eta 0:00:00\n",
      "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Downloading art-6.2-py3-none-any.whl (601 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 601.8/601.8 kB 63.6 MB/s eta 0:00:00\n",
      "Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl (44.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.5/44.5 MB 54.3 MB/s eta 0:00:00\n",
      "Downloading gcsfs-2024.3.1-py2.py3-none-any.whl (34 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 172.0/172.0 kB 31.2 MB/s eta 0:00:00\n",
      "Downloading hf_transfer-0.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.5/44.5 MB 41.8 MB/s eta 0:00:00\n",
      "Downloading gcsfs-2024.3.1-py2.py3-none-any.whl (34 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 172.0/172.0 kB 27.0 MB/s eta 0:00:00\n",
      "Downloading hf_transfer-0.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 90.8 MB/s eta 0:00:00\n",
      "Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 71.5 MB/s eta 0:00:00\n",
      "Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 95.8 MB/s eta 0:00:00\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 70.1 MB/s eta 0:00:00\n",
      "Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 857.8/857.8 kB 66.0 MB/s eta 0:00:00\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.3/207.3 kB 28.3 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.31.0-py2.py3-none-any.whl (194 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.6/194.6 kB 25.1 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 402.6/402.6 kB 43.7 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading orjson-3.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141.1/141.1 kB 22.0 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 785.0/785.0 kB 58.9 MB/s eta 0:00:00\n",
      "Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading sentry_sdk-2.8.0-py2.py3-none-any.whl (300 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.6/300.6 kB 36.7 MB/s eta 0:00:00\n",
      "Downloading tyro-0.8.5-py3-none-any.whl (103 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.4/103.4 kB 17.5 MB/s eta 0:00:00\n",
      "Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.4/62.4 kB 12.5 MB/s eta 0:00:00\n",
      "Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.6/130.6 kB 20.9 MB/s eta 0:00:00\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 7.8 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.0/92.0 kB 16.5 MB/s eta 0:00:00\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.6/75.6 kB 11.8 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.9/77.9 kB 11.9 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 19.7 MB/s eta 0:00:00\n",
      "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.0/54.0 kB 8.0 MB/s eta 0:00:00\n",
      "Downloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 769.2/769.2 kB 63.0 MB/s eta 0:00:00\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 69.8 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.8/194.8 kB 27.0 MB/s eta 0:00:00\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 272.3/272.3 kB 33.6 MB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 11.7 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 98.7 MB/s eta 0:00:00\n",
      "Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 11.3 MB/s eta 0:00:00\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 83.5 MB/s eta 0:00:00\n",
      "Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 104.2 MB/s eta 0:00:00\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 78.6 MB/s eta 0:00:00\n",
      "Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 857.8/857.8 kB 75.4 MB/s eta 0:00:00\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.3/207.3 kB 36.7 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.31.0-py2.py3-none-any.whl (194 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.6/194.6 kB 29.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 402.6/402.6 kB 50.3 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading orjson-3.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141.1/141.1 kB 26.9 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 785.0/785.0 kB 70.0 MB/s eta 0:00:00\n",
      "Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading sentry_sdk-2.8.0-py2.py3-none-any.whl (300 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.6/300.6 kB 41.0 MB/s eta 0:00:00\n",
      "Downloading tyro-0.8.5-py3-none-any.whl (103 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.4/103.4 kB 19.7 MB/s eta 0:00:00\n",
      "Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.4/62.4 kB 11.9 MB/s eta 0:00:00\n",
      "Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.6/130.6 kB 22.6 MB/s eta 0:00:00\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 8.8 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.0/92.0 kB 19.3 MB/s eta 0:00:00\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.6/75.6 kB 15.5 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.9/77.9 kB 15.9 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 23.1 MB/s eta 0:00:00\n",
      "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.0/54.0 kB 11.2 MB/s eta 0:00:00\n",
      "Downloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 769.2/769.2 kB 69.8 MB/s eta 0:00:00\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 77.5 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.8/194.8 kB 32.8 MB/s eta 0:00:00\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 272.3/272.3 kB 42.6 MB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 13.9 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.4/139.4 kB 27.6 MB/s eta 0:00:00\n",
      "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl (81 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.2/81.2 kB 15.8 MB/s eta 0:00:00\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 11.3 MB/s eta 0:00:00\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 16.5 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.7/128.7 kB 26.0 MB/s eta 0:00:00\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.2/181.2 kB 27.9 MB/s eta 0:00:00\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.9/71.9 kB 14.0 MB/s eta 0:00:00\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 17.5 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.6/53.6 kB 10.6 MB/s eta 0:00:00\n",
      "Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 328.1/328.1 kB 47.0 MB/s eta 0:00:00\n",
      "Downloading markdown2-2.4.13-py2.py3-none-any.whl (41 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.3/41.3 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.1/56.1 kB 12.1 MB/s eta 0:00:00\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.7/307.7 kB 42.0 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 220.0/220.0 kB 34.5 MB/s eta 0:00:00\n",
      "Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 318.5/318.5 kB 48.1 MB/s eta 0:00:00\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 27.4 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.1/50.1 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.2/47.2 kB 10.3 MB/s eta 0:00:00\n",
      "Downloading uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 105.0 MB/s eta 0:00:00\n",
      "Downloading watchfiles-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 82.0 MB/s eta 0:00:00\n",
      "Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.1/67.1 kB 12.5 MB/s eta 0:00:00\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 222.8/222.8 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading zstandard-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 96.5 MB/s eta 0:00:00\n",
      "Downloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 299.2/299.2 kB 38.6 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 84.9 MB/s eta 0:00:00\n",
      "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Downloading art-6.2-py3-none-any.whl (601 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 601.8/601.8 kB 52.7 MB/s eta 0:00:00\n",
      "Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl (44.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 222.8/222.8 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading zstandard-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 89.1 MB/s eta 0:00:00\n",
      "Downloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 299.2/299.2 kB 26.6 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 77.5 MB/s eta 0:00:00\n",
      "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Downloading art-6.2-py3-none-any.whl (601 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 601.8/601.8 kB 54.5 MB/s eta 0:00:00\n",
      "Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl (44.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.4/139.4 kB 20.5 MB/s eta 0:00:00\n",
      "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl (81 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.2/81.2 kB 14.1 MB/s eta 0:00:00\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 10.3 MB/s eta 0:00:00\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 13.6 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.7/128.7 kB 17.8 MB/s eta 0:00:00\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.2/181.2 kB 23.8 MB/s eta 0:00:00\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.9/71.9 kB 14.5 MB/s eta 0:00:00\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 14.6 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.6/53.6 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 328.1/328.1 kB 36.7 MB/s eta 0:00:00\n",
      "Downloading markdown2-2.4.13-py2.py3-none-any.whl (41 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.3/41.3 kB 6.5 MB/s eta 0:00:00\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.1/56.1 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.7/307.7 kB 36.0 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 220.0/220.0 kB 30.1 MB/s eta 0:00:00\n",
      "Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 318.5/318.5 kB 39.1 MB/s eta 0:00:00\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 25.3 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.1/50.1 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.2/47.2 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 78.2 MB/s eta 0:00:00\n",
      "Downloading watchfiles-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 64.9 MB/s eta 0:00:00\n",
      "Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.1/67.1 kB 11.6 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: flash-attn, deepspeed, fire, fschat, trl, ffmpy, wavedrom\n",
      "Building wheel for flash-attn (setup.py): started\n",
      "Building wheels for collected packages: flash-attn, deepspeed, fire, fschat, trl, ffmpy, wavedrom\n",
      "Building wheel for flash-attn (setup.py): started\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.5/44.5 MB 47.4 MB/s eta 0:00:00\n",
      "Downloading gcsfs-2024.3.1-py2.py3-none-any.whl (34 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 172.0/172.0 kB 27.5 MB/s eta 0:00:00\n",
      "Downloading hf_transfer-0.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 104.5 MB/s eta 0:00:00\n",
      "Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 9.6 MB/s eta 0:00:00\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 76.5 MB/s eta 0:00:00\n",
      "Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 105.7 MB/s eta 0:00:00\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 78.5 MB/s eta 0:00:00\n",
      "Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 857.8/857.8 kB 17.9 MB/s eta 0:00:00\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.3/207.3 kB 31.5 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.31.0-py2.py3-none-any.whl (194 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.6/194.6 kB 27.0 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 402.6/402.6 kB 47.2 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading orjson-3.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141.1/141.1 kB 24.7 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 785.0/785.0 kB 67.4 MB/s eta 0:00:00\n",
      "Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading sentry_sdk-2.8.0-py2.py3-none-any.whl (300 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.6/300.6 kB 39.1 MB/s eta 0:00:00\n",
      "Downloading tyro-0.8.5-py3-none-any.whl (103 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.4/103.4 kB 19.6 MB/s eta 0:00:00\n",
      "Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.4/62.4 kB 11.1 MB/s eta 0:00:00\n",
      "Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.6/130.6 kB 24.5 MB/s eta 0:00:00\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.0/92.0 kB 17.6 MB/s eta 0:00:00\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.6/75.6 kB 11.8 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.9/77.9 kB 15.1 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 24.6 MB/s eta 0:00:00\n",
      "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.0/54.0 kB 8.7 MB/s eta 0:00:00\n",
      "Downloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 769.2/769.2 kB 66.7 MB/s eta 0:00:00\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 74.0 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.8/194.8 kB 29.3 MB/s eta 0:00:00\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 272.3/272.3 kB 38.1 MB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 12.7 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.4/139.4 kB 23.3 MB/s eta 0:00:00\n",
      "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl (81 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.2/81.2 kB 16.0 MB/s eta 0:00:00\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 11.1 MB/s eta 0:00:00\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 16.4 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.7/128.7 kB 22.2 MB/s eta 0:00:00\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.2/181.2 kB 29.5 MB/s eta 0:00:00\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.9/71.9 kB 12.4 MB/s eta 0:00:00\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 17.3 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.6/53.6 kB 7.1 MB/s eta 0:00:00\n",
      "Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.5/44.5 MB 36.0 MB/s eta 0:00:00\n",
      "Downloading gcsfs-2024.3.1-py2.py3-none-any.whl (34 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 172.0/172.0 kB 16.0 MB/s eta 0:00:00\n",
      "Downloading hf_transfer-0.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 85.5 MB/s eta 0:00:00\n",
      "Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 8.8 MB/s eta 0:00:00\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 62.7 MB/s eta 0:00:00\n",
      "Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 80.8 MB/s eta 0:00:00\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 50.7 MB/s eta 0:00:00\n",
      "Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 857.8/857.8 kB 51.5 MB/s eta 0:00:00\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.3/207.3 kB 25.6 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.31.0-py2.py3-none-any.whl (194 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.6/194.6 kB 20.5 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 402.6/402.6 kB 29.9 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading orjson-3.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141.1/141.1 kB 10.9 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 785.0/785.0 kB 46.6 MB/s eta 0:00:00\n",
      "Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading sentry_sdk-2.8.0-py2.py3-none-any.whl (300 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.6/300.6 kB 28.8 MB/s eta 0:00:00\n",
      "Downloading tyro-0.8.5-py3-none-any.whl (103 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.4/103.4 kB 12.4 MB/s eta 0:00:00\n",
      "Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.4/62.4 kB 6.6 MB/s eta 0:00:00\n",
      "Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.6/130.6 kB 14.3 MB/s eta 0:00:00\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 6.8 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.0/92.0 kB 9.8 MB/s eta 0:00:00\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.6/75.6 kB 12.3 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.9/77.9 kB 10.5 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 16.3 MB/s eta 0:00:00\n",
      "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.0/54.0 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 769.2/769.2 kB 49.6 MB/s eta 0:00:00\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 58.8 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.8/194.8 kB 24.4 MB/s eta 0:00:00\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 272.3/272.3 kB 28.2 MB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.4/139.4 kB 20.5 MB/s eta 0:00:00\n",
      "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl (81 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.2/81.2 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.7/128.7 kB 19.3 MB/s eta 0:00:00\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.2/181.2 kB 22.2 MB/s eta 0:00:00\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 328.1/328.1 kB 43.5 MB/s eta 0:00:00\n",
      "Downloading markdown2-2.4.13-py2.py3-none-any.whl (41 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.3/41.3 kB 7.3 MB/s eta 0:00:00\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.1/56.1 kB 11.5 MB/s eta 0:00:00\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.7/307.7 kB 40.1 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 220.0/220.0 kB 32.0 MB/s eta 0:00:00\n",
      "Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 318.5/318.5 kB 42.7 MB/s eta 0:00:00\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 24.3 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.1/50.1 kB 10.4 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.2/47.2 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 95.3 MB/s eta 0:00:00\n",
      "Downloading watchfiles-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 74.1 MB/s eta 0:00:00\n",
      "Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.1/67.1 kB 10.5 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: flash-attn, deepspeed, fire, fschat, trl, ffmpy, wavedrom\n",
      "Building wheel for flash-attn (setup.py): started\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.9/71.9 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 12.0 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.6/53.6 kB 7.9 MB/s eta 0:00:00\n",
      "Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 328.1/328.1 kB 30.8 MB/s eta 0:00:00\n",
      "Downloading markdown2-2.4.13-py2.py3-none-any.whl (41 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.3/41.3 kB 5.3 MB/s eta 0:00:00\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.1/56.1 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.7/307.7 kB 31.8 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 220.0/220.0 kB 24.5 MB/s eta 0:00:00\n",
      "Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 318.5/318.5 kB 28.6 MB/s eta 0:00:00\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 19.5 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.1/50.1 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.2/47.2 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 83.5 MB/s eta 0:00:00\n",
      "Downloading watchfiles-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 66.0 MB/s eta 0:00:00\n",
      "Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.1/67.1 kB 8.4 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: flash-attn, deepspeed, fire, fschat, trl, ffmpy, wavedrom\n",
      "Building wheel for flash-attn (setup.py): started\n",
      "Building wheel for flash-attn (setup.py): finished with status 'done'\n",
      "Created wheel for flash-attn: filename=flash_attn-2.5.8-cp311-cp311-linux_x86_64.whl size=120938665 sha256=0b28549d7a7105dfa9300751de038f1e607fe11bb96ac2bdd29b474926ca8e41\n",
      "Stored in directory: /root/.cache/pip/wheels/2a/88/b2/587b498e2caa887707a63d0ed7d7f4beca27f5034640382845\n",
      "Building wheel for deepspeed (setup.py): started\n",
      "Building wheel for flash-attn (setup.py): finished with status 'done'\n",
      "Created wheel for flash-attn: filename=flash_attn-2.5.8-cp311-cp311-linux_x86_64.whl size=120938665 sha256=0b28549d7a7105dfa9300751de038f1e607fe11bb96ac2bdd29b474926ca8e41\n",
      "Stored in directory: /root/.cache/pip/wheels/2a/88/b2/587b498e2caa887707a63d0ed7d7f4beca27f5034640382845\n",
      "Building wheel for deepspeed (setup.py): started\n",
      "Building wheel for flash-attn (setup.py): finished with status 'done'\n",
      "Created wheel for flash-attn: filename=flash_attn-2.5.8-cp311-cp311-linux_x86_64.whl size=120938665 sha256=0b28549d7a7105dfa9300751de038f1e607fe11bb96ac2bdd29b474926ca8e41\n",
      "Stored in directory: /root/.cache/pip/wheels/2a/88/b2/587b498e2caa887707a63d0ed7d7f4beca27f5034640382845\n",
      "Building wheel for deepspeed (setup.py): started\n",
      "Building wheel for flash-attn (setup.py): finished with status 'done'\n",
      "Created wheel for flash-attn: filename=flash_attn-2.5.8-cp311-cp311-linux_x86_64.whl size=120938665 sha256=0b28549d7a7105dfa9300751de038f1e607fe11bb96ac2bdd29b474926ca8e41\n",
      "Stored in directory: /root/.cache/pip/wheels/2a/88/b2/587b498e2caa887707a63d0ed7d7f4beca27f5034640382845\n",
      "Building wheel for deepspeed (setup.py): started\n",
      "Building wheel for deepspeed (setup.py): finished with status 'done'\n",
      "Created wheel for deepspeed: filename=deepspeed-0.14.3+bc48371c-py3-none-any.whl size=1437504 sha256=1a3f16cd088c13405da6d3c6628a41c9e2570ea206ff6c92b53d8dafca268f98\n",
      "Stored in directory: /root/.cache/pip/wheels/45/9d/89/c25118bccc39bf550d971013176e36b908f6df69f7bf8ccf65\n",
      "Building wheel for fire (setup.py): started\n",
      "Building wheel for deepspeed (setup.py): finished with status 'done'\n",
      "Created wheel for deepspeed: filename=deepspeed-0.14.3+bc48371c-py3-none-any.whl size=1437505 sha256=6b624b312bec39143e758723f4a85e67101b1d81cbcbd92f52aeb1c6a222f270\n",
      "Stored in directory: /root/.cache/pip/wheels/45/9d/89/c25118bccc39bf550d971013176e36b908f6df69f7bf8ccf65\n",
      "Building wheel for fire (setup.py): started\n",
      "Building wheel for fire (setup.py): finished with status 'done'\n",
      "Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117031 sha256=5a2d960de564bd470ae3a3b356c88f96d575e49bfa0d4735968ea960012221f9\n",
      "Stored in directory: /root/.cache/pip/wheels/6a/f3/0c/fa347dfa663f573462c6533d259c2c859e97e103d1ce21538f\n",
      "Building wheel for fschat (pyproject.toml): started\n",
      "Building wheel for fire (setup.py): finished with status 'done'\n",
      "Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117031 sha256=5a2d960de564bd470ae3a3b356c88f96d575e49bfa0d4735968ea960012221f9\n",
      "Stored in directory: /root/.cache/pip/wheels/6a/f3/0c/fa347dfa663f573462c6533d259c2c859e97e103d1ce21538f\n",
      "Building wheel for fschat (pyproject.toml): started\n",
      "Building wheel for fschat (pyproject.toml): finished with status 'done'\n",
      "Created wheel for fschat: filename=fschat-0.2.36-py3-none-any.whl size=272080 sha256=174f9135c43b40535b4c8ccba7048662b82928d808e0be74c90fd58ca5ccc8fb\n",
      "Stored in directory: /root/.cache/pip/wheels/9b/55/aa/a784e8f9fdf609b0a54c201b849bd0867f4e3bbdcd406de5c3\n",
      "Building wheel for trl (pyproject.toml): started\n",
      "Building wheel for trl (pyproject.toml): finished with status 'done'\n",
      "Created wheel for trl: filename=trl-0.8.7.dev0-py3-none-any.whl size=226579 sha256=d22ce8f064f05beb62a942c64977bcb40c0fe2f35500d851531feb8438d089df\n",
      "Stored in directory: /root/.cache/pip/wheels/c0/bd/84/5e5a612e02c792fc5eba5de08b14842abecc302fe523817980\n",
      "Building wheel for ffmpy (setup.py): started\n",
      "Building wheel for fschat (pyproject.toml): finished with status 'done'\n",
      "Created wheel for fschat: filename=fschat-0.2.36-py3-none-any.whl size=272080 sha256=174f9135c43b40535b4c8ccba7048662b82928d808e0be74c90fd58ca5ccc8fb\n",
      "Stored in directory: /root/.cache/pip/wheels/9b/55/aa/a784e8f9fdf609b0a54c201b849bd0867f4e3bbdcd406de5c3\n",
      "Building wheel for trl (pyproject.toml): started\n",
      "Building wheel for trl (pyproject.toml): finished with status 'done'\n",
      "Created wheel for trl: filename=trl-0.8.7.dev0-py3-none-any.whl size=226579 sha256=d22ce8f064f05beb62a942c64977bcb40c0fe2f35500d851531feb8438d089df\n",
      "Stored in directory: /root/.cache/pip/wheels/c0/bd/84/5e5a612e02c792fc5eba5de08b14842abecc302fe523817980\n",
      "Building wheel for ffmpy (setup.py): started\n",
      "Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=0c6c89fff3d589cf4c6a44957a777cea9cab44f416259b2822031a248a91fafe\n",
      "Stored in directory: /root/.cache/pip/wheels/55/3c/f2/f6e34046bac0d57c13c7d08123b85872423b89c8f59bafda51\n",
      "Building wheel for wavedrom (setup.py): started\n",
      "Building wheel for deepspeed (setup.py): finished with status 'done'\n",
      "Created wheel for deepspeed: filename=deepspeed-0.14.3+bc48371c-py3-none-any.whl size=1437497 sha256=5978dd953a0b45f5c8767e553477c7a671bcdd715a1aa88785849df105f7c531\n",
      "Stored in directory: /root/.cache/pip/wheels/45/9d/89/c25118bccc39bf550d971013176e36b908f6df69f7bf8ccf65\n",
      "Building wheel for fire (setup.py): started\n",
      "Building wheel for fire (setup.py): finished with status 'done'\n",
      "Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117031 sha256=5a2d960de564bd470ae3a3b356c88f96d575e49bfa0d4735968ea960012221f9\n",
      "Stored in directory: /root/.cache/pip/wheels/6a/f3/0c/fa347dfa663f573462c6533d259c2c859e97e103d1ce21538f\n",
      "Building wheel for fschat (pyproject.toml): started\n",
      "Building wheel for deepspeed (setup.py): finished with status 'done'\n",
      "Created wheel for deepspeed: filename=deepspeed-0.14.3+bc48371c-py3-none-any.whl size=1437504 sha256=41078e1758a9833d48b5a8118449e1720494cba55caf54ecd9b9e92ddf7bdd37\n",
      "Stored in directory: /root/.cache/pip/wheels/45/9d/89/c25118bccc39bf550d971013176e36b908f6df69f7bf8ccf65\n",
      "Building wheel for fire (setup.py): started\n",
      "Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=0c6c89fff3d589cf4c6a44957a777cea9cab44f416259b2822031a248a91fafe\n",
      "Stored in directory: /root/.cache/pip/wheels/55/3c/f2/f6e34046bac0d57c13c7d08123b85872423b89c8f59bafda51\n",
      "Building wheel for wavedrom (setup.py): started\n",
      "Building wheel for wavedrom (setup.py): finished with status 'done'\n",
      "Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=a71e706150f867785bf5c414c6b1fedfc620a6e3c94bf7e48eb3fd28032b61e8\n",
      "Stored in directory: /root/.cache/pip/wheels/23/cf/3b/4dcf6b22fa41c5ece715fa5f4e05afd683e7b0ce0f2fcc7bb6\n",
      "Successfully built flash-attn deepspeed fire fschat trl ffmpy wavedrom\n",
      "Building wheel for wavedrom (setup.py): finished with status 'done'\n",
      "Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=0972d6d50fb2695e99003e3e3190b543a6f3699a0cb801c8d3061e458d24cbe4\n",
      "Stored in directory: /root/.cache/pip/wheels/23/cf/3b/4dcf6b22fa41c5ece715fa5f4e05afd683e7b0ce0f2fcc7bb6\n",
      "Successfully built flash-attn deepspeed fire fschat trl ffmpy wavedrom\n",
      "Building wheel for fschat (pyproject.toml): finished with status 'done'\n",
      "Created wheel for fschat: filename=fschat-0.2.36-py3-none-any.whl size=272080 sha256=eaffc6e072fd9ebc9ebdd3976a8c739e1bc5285fb6daa3e7ebc38e647ac150be\n",
      "Stored in directory: /root/.cache/pip/wheels/9b/55/aa/a784e8f9fdf609b0a54c201b849bd0867f4e3bbdcd406de5c3\n",
      "Building wheel for trl (pyproject.toml): started\n",
      "Building wheel for trl (pyproject.toml): finished with status 'done'\n",
      "Created wheel for trl: filename=trl-0.8.7.dev0-py3-none-any.whl size=226579 sha256=202f1ddbd57ea3b158bb3a52e215f7c8799965d94765e558c0d8cab58421522b\n",
      "Stored in directory: /root/.cache/pip/wheels/c0/bd/84/5e5a612e02c792fc5eba5de08b14842abecc302fe523817980\n",
      "Building wheel for ffmpy (setup.py): started\n",
      "Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=672bab28f9ce3c1b4459d6d78e6132bff8e136db6d5c4ed11f73b550238c88cd\n",
      "Stored in directory: /root/.cache/pip/wheels/55/3c/f2/f6e34046bac0d57c13c7d08123b85872423b89c8f59bafda51\n",
      "Building wheel for wavedrom (setup.py): started\n",
      "Building wheel for fire (setup.py): finished with status 'done'\n",
      "Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117031 sha256=d63c696f0206c0ac43cee0a49c50f7b0392b9c6ce1b0051234c2ad1d67284b84\n",
      "Stored in directory: /root/.cache/pip/wheels/6a/f3/0c/fa347dfa663f573462c6533d259c2c859e97e103d1ce21538f\n",
      "Building wheel for fschat (pyproject.toml): started\n",
      "Building wheel for fschat (pyproject.toml): finished with status 'done'\n",
      "Created wheel for fschat: filename=fschat-0.2.36-py3-none-any.whl size=272080 sha256=9eaf87e0bc6d6888a48b037e9fc5b108f4be0b56360ef677fa00abd0a8140736\n",
      "Stored in directory: /root/.cache/pip/wheels/9b/55/aa/a784e8f9fdf609b0a54c201b849bd0867f4e3bbdcd406de5c3\n",
      "Building wheel for trl (pyproject.toml): started\n",
      "Building wheel for trl (pyproject.toml): finished with status 'done'\n",
      "Created wheel for trl: filename=trl-0.8.7.dev0-py3-none-any.whl size=226579 sha256=9d835ca4e97420e7341e14006bafbbf7f5f0e0a28000ea7cc0c221abe9729d7e\n",
      "Stored in directory: /root/.cache/pip/wheels/c0/bd/84/5e5a612e02c792fc5eba5de08b14842abecc302fe523817980\n",
      "Building wheel for ffmpy (setup.py): started\n",
      "Installing collected packages: sentencepiece, pydub, py-cpuinfo, nh3, hjson, ffmpy, addict, zstandard, xxhash, websockets, uvloop, ujson, toolz, termcolor, svgwrite, sniffio, smmap, shtab, shortuuid, setproctitle, sentry-sdk, semantic-version, regex, python-multipart, python-dotenv, pynvml, pydantic-core, pyasn1-modules, pyarrow-hotfix, proto-plus, orjson, oauthlib, multidict, markdown2, importlib-resources, humanfriendly, httptools, hf_transfer, h11, googleapis-common-protos, google-crc32c, fsspec, frozenlist, docstring-parser, docker-pycreds, dnspython, deepspeed-kernels, cachetools, art, aiofiles, yarl, wavedrom, uvicorn, tiktoken, scikit-learn, responses, requests-oauthlib, pydantic, huggingface-hub, httpcore, google-resumable-media, google-auth, gitdb, fire, email_validator, coloredlogs, anyio, aiosignal, xformers, watchfiles, tyro, typer, tokenizers, starlette, httpx, google-auth-oauthlib, google-api-core, gitpython, flash-attn, deepspeed, bitsandbytes, aiohttp, wandb, transformers, gradio-client, google-cloud-core, fastapi-cli, altair, peft, google-cloud-storage, fastapi, datasets, trl, optimum, gradio, gcsfs, fschat, evaluate, axolotl\n",
      "Attempting uninstall: zstandard\n",
      "Found existing installation: zstandard 0.19.0\n",
      "Uninstalling zstandard-0.19.0:\n",
      "Successfully uninstalled zstandard-0.19.0\n",
      "Installing collected packages: sentencepiece, pydub, py-cpuinfo, nh3, hjson, ffmpy, addict, zstandard, xxhash, websockets, uvloop, ujson, toolz, termcolor, svgwrite, sniffio, smmap, shtab, shortuuid, setproctitle, sentry-sdk, semantic-version, regex, python-multipart, python-dotenv, pynvml, pydantic-core, pyasn1-modules, pyarrow-hotfix, proto-plus, orjson, oauthlib, multidict, markdown2, importlib-resources, humanfriendly, httptools, hf_transfer, h11, googleapis-common-protos, google-crc32c, fsspec, frozenlist, docstring-parser, docker-pycreds, dnspython, deepspeed-kernels, cachetools, art, aiofiles, yarl, wavedrom, uvicorn, tiktoken, scikit-learn, responses, requests-oauthlib, pydantic, huggingface-hub, httpcore, google-resumable-media, google-auth, gitdb, fire, email_validator, coloredlogs, anyio, aiosignal, xformers, watchfiles, tyro, typer, tokenizers, starlette, httpx, google-auth-oauthlib, google-api-core, gitpython, flash-attn, deepspeed, bitsandbytes, aiohttp, wandb, transformers, gradio-client, google-cloud-core, fastapi-cli, altair, peft, google-cloud-storage, fastapi, datasets, trl, optimum, gradio, gcsfs, fschat, evaluate, axolotl\n",
      "Attempting uninstall: zstandard\n",
      "Found existing installation: zstandard 0.19.0\n",
      "Uninstalling zstandard-0.19.0:\n",
      "Successfully uninstalled zstandard-0.19.0\n",
      "Building wheel for wavedrom (setup.py): finished with status 'done'\n",
      "Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=48bdc117adf87394dbdb7627a9621146a5b2ea9da79ae053b890f1855a1ed27b\n",
      "Stored in directory: /root/.cache/pip/wheels/23/cf/3b/4dcf6b22fa41c5ece715fa5f4e05afd683e7b0ce0f2fcc7bb6\n",
      "Successfully built flash-attn deepspeed fire fschat trl ffmpy wavedrom\n",
      "Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=672bab28f9ce3c1b4459d6d78e6132bff8e136db6d5c4ed11f73b550238c88cd\n",
      "Stored in directory: /root/.cache/pip/wheels/55/3c/f2/f6e34046bac0d57c13c7d08123b85872423b89c8f59bafda51\n",
      "Building wheel for wavedrom (setup.py): started\n",
      "Building wheel for wavedrom (setup.py): finished with status 'done'\n",
      "Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=e6a7477311b683f6b6c7fd76166938ebe02856c1cad42ba764544bcbdebd9b22\n",
      "Stored in directory: /root/.cache/pip/wheels/23/cf/3b/4dcf6b22fa41c5ece715fa5f4e05afd683e7b0ce0f2fcc7bb6\n",
      "Successfully built flash-attn deepspeed fire fschat trl ffmpy wavedrom\n",
      "Attempting uninstall: pydantic-core\n",
      "Found existing installation: pydantic_core 2.18.2\n",
      "Uninstalling pydantic_core-2.18.2:\n",
      "Successfully uninstalled pydantic_core-2.18.2\n",
      "Attempting uninstall: pydantic-core\n",
      "Found existing installation: pydantic_core 2.18.2\n",
      "Uninstalling pydantic_core-2.18.2:\n",
      "Successfully uninstalled pydantic_core-2.18.2\n",
      "Attempting uninstall: fsspec\n",
      "Found existing installation: fsspec 2024.5.0\n",
      "Uninstalling fsspec-2024.5.0:\n",
      "Successfully uninstalled fsspec-2024.5.0\n",
      "Installing collected packages: sentencepiece, pydub, py-cpuinfo, nh3, hjson, ffmpy, addict, zstandard, xxhash, websockets, uvloop, ujson, toolz, termcolor, svgwrite, sniffio, smmap, shtab, shortuuid, setproctitle, sentry-sdk, semantic-version, regex, python-multipart, python-dotenv, pynvml, pydantic-core, pyasn1-modules, pyarrow-hotfix, proto-plus, orjson, oauthlib, multidict, markdown2, importlib-resources, humanfriendly, httptools, hf_transfer, h11, googleapis-common-protos, google-crc32c, fsspec, frozenlist, docstring-parser, docker-pycreds, dnspython, deepspeed-kernels, cachetools, art, aiofiles, yarl, wavedrom, uvicorn, tiktoken, scikit-learn, responses, requests-oauthlib, pydantic, huggingface-hub, httpcore, google-resumable-media, google-auth, gitdb, fire, email_validator, coloredlogs, anyio, aiosignal, xformers, watchfiles, tyro, typer, tokenizers, starlette, httpx, google-auth-oauthlib, google-api-core, gitpython, flash-attn, deepspeed, bitsandbytes, aiohttp, wandb, transformers, gradio-client, google-cloud-core, fastapi-cli, altair, peft, google-cloud-storage, fastapi, datasets, trl, optimum, gradio, gcsfs, fschat, evaluate, axolotl\n",
      "Attempting uninstall: zstandard\n",
      "Found existing installation: zstandard 0.19.0\n",
      "Uninstalling zstandard-0.19.0:\n",
      "Successfully uninstalled zstandard-0.19.0\n",
      "Installing collected packages: sentencepiece, pydub, py-cpuinfo, nh3, hjson, ffmpy, addict, zstandard, xxhash, websockets, uvloop, ujson, toolz, termcolor, svgwrite, sniffio, smmap, shtab, shortuuid, setproctitle, sentry-sdk, semantic-version, regex, python-multipart, python-dotenv, pynvml, pydantic-core, pyasn1-modules, pyarrow-hotfix, proto-plus, orjson, oauthlib, multidict, markdown2, importlib-resources, humanfriendly, httptools, hf_transfer, h11, googleapis-common-protos, google-crc32c, fsspec, frozenlist, docstring-parser, docker-pycreds, dnspython, deepspeed-kernels, cachetools, art, aiofiles, yarl, wavedrom, uvicorn, tiktoken, scikit-learn, responses, requests-oauthlib, pydantic, huggingface-hub, httpcore, google-resumable-media, google-auth, gitdb, fire, email_validator, coloredlogs, anyio, aiosignal, xformers, watchfiles, tyro, typer, tokenizers, starlette, httpx, google-auth-oauthlib, google-api-core, gitpython, flash-attn, deepspeed, bitsandbytes, aiohttp, wandb, transformers, gradio-client, google-cloud-core, fastapi-cli, altair, peft, google-cloud-storage, fastapi, datasets, trl, optimum, gradio, gcsfs, fschat, evaluate, axolotl\n",
      "Attempting uninstall: zstandard\n",
      "Found existing installation: zstandard 0.19.0\n",
      "Uninstalling zstandard-0.19.0:\n",
      "Successfully uninstalled zstandard-0.19.0\n",
      "Attempting uninstall: fsspec\n",
      "Found existing installation: fsspec 2024.5.0\n",
      "Uninstalling fsspec-2024.5.0:\n",
      "Successfully uninstalled fsspec-2024.5.0\n",
      "Attempting uninstall: pydantic-core\n",
      "Found existing installation: pydantic_core 2.18.2\n",
      "Uninstalling pydantic_core-2.18.2:\n",
      "Successfully uninstalled pydantic_core-2.18.2\n",
      "Attempting uninstall: fsspec\n",
      "Found existing installation: fsspec 2024.5.0\n",
      "Uninstalling fsspec-2024.5.0:\n",
      "Attempting uninstall: pydantic-core\n",
      "Found existing installation: pydantic_core 2.18.2\n",
      "Uninstalling pydantic_core-2.18.2:\n",
      "Successfully uninstalled pydantic_core-2.18.2\n",
      "Attempting uninstall: scikit-learn\n",
      "Attempting uninstall: scikit-learn\n",
      "Found existing installation: scikit-learn 1.5.0\n",
      "Uninstalling scikit-learn-1.5.0:\n",
      "Successfully uninstalled scikit-learn-1.5.0\n",
      "Successfully uninstalled fsspec-2024.5.0\n",
      "Attempting uninstall: fsspec\n",
      "Found existing installation: fsspec 2024.5.0\n",
      "Uninstalling fsspec-2024.5.0:\n",
      "Successfully uninstalled fsspec-2024.5.0\n",
      "Attempting uninstall: scikit-learn\n",
      "Found existing installation: scikit-learn 1.5.0\n",
      "Uninstalling scikit-learn-1.5.0:\n",
      "Found existing installation: scikit-learn 1.5.0\n",
      "Uninstalling scikit-learn-1.5.0:\n",
      "Successfully uninstalled scikit-learn-1.5.0\n",
      "Attempting uninstall: pydantic\n",
      "Found existing installation: pydantic 2.7.1\n",
      "Uninstalling pydantic-2.7.1:\n",
      "Successfully uninstalled pydantic-2.7.1\n",
      "Attempting uninstall: huggingface-hub\n",
      "Found existing installation: huggingface_hub 0.23.0\n",
      "Uninstalling huggingface_hub-0.23.0:\n",
      "Successfully uninstalled huggingface_hub-0.23.0\n",
      "Successfully uninstalled scikit-learn-1.5.0\n",
      "Attempting uninstall: scikit-learn\n",
      "Found existing installation: scikit-learn 1.5.0\n",
      "Uninstalling scikit-learn-1.5.0:\n",
      "Successfully uninstalled scikit-learn-1.5.0\n",
      "Attempting uninstall: pydantic\n",
      "Found existing installation: pydantic 2.7.1\n",
      "Uninstalling pydantic-2.7.1:\n",
      "Successfully uninstalled pydantic-2.7.1\n",
      "Attempting uninstall: huggingface-hub\n",
      "Found existing installation: huggingface_hub 0.23.0\n",
      "Uninstalling huggingface_hub-0.23.0:\n",
      "Successfully uninstalled huggingface_hub-0.23.0\n",
      "Attempting uninstall: pydantic\n",
      "Found existing installation: pydantic 2.7.1\n",
      "Uninstalling pydantic-2.7.1:\n",
      "Successfully uninstalled pydantic-2.7.1\n",
      "Attempting uninstall: huggingface-hub\n",
      "Found existing installation: huggingface_hub 0.23.0\n",
      "Uninstalling huggingface_hub-0.23.0:\n",
      "Successfully uninstalled huggingface_hub-0.23.0\n",
      "Attempting uninstall: pydantic\n",
      "Found existing installation: pydantic 2.7.1\n",
      "Uninstalling pydantic-2.7.1:\n",
      "Successfully uninstalled pydantic-2.7.1\n",
      "Attempting uninstall: huggingface-hub\n",
      "Found existing installation: huggingface_hub 0.23.0\n",
      "Uninstalling huggingface_hub-0.23.0:\n",
      "Successfully uninstalled huggingface_hub-0.23.0\n",
      "Attempting uninstall: typer\n",
      "Found existing installation: typer 0.9.4\n",
      "Uninstalling typer-0.9.4:\n",
      "Successfully uninstalled typer-0.9.4\n",
      "Attempting uninstall: flash-attn\n",
      "Attempting uninstall: typer\n",
      "Found existing installation: typer 0.9.4\n",
      "Uninstalling typer-0.9.4:\n",
      "Successfully uninstalled typer-0.9.4\n",
      "Attempting uninstall: flash-attn\n",
      "Found existing installation: flash-attn 2.0.4\n",
      "Uninstalling flash-attn-2.0.4:\n",
      "Found existing installation: flash-attn 2.0.4\n",
      "Uninstalling flash-attn-2.0.4:\n",
      "Successfully uninstalled flash-attn-2.0.4\n",
      "Attempting uninstall: typer\n",
      "Found existing installation: typer 0.9.4\n",
      "Uninstalling typer-0.9.4:\n",
      "Successfully uninstalled typer-0.9.4\n",
      "Successfully uninstalled flash-attn-2.0.4\n",
      "Attempting uninstall: flash-attn\n",
      "Found existing installation: flash-attn 2.0.4\n",
      "Uninstalling flash-attn-2.0.4:\n",
      "Attempting uninstall: typer\n",
      "Found existing installation: typer 0.9.4\n",
      "Uninstalling typer-0.9.4:\n",
      "Successfully uninstalled typer-0.9.4\n",
      "Attempting uninstall: flash-attn\n",
      "Found existing installation: flash-attn 2.0.4\n",
      "Uninstalling flash-attn-2.0.4:\n",
      "Successfully uninstalled flash-attn-2.0.4\n",
      "Successfully uninstalled flash-attn-2.0.4\n",
      "Running setup.py develop for axolotl\n",
      "Running setup.py develop for axolotl\n",
      "Running setup.py develop for axolotl\n",
      "Running setup.py develop for axolotl\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformer-engine 0.12.0+170797 requires flash-attn<=2.0.4,>=1.0.6, but you have flash-attn 2.5.8 which is incompatible.\n",
      "spacy 3.7.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "Successfully installed addict-2.4.0 aiofiles-23.2.1 aiohttp-3.9.5 aiosignal-1.3.1 altair-5.3.0 anyio-4.4.0 art-6.2 axolotl-0.4.1 bitsandbytes-0.43.1 cachetools-5.3.3 coloredlogs-15.0.1 datasets-2.19.1 deepspeed-0.14.3+bc48371c deepspeed-kernels-0.0.1.dev1698255861 dnspython-2.6.1 docker-pycreds-0.4.0 docstring-parser-0.16 email_validator-2.2.0 evaluate-0.4.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 fire-0.6.0 flash-attn-2.5.8 frozenlist-1.4.1 fschat-0.2.36 fsspec-2024.3.1 gcsfs-2024.3.1 gitdb-4.0.11 gitpython-3.1.43 google-api-core-2.19.1 google-auth-2.31.0 google-auth-oauthlib-1.2.0 google-cloud-core-2.4.1 google-cloud-storage-2.17.0 google-crc32c-1.5.0 google-resumable-media-2.7.1 googleapis-common-protos-1.63.2 gradio-3.50.2 gradio-client-0.6.1 h11-0.14.0 hf_transfer-0.1.6 hjson-3.1.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 huggingface-hub-0.23.4 humanfriendly-10.0 importlib-resources-6.4.0 markdown2-2.4.13 multidict-6.0.5 nh3-0.2.18 oauthlib-3.2.2 optimum-1.16.2 orjson-3.10.6 peft-0.11.1 proto-plus-1.24.0 py-cpuinfo-9.0.0 pyarrow-hotfix-0.6 pyasn1-modules-0.4.0 pydantic-2.6.3 pydantic-core-2.16.3 pydub-0.25.1 pynvml-11.5.0 python-dotenv-1.0.1 python-multipart-0.0.9 regex-2024.5.15 requests-oauthlib-2.0.0 responses-0.18.0 scikit-learn-1.2.2 semantic-version-2.10.0 sentencepiece-0.2.0 sentry-sdk-2.8.0 setproctitle-1.3.3 shortuuid-1.0.13 shtab-1.7.1 smmap-5.0.1 sniffio-1.3.1 starlette-0.37.2 svgwrite-1.4.3 termcolor-2.4.0 tiktoken-0.7.0 tokenizers-0.19.1 toolz-0.12.1 transformers-4.42.3 trl-0.8.7.dev0 typer-0.12.3 tyro-0.8.5 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 wandb-0.17.4 watchfiles-0.22.0 wavedrom-2.0.3.post3 websockets-11.0.3 xformers-0.0.26.post1 xxhash-3.4.1 yarl-1.9.4 zstandard-0.22.0\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformer-engine 0.12.0+170797 requires flash-attn<=2.0.4,>=1.0.6, but you have flash-attn 2.5.8 which is incompatible.\n",
      "spacy 3.7.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "Successfully installed addict-2.4.0 aiofiles-23.2.1 aiohttp-3.9.5 aiosignal-1.3.1 altair-5.3.0 anyio-4.4.0 art-6.2 axolotl-0.4.1 bitsandbytes-0.43.1 cachetools-5.3.3 coloredlogs-15.0.1 datasets-2.19.1 deepspeed-0.14.3+bc48371c deepspeed-kernels-0.0.1.dev1698255861 dnspython-2.6.1 docker-pycreds-0.4.0 docstring-parser-0.16 email_validator-2.2.0 evaluate-0.4.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 fire-0.6.0 flash-attn-2.5.8 frozenlist-1.4.1 fschat-0.2.36 fsspec-2024.3.1 gcsfs-2024.3.1 gitdb-4.0.11 gitpython-3.1.43 google-api-core-2.19.1 google-auth-2.31.0 google-auth-oauthlib-1.2.0 google-cloud-core-2.4.1 google-cloud-storage-2.17.0 google-crc32c-1.5.0 google-resumable-media-2.7.1 googleapis-common-protos-1.63.2 gradio-3.50.2 gradio-client-0.6.1 h11-0.14.0 hf_transfer-0.1.6 hjson-3.1.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 huggingface-hub-0.23.4 humanfriendly-10.0 importlib-resources-6.4.0 markdown2-2.4.13 multidict-6.0.5 nh3-0.2.18 oauthlib-3.2.2 optimum-1.16.2 orjson-3.10.6 peft-0.11.1 proto-plus-1.24.0 py-cpuinfo-9.0.0 pyarrow-hotfix-0.6 pyasn1-modules-0.4.0 pydantic-2.6.3 pydantic-core-2.16.3 pydub-0.25.1 pynvml-11.5.0 python-dotenv-1.0.1 python-multipart-0.0.9 regex-2024.5.15 requests-oauthlib-2.0.0 responses-0.18.0 scikit-learn-1.2.2 semantic-version-2.10.0 sentencepiece-0.2.0 sentry-sdk-2.8.0 setproctitle-1.3.3 shortuuid-1.0.13 shtab-1.7.1 smmap-5.0.1 sniffio-1.3.1 starlette-0.37.2 svgwrite-1.4.3 termcolor-2.4.0 tiktoken-0.7.0 tokenizers-0.19.1 toolz-0.12.1 transformers-4.42.3 trl-0.8.7.dev0 typer-0.12.3 tyro-0.8.5 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 wandb-0.17.4 watchfiles-0.22.0 wavedrom-2.0.3.post3 websockets-11.0.3 xformers-0.0.26.post1 xxhash-3.4.1 yarl-1.9.4 zstandard-0.22.0\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "2024-07-08 18:10:43,941 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-07-08 18:10:43,941 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-07-08 18:10:43,984 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:10:44,013 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:10:44,025 sagemaker-training-toolkit INFO     Starting distributed training through torchrun\n",
      "2024-07-08 18:10:44,042 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:10:44,054 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"sagemaker_torch_distributed_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-3\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config\": \"qlora.yml\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-3\",\n",
      "                \"algo-4\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"pytorch-training-2024-07-08-18-02-56-581\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-07-08-18-02-56-581/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"axolotl/src/axolotl/cli/train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-3\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\",\n",
      "            \"algo-4\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-3\",\n",
      "                    \"algo-4\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"axolotl/src/axolotl/cli/train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"config\":\"qlora.yml\"}\n",
      "SM_USER_ENTRY_POINT=axolotl/src/axolotl/cli/train.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.g5.2xlarge\",\"sagemaker_torch_distributed_enabled\":true}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-3\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"model\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-3\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=axolotl/src/axolotl/cli/train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-07-08-18-02-56-581/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.g5.2xlarge\",\"sagemaker_torch_distributed_enabled\":true},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-3\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"hyperparameters\":{\"config\":\"qlora.yml\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"pytorch-training-2024-07-08-18-02-56-581\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-07-08-18-02-56-581/source/sourcedir.tar.gz\",\"module_name\":\"axolotl/src/axolotl/cli/train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-3\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"axolotl/src/axolotl/cli/train.py\"}\n",
      "SM_USER_ARGS=[\"--config\",\"qlora.yml\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_MODEL=/opt/ml/input/data/model\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_HP_CONFIG=qlora.yml\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\n",
      "Invoking script with the following command:\n",
      "torchrun --nnodes 4 --nproc_per_node 1 --master_addr algo-1 --master_port 7777 --node_rank 1 axolotl/src/axolotl/cli/train.py --config qlora.yml\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformer-engine 0.12.0+170797 requires flash-attn<=2.0.4,>=1.0.6, but you have flash-attn 2.5.8 which is incompatible.\n",
      "spacy 3.7.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "Successfully installed addict-2.4.0 aiofiles-23.2.1 aiohttp-3.9.5 aiosignal-1.3.1 altair-5.3.0 anyio-4.4.0 art-6.2 axolotl-0.4.1 bitsandbytes-0.43.1 cachetools-5.3.3 coloredlogs-15.0.1 datasets-2.19.1 deepspeed-0.14.3+bc48371c deepspeed-kernels-0.0.1.dev1698255861 dnspython-2.6.1 docker-pycreds-0.4.0 docstring-parser-0.16 email_validator-2.2.0 evaluate-0.4.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 fire-0.6.0 flash-attn-2.5.8 frozenlist-1.4.1 fschat-0.2.36 fsspec-2024.3.1 gcsfs-2024.3.1 gitdb-4.0.11 gitpython-3.1.43 google-api-core-2.19.1 google-auth-2.31.0 google-auth-oauthlib-1.2.0 google-cloud-core-2.4.1 google-cloud-storage-2.17.0 google-crc32c-1.5.0 google-resumable-media-2.7.1 googleapis-common-protos-1.63.2 gradio-3.50.2 gradio-client-0.6.1 h11-0.14.0 hf_transfer-0.1.6 hjson-3.1.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 huggingface-hub-0.23.4 humanfriendly-10.0 importlib-resources-6.4.0 markdown2-2.4.13 multidict-6.0.5 nh3-0.2.18 oauthlib-3.2.2 optimum-1.16.2 orjson-3.10.6 peft-0.11.1 proto-plus-1.24.0 py-cpuinfo-9.0.0 pyarrow-hotfix-0.6 pyasn1-modules-0.4.0 pydantic-2.6.3 pydantic-core-2.16.3 pydub-0.25.1 pynvml-11.5.0 python-dotenv-1.0.1 python-multipart-0.0.9 regex-2024.5.15 requests-oauthlib-2.0.0 responses-0.18.0 scikit-learn-1.2.2 semantic-version-2.10.0 sentencepiece-0.2.0 sentry-sdk-2.8.0 setproctitle-1.3.3 shortuuid-1.0.13 shtab-1.7.1 smmap-5.0.1 sniffio-1.3.1 starlette-0.37.2 svgwrite-1.4.3 termcolor-2.4.0 tiktoken-0.7.0 tokenizers-0.19.1 toolz-0.12.1 transformers-4.42.3 trl-0.8.7.dev0 typer-0.12.3 tyro-0.8.5 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 wandb-0.17.4 watchfiles-0.22.0 wavedrom-2.0.3.post3 websockets-11.0.3 xformers-0.0.26.post1 xxhash-3.4.1 yarl-1.9.4 zstandard-0.22.0\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "2024-07-08 18:10:44,318 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-07-08 18:10:44,318 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-07-08 18:10:44,360 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:10:44,389 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:10:44,400 sagemaker-training-toolkit INFO     Starting distributed training through torchrun\n",
      "2024-07-08 18:10:44,418 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:10:44,429 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"sagemaker_torch_distributed_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config\": \"qlora.yml\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-3\",\n",
      "                \"algo-4\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"pytorch-training-2024-07-08-18-02-56-581\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-07-08-18-02-56-581/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"axolotl/src/axolotl/cli/train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\",\n",
      "            \"algo-4\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-3\",\n",
      "                    \"algo-4\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"axolotl/src/axolotl/cli/train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"config\":\"qlora.yml\"}\n",
      "SM_USER_ENTRY_POINT=axolotl/src/axolotl/cli/train.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.g5.2xlarge\",\"sagemaker_torch_distributed_enabled\":true}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"model\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-2\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=axolotl/src/axolotl/cli/train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-07-08-18-02-56-581/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.g5.2xlarge\",\"sagemaker_torch_distributed_enabled\":true},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"hyperparameters\":{\"config\":\"qlora.yml\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"pytorch-training-2024-07-08-18-02-56-581\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-07-08-18-02-56-581/source/sourcedir.tar.gz\",\"module_name\":\"axolotl/src/axolotl/cli/train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"axolotl/src/axolotl/cli/train.py\"}\n",
      "SM_USER_ARGS=[\"--config\",\"qlora.yml\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_MODEL=/opt/ml/input/data/model\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_HP_CONFIG=qlora.yml\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\n",
      "Invoking script with the following command:\n",
      "torchrun --nnodes 4 --nproc_per_node 1 --master_addr algo-1 --master_port 7777 --node_rank 3 axolotl/src/axolotl/cli/train.py --config qlora.yml\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformer-engine 0.12.0+170797 requires flash-attn<=2.0.4,>=1.0.6, but you have flash-attn 2.5.8 which is incompatible.\n",
      "spacy 3.7.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "Successfully installed addict-2.4.0 aiofiles-23.2.1 aiohttp-3.9.5 aiosignal-1.3.1 altair-5.3.0 anyio-4.4.0 art-6.2 axolotl-0.4.1 bitsandbytes-0.43.1 cachetools-5.3.3 coloredlogs-15.0.1 datasets-2.19.1 deepspeed-0.14.3+bc48371c deepspeed-kernels-0.0.1.dev1698255861 dnspython-2.6.1 docker-pycreds-0.4.0 docstring-parser-0.16 email_validator-2.2.0 evaluate-0.4.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 fire-0.6.0 flash-attn-2.5.8 frozenlist-1.4.1 fschat-0.2.36 fsspec-2024.3.1 gcsfs-2024.3.1 gitdb-4.0.11 gitpython-3.1.43 google-api-core-2.19.1 google-auth-2.31.0 google-auth-oauthlib-1.2.0 google-cloud-core-2.4.1 google-cloud-storage-2.17.0 google-crc32c-1.5.0 google-resumable-media-2.7.1 googleapis-common-protos-1.63.2 gradio-3.50.2 gradio-client-0.6.1 h11-0.14.0 hf_transfer-0.1.6 hjson-3.1.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 huggingface-hub-0.23.4 humanfriendly-10.0 importlib-resources-6.4.0 markdown2-2.4.13 multidict-6.0.5 nh3-0.2.18 oauthlib-3.2.2 optimum-1.16.2 orjson-3.10.6 peft-0.11.1 proto-plus-1.24.0 py-cpuinfo-9.0.0 pyarrow-hotfix-0.6 pyasn1-modules-0.4.0 pydantic-2.6.3 pydantic-core-2.16.3 pydub-0.25.1 pynvml-11.5.0 python-dotenv-1.0.1 python-multipart-0.0.9 regex-2024.5.15 requests-oauthlib-2.0.0 responses-0.18.0 scikit-learn-1.2.2 semantic-version-2.10.0 sentencepiece-0.2.0 sentry-sdk-2.8.0 setproctitle-1.3.3 shortuuid-1.0.13 shtab-1.7.1 smmap-5.0.1 sniffio-1.3.1 starlette-0.37.2 svgwrite-1.4.3 termcolor-2.4.0 tiktoken-0.7.0 tokenizers-0.19.1 toolz-0.12.1 transformers-4.42.3 trl-0.8.7.dev0 typer-0.12.3 tyro-0.8.5 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 wandb-0.17.4 watchfiles-0.22.0 wavedrom-2.0.3.post3 websockets-11.0.3 xformers-0.0.26.post1 xxhash-3.4.1 yarl-1.9.4 zstandard-0.22.0\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "2024-07-08 18:10:45,897 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-07-08 18:10:45,897 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-07-08 18:10:45,932 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:10:45,961 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:10:45,972 sagemaker-training-toolkit INFO     Starting distributed training through torchrun\n",
      "2024-07-08 18:10:45,990 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:10:46,001 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"sagemaker_torch_distributed_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-4\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config\": \"qlora.yml\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-3\",\n",
      "                \"algo-4\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"pytorch-training-2024-07-08-18-02-56-581\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-07-08-18-02-56-581/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"axolotl/src/axolotl/cli/train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-4\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\",\n",
      "            \"algo-4\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-3\",\n",
      "                    \"algo-4\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"axolotl/src/axolotl/cli/train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"config\":\"qlora.yml\"}\n",
      "SM_USER_ENTRY_POINT=axolotl/src/axolotl/cli/train.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.g5.2xlarge\",\"sagemaker_torch_distributed_enabled\":true}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-4\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"model\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-4\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=axolotl/src/axolotl/cli/train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-07-08-18-02-56-581/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.g5.2xlarge\",\"sagemaker_torch_distributed_enabled\":true},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-4\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"hyperparameters\":{\"config\":\"qlora.yml\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"pytorch-training-2024-07-08-18-02-56-581\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-07-08-18-02-56-581/source/sourcedir.tar.gz\",\"module_name\":\"axolotl/src/axolotl/cli/train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-4\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"axolotl/src/axolotl/cli/train.py\"}\n",
      "SM_USER_ARGS=[\"--config\",\"qlora.yml\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_MODEL=/opt/ml/input/data/model\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_HP_CONFIG=qlora.yml\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\n",
      "Invoking script with the following command:\n",
      "torchrun --nnodes 4 --nproc_per_node 1 --master_addr algo-1 --master_port 7777 --node_rank 2 axolotl/src/axolotl/cli/train.py --config qlora.yml\n",
      "2024-07-08 18:10:46,477 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-07-08 18:10:46,477 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-07-08 18:10:46,513 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:10:46,542 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:10:46,553 sagemaker-training-toolkit INFO     Starting distributed training through torchrun\n",
      "2024-07-08 18:10:46,571 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-07-08 18:10:46,582 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"sagemaker_torch_distributed_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config\": \"qlora.yml\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-3\",\n",
      "                \"algo-4\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"pytorch-training-2024-07-08-18-02-56-581\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-07-08-18-02-56-581/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"axolotl/src/axolotl/cli/train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\",\n",
      "            \"algo-4\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-3\",\n",
      "                    \"algo-4\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"axolotl/src/axolotl/cli/train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"config\":\"qlora.yml\"}\n",
      "SM_USER_ENTRY_POINT=axolotl/src/axolotl/cli/train.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.g5.2xlarge\",\"sagemaker_torch_distributed_enabled\":true}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"model\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=axolotl/src/axolotl/cli/train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-07-08-18-02-56-581/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.g5.2xlarge\",\"sagemaker_torch_distributed_enabled\":true},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"hyperparameters\":{\"config\":\"qlora.yml\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"pytorch-training-2024-07-08-18-02-56-581\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-07-08-18-02-56-581/source/sourcedir.tar.gz\",\"module_name\":\"axolotl/src/axolotl/cli/train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-4\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"axolotl/src/axolotl/cli/train.py\"}\n",
      "SM_USER_ARGS=[\"--config\",\"qlora.yml\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_MODEL=/opt/ml/input/data/model\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_HP_CONFIG=qlora.yml\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\n",
      "Invoking script with the following command:\n",
      "torchrun --nnodes 4 --nproc_per_node 1 --master_addr algo-1 --master_port 7777 --node_rank 0 axolotl/src/axolotl/cli/train.py --config qlora.yml\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "[2024-07-08 18:10:54,958] [INFO] [datasets.<module>:58] [PID:435] PyTorch version 2.3.0 available.\n",
      "[2024-07-08 18:10:55,073] [INFO] [datasets.<module>:58] [PID:435] PyTorch version 2.3.0 available.\n",
      "[2024-07-08 18:10:55,401] [INFO] [datasets.<module>:58] [PID:436] PyTorch version 2.3.0 available.\n",
      "[2024-07-08 18:10:55,302] [INFO] [datasets.<module>:58] [PID:435] PyTorch version 2.3.0 available.\n",
      "[2024-07-08 18:10:56,056] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "df: /root/.triton/autotune: No such file or directory\n",
      "[2024-07-08 18:10:56,133] [INFO] [root.spawn:38] [PID:435] gcc -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c /tmp/tmpt_gesnju/test.c -o /tmp/tmpt_gesnju/test.o\n",
      "[2024-07-08 18:10:56,153] [INFO] [root.spawn:38] [PID:435] gcc -pthread -B /opt/conda/compiler_compat /tmp/tmpt_gesnju/test.o -laio -o /tmp/tmpt_gesnju/a.out\n",
      "[WARNING]  async_io requires the dev libaio .so object and headers but these were not found.\n",
      "[WARNING]  async_io: please install the libaio-dev package with apt\n",
      "[WARNING]  If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "[WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "[WARNING]  sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "[WARNING]  using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n",
      "[2024-07-08 18:10:55,713] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "df: /root/.triton/autotune: No such file or directory\n",
      "[2024-07-08 18:10:55,789] [INFO] [root.spawn:38] [PID:435] gcc -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c /tmp/tmpxm7dppjs/test.c -o /tmp/tmpxm7dppjs/test.o\n",
      "[2024-07-08 18:10:55,809] [INFO] [root.spawn:38] [PID:435] gcc -pthread -B /opt/conda/compiler_compat /tmp/tmpxm7dppjs/test.o -laio -o /tmp/tmpxm7dppjs/a.out\n",
      "[WARNING]  async_io requires the dev libaio .so object and headers but these were not found.\n",
      "[WARNING]  async_io: please install the libaio-dev package with apt\n",
      "[WARNING]  If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "[WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "[WARNING]  sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "[WARNING]  using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n",
      "[2024-07-08 18:10:55,840] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "df: /root/.triton/autotune: No such file or directory\n",
      "[2024-07-08 18:10:55,918] [INFO] [root.spawn:38] [PID:435] gcc -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c /tmp/tmp8yl2g95y/test.c -o /tmp/tmp8yl2g95y/test.o\n",
      "[2024-07-08 18:10:55,938] [INFO] [root.spawn:38] [PID:435] gcc -pthread -B /opt/conda/compiler_compat /tmp/tmp8yl2g95y/test.o -laio -o /tmp/tmp8yl2g95y/a.out\n",
      "[WARNING]  async_io requires the dev libaio .so object and headers but these were not found.\n",
      "[WARNING]  async_io: please install the libaio-dev package with apt\n",
      "[WARNING]  If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      " [WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "[WARNING]  sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "[WARNING]  using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n",
      "[2024-07-08 18:10:56,378] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "df: /root/.triton/autotune: No such file or directory\n",
      "[2024-07-08 18:10:56,455] [INFO] [root.spawn:38] [PID:436] gcc -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c /tmp/tmp0txy_n9p/test.c -o /tmp/tmp0txy_n9p/test.o\n",
      "[2024-07-08 18:10:56,475] [INFO] [root.spawn:38] [PID:436] gcc -pthread -B /opt/conda/compiler_compat /tmp/tmp0txy_n9p/test.o -laio -o /tmp/tmp0txy_n9p/a.out\n",
      "[WARNING]  async_io requires the dev libaio .so object and headers but these were not found.\n",
      "[WARNING]  async_io: please install the libaio-dev package with apt\n",
      "[WARNING]  If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "[WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "[WARNING]  sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "[WARNING]  using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n",
      "[2024-07-08 18:10:58,037] [INFO] [axolotl.utils.config.models.input.check_eval_packing:908] [PID:435] [RANK:0] explicitly setting `eval_sample_packing` to match `sample_packing`#033[39m\n",
      "[2024-07-08 18:10:58,038] [DEBUG] [axolotl.normalize_config:80] [PID:435] [RANK:0] bf16 support detected, enabling for this configuration.#033[39m\n",
      "[2024-07-08 18:10:58,040] [INFO] [axolotl.normalize_config:183] [PID:435] [RANK:0] GPU memory usage baseline: 0.000GB (+0.300GB misc)#033[39m\n",
      "#033[33m[2024-07-08 18:10:58,061] [WARNING] [axolotl.scripts.check_user_token:487] [PID:435] [RANK:0] Error verifying HuggingFace token. Remember to log in using `huggingface-cli login` and get your access token from https://huggingface.co/settings/tokens if you want to use gated models or datasets.#033[39m\n",
      "[2024-07-08 18:10:58,117] [DEBUG] [axolotl.load_tokenizer:280] [PID:435] [RANK:0] EOS: 2 / </s>#033[39m\n",
      "[2024-07-08 18:10:58,118] [DEBUG] [axolotl.load_tokenizer:281] [PID:435] [RANK:0] BOS: 1 / <s>#033[39m\n",
      "[2024-07-08 18:10:58,118] [DEBUG] [axolotl.load_tokenizer:282] [PID:435] [RANK:0] PAD: 2 / </s>#033[39m\n",
      "[2024-07-08 18:10:58,118] [DEBUG] [axolotl.load_tokenizer:283] [PID:435] [RANK:0] UNK: 0 / <unk>#033[39m\n",
      "[2024-07-08 18:10:58,118] [INFO] [axolotl.load_tokenizer:294] [PID:435] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.#033[39m\n",
      "[2024-07-08 18:10:57,744] [INFO] [axolotl.utils.config.models.input.check_eval_packing:908] [PID:435] [RANK:0] explicitly setting `eval_sample_packing` to match `sample_packing`#033[39m\n",
      "[2024-07-08 18:10:57,744] [DEBUG] [axolotl.normalize_config:80] [PID:435] [RANK:0] bf16 support detected, enabling for this configuration.#033[39m\n",
      "[2024-07-08 18:10:57,747] [INFO] [axolotl.normalize_config:183] [PID:435] [RANK:0] GPU memory usage baseline: 0.000GB (+0.300GB misc)#033[39m\n",
      "#033[33m[2024-07-08 18:10:57,768] [WARNING] [axolotl.scripts.check_user_token:487] [PID:435] [RANK:0] Error verifying HuggingFace token. Remember to log in using `huggingface-cli login` and get your access token from https://huggingface.co/settings/tokens if you want to use gated models or datasets.#033[39m\n",
      "[2024-07-08 18:10:57,823] [DEBUG] [axolotl.load_tokenizer:280] [PID:435] [RANK:0] EOS: 2 / </s>#033[39m\n",
      "[2024-07-08 18:10:57,823] [DEBUG] [axolotl.load_tokenizer:281] [PID:435] [RANK:0] BOS: 1 / <s>#033[39m\n",
      "[2024-07-08 18:10:57,823] [DEBUG] [axolotl.load_tokenizer:282] [PID:435] [RANK:0] PAD: 2 / </s>#033[39m\n",
      "[2024-07-08 18:10:57,823] [DEBUG] [axolotl.load_tokenizer:283] [PID:435] [RANK:0] UNK: 0 / <unk>#033[39m\n",
      "[2024-07-08 18:10:57,823] [INFO] [axolotl.load_tokenizer:294] [PID:435] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.#033[39m\n",
      "[2024-07-08 18:10:57,720] [INFO] [axolotl.utils.config.models.input.check_eval_packing:908] [PID:435] [RANK:0] explicitly setting `eval_sample_packing` to match `sample_packing`#033[39m\n",
      "[2024-07-08 18:10:57,721] [DEBUG] [axolotl.normalize_config:80] [PID:435] [RANK:0] bf16 support detected, enabling for this configuration.#033[39m\n",
      "[2024-07-08 18:10:57,723] [INFO] [axolotl.normalize_config:183] [PID:435] [RANK:0] GPU memory usage baseline: 0.000GB (+0.300GB misc)#033[39m\n",
      "#033[33m[2024-07-08 18:10:57,745] [WARNING] [axolotl.scripts.check_user_token:487] [PID:435] [RANK:0] Error verifying HuggingFace token. Remember to log in using `huggingface-cli login` and get your access token from https://huggingface.co/settings/tokens if you want to use gated models or datasets.#033[39m\n",
      "[2024-07-08 18:10:57,802] [DEBUG] [axolotl.load_tokenizer:280] [PID:435] [RANK:0] EOS: 2 / </s>#033[39m\n",
      "[2024-07-08 18:10:57,802] [DEBUG] [axolotl.load_tokenizer:281] [PID:435] [RANK:0] BOS: 1 / <s>#033[39m\n",
      "[2024-07-08 18:10:57,802] [DEBUG] [axolotl.load_tokenizer:282] [PID:435] [RANK:0] PAD: 2 / </s>#033[39m\n",
      "[2024-07-08 18:10:57,802] [DEBUG] [axolotl.load_tokenizer:283] [PID:435] [RANK:0] UNK: 0 / <unk>#033[39m\n",
      "[2024-07-08 18:10:57,802] [INFO] [axolotl.load_tokenizer:294] [PID:435] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.#033[39m\n",
      "[2024-07-08 18:10:58,491] [INFO] [axolotl.utils.config.models.input.check_eval_packing:908] [PID:436] [RANK:0] explicitly setting `eval_sample_packing` to match `sample_packing`#033[39m\n",
      "[2024-07-08 18:10:58,491] [DEBUG] [axolotl.normalize_config:80] [PID:436] [RANK:0] bf16 support detected, enabling for this configuration.#033[39m\n",
      "[2024-07-08 18:10:58,494] [INFO] [axolotl.normalize_config:183] [PID:436] [RANK:0] GPU memory usage baseline: 0.000GB (+0.300GB misc)#033[39m\n",
      "dP            dP   dP \n",
      "                                 88            88   88 \n",
      "      .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 \n",
      "      88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 \n",
      "      88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 \n",
      "      `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP \n",
      "                                                       \n",
      "                                                       \n",
      "****************************************\n",
      "**** Axolotl Dependency Versions *****\n",
      "accelerate: 0.30.1\n",
      "peft: 0.11.1\n",
      "transformers: 4.42.3\n",
      "trl: 0.8.7.dev0\n",
      "torch: 2.3.0\n",
      "bitsandbytes: 0.43.1\n",
      "****************************************\n",
      "#033[33m[2024-07-08 18:10:58,521] [WARNING] [axolotl.scripts.check_user_token:487] [PID:436] [RANK:0] Error verifying HuggingFace token. Remember to log in using `huggingface-cli login` and get your access token from https://huggingface.co/settings/tokens if you want to use gated models or datasets.#033[39m\n",
      "[2024-07-08 18:10:58,577] [DEBUG] [axolotl.load_tokenizer:280] [PID:436] [RANK:0] EOS: 2 / </s>#033[39m\n",
      "[2024-07-08 18:10:58,577] [DEBUG] [axolotl.load_tokenizer:281] [PID:436] [RANK:0] BOS: 1 / <s>#033[39m\n",
      "[2024-07-08 18:10:58,577] [DEBUG] [axolotl.load_tokenizer:282] [PID:436] [RANK:0] PAD: 2 / </s>#033[39m\n",
      "[2024-07-08 18:10:58,577] [DEBUG] [axolotl.load_tokenizer:283] [PID:436] [RANK:0] UNK: 0 / <unk>#033[39m\n",
      "[2024-07-08 18:10:58,577] [INFO] [axolotl.load_tokenizer:294] [PID:436] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.#033[39m\n",
      "[2024-07-08 18:10:58,577] [INFO] [axolotl.load_tokenized_prepared_datasets:183] [PID:436] [RANK:0] Unable to find prepared dataset in last_run_prepared/515d28cedb8f11b4423ad59630e8364d#033[39m\n",
      "[2024-07-08 18:10:58,577] [INFO] [axolotl.load_tokenized_prepared_datasets:184] [PID:436] [RANK:0] Loading raw datasets...#033[39m\n",
      "#033[33m[2024-07-08 18:10:58,577] [WARNING] [axolotl.load_tokenized_prepared_datasets:186] [PID:436] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.#033[39m\n",
      "[2024-07-08 18:10:58,578] [INFO] [axolotl.load_tokenized_prepared_datasets:193] [PID:436] [RANK:0] No seed provided, using default seed of 42#033[39m\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 76334 examples [00:13, 5777.05 examples/s]\n",
      "Generating train split: 76334 examples [00:13, 5734.33 examples/s]\n",
      "[2024-07-08 18:11:11,978] [INFO] [axolotl.get_dataset_wrapper:540] [PID:436] [RANK:0] Loading dataset with base_type: sharegpt.load_role and prompt_style: None#033[39m\n",
      "Tokenizing Prompts (num_proc=8):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   0%|          | 20/76334 [00:00<08:02, 158.25 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   0%|          | 279/76334 [00:00<00:53, 1434.89 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   1%|          | 564/76334 [00:00<00:37, 2014.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   1%|          | 881/76334 [00:00<00:31, 2385.98 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   2%|▏         | 1175/76334 [00:00<00:29, 2564.43 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   2%|▏         | 1459/76334 [00:00<00:28, 2637.73 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   2%|▏         | 1740/76334 [00:00<00:28, 2606.31 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   3%|▎         | 2013/76334 [00:00<00:31, 2355.79 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   3%|▎         | 2257/76334 [00:00<00:31, 2376.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   3%|▎         | 2513/76334 [00:01<00:31, 2366.99 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   4%|▎         | 2764/76334 [00:01<00:30, 2378.19 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   4%|▍         | 3009/76334 [00:01<00:30, 2376.75 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   4%|▍         | 3266/76334 [00:01<00:30, 2361.47 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   5%|▍         | 3507/76334 [00:01<00:30, 2360.57 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   5%|▍         | 3758/76334 [00:01<00:30, 2378.36 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   5%|▌         | 4005/76334 [00:01<00:31, 2305.13 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   6%|▌         | 4260/76334 [00:01<00:30, 2348.53 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   6%|▌         | 4498/76334 [00:01<00:30, 2325.55 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   6%|▌         | 4742/76334 [00:02<00:31, 2302.53 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   7%|▋         | 4986/76334 [00:02<00:30, 2309.02 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   7%|▋         | 5224/76334 [00:02<00:30, 2303.67 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   7%|▋         | 5456/76334 [00:02<00:31, 2254.96 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   7%|▋         | 5696/76334 [00:02<00:31, 2268.52 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   8%|▊         | 5939/76334 [00:02<00:31, 2264.12 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   8%|▊         | 6175/76334 [00:02<00:31, 2262.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   8%|▊         | 6408/76334 [00:02<00:30, 2264.37 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   9%|▊         | 6639/76334 [00:02<00:31, 2191.82 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   9%|▉         | 6881/76334 [00:03<00:31, 2216.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   9%|▉         | 7116/76334 [00:03<00:30, 2241.73 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  10%|▉         | 7353/76334 [00:03<00:31, 2211.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  10%|▉         | 7586/76334 [00:03<00:31, 2193.87 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  10%|█         | 7806/76334 [00:03<00:31, 2165.88 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  11%|█         | 8033/76334 [00:03<00:31, 2139.24 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  11%|█         | 8252/76334 [00:03<00:34, 1982.75 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  11%|█         | 8461/76334 [00:03<00:34, 1960.03 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  11%|█▏        | 8666/76334 [00:03<00:35, 1885.12 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  12%|█▏        | 8868/76334 [00:04<00:35, 1917.89 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  12%|█▏        | 9097/76334 [00:04<00:33, 2014.90 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  12%|█▏        | 9334/76334 [00:04<00:31, 2100.36 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  13%|█▎        | 9572/76334 [00:04<00:30, 2159.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  13%|█▎        | 9806/76334 [00:04<00:30, 2189.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  13%|█▎        | 10041/76334 [00:04<00:29, 2213.21 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  13%|█▎        | 10303/76334 [00:04<00:28, 2326.15 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  14%|█▍        | 10537/76334 [00:04<00:28, 2293.29 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  14%|█▍        | 10770/76334 [00:04<00:28, 2272.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  14%|█▍        | 11013/76334 [00:04<00:28, 2297.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  15%|█▍        | 11259/76334 [00:05<00:27, 2329.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  15%|█▌        | 11501/76334 [00:05<00:27, 2316.04 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  15%|█▌        | 11754/76334 [00:05<00:27, 2354.47 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  16%|█▌        | 12038/76334 [00:05<00:26, 2463.29 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  16%|█▌        | 12316/76334 [00:05<00:25, 2549.75 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  17%|█▋        | 12597/76334 [00:05<00:24, 2609.15 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  17%|█▋        | 12883/76334 [00:05<00:23, 2650.95 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  17%|█▋        | 13164/76334 [00:05<00:24, 2593.12 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  18%|█▊        | 13432/76334 [00:05<00:24, 2589.22 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  18%|█▊        | 13702/76334 [00:05<00:24, 2580.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  18%|█▊        | 13986/76334 [00:06<00:23, 2613.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  19%|█▊        | 14280/76334 [00:06<00:23, 2690.73 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  19%|█▉        | 14561/76334 [00:06<00:22, 2707.61 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  19%|█▉        | 14845/76334 [00:06<00:22, 2735.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  20%|█▉        | 15130/76334 [00:06<00:22, 2677.78 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  20%|██        | 15414/76334 [00:06<00:22, 2682.43 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  21%|██        | 15695/76334 [00:06<00:23, 2574.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  21%|██        | 15960/76334 [00:06<00:23, 2582.80 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  21%|██▏       | 16231/76334 [00:06<00:24, 2479.30 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  22%|██▏       | 16481/76334 [00:07<00:26, 2282.10 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  22%|██▏       | 16724/76334 [00:07<00:25, 2302.96 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  22%|██▏       | 16971/76334 [00:07<00:25, 2306.11 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  23%|██▎       | 17230/76334 [00:07<00:25, 2355.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  23%|██▎       | 17515/76334 [00:07<00:23, 2470.77 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  23%|██▎       | 17776/76334 [00:07<00:23, 2497.59 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  24%|██▎       | 18051/76334 [00:07<00:22, 2546.44 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  24%|██▍       | 18316/76334 [00:07<00:22, 2553.96 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  24%|██▍       | 18592/76334 [00:07<00:22, 2598.63 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  25%|██▍       | 18871/76334 [00:08<00:21, 2638.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  25%|██▌       | 19146/76334 [00:08<00:21, 2649.78 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  25%|██▌       | 19422/76334 [00:08<00:21, 2673.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  26%|██▌       | 19701/76334 [00:08<00:21, 2650.82 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  26%|██▌       | 19970/76334 [00:08<00:21, 2650.43 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  27%|██▋       | 20245/76334 [00:08<00:21, 2590.72 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  27%|██▋       | 20517/76334 [00:08<00:21, 2586.24 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  27%|██▋       | 20802/76334 [00:08<00:21, 2639.00 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  28%|██▊       | 21092/76334 [00:08<00:20, 2670.81 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  28%|██▊       | 21365/76334 [00:08<00:20, 2639.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  28%|██▊       | 21631/76334 [00:09<00:21, 2603.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  29%|██▊       | 21901/76334 [00:09<00:20, 2620.15 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  29%|██▉       | 22176/76334 [00:09<00:20, 2646.24 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  29%|██▉       | 22467/76334 [00:09<00:19, 2701.41 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  30%|██▉       | 22746/76334 [00:09<00:19, 2703.29 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  30%|███       | 23030/76334 [00:09<00:19, 2706.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  31%|███       | 23315/76334 [00:09<00:21, 2516.96 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  31%|███       | 23586/76334 [00:09<00:20, 2531.56 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  31%|███       | 23853/76334 [00:09<00:20, 2531.38 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  32%|███▏      | 24114/76334 [00:10<00:20, 2544.45 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  32%|███▏      | 24374/76334 [00:10<00:21, 2376.48 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  32%|███▏      | 24622/76334 [00:10<00:22, 2322.06 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  33%|███▎      | 24871/76334 [00:10<00:22, 2297.30 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  33%|███▎      | 25121/76334 [00:10<00:22, 2323.67 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  33%|███▎      | 25396/76334 [00:10<00:20, 2426.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  34%|███▎      | 25682/76334 [00:10<00:19, 2536.82 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  34%|███▍      | 25975/76334 [00:10<00:19, 2613.34 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  34%|███▍      | 26264/76334 [00:10<00:18, 2665.34 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  35%|███▍      | 26548/76334 [00:10<00:18, 2701.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  35%|███▌      | 26824/76334 [00:11<00:18, 2690.05 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  36%|███▌      | 27117/76334 [00:11<00:17, 2752.81 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  36%|███▌      | 27394/76334 [00:11<00:17, 2733.59 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  36%|███▋      | 27673/76334 [00:11<00:17, 2734.03 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  37%|███▋      | 27955/76334 [00:11<00:17, 2752.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  37%|███▋      | 28238/76334 [00:11<00:18, 2604.36 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  37%|███▋      | 28515/76334 [00:11<00:18, 2626.24 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  38%|███▊      | 28809/76334 [00:11<00:17, 2705.56 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  38%|███▊      | 29099/76334 [00:11<00:17, 2683.29 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  38%|███▊      | 29380/76334 [00:12<00:17, 2696.65 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  39%|███▉      | 29667/76334 [00:12<00:17, 2713.42 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  39%|███▉      | 29953/76334 [00:12<00:17, 2719.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  40%|███▉      | 30229/76334 [00:12<00:17, 2686.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  40%|███▉      | 30510/76334 [00:12<00:16, 2703.65 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  40%|████      | 30791/76334 [00:12<00:17, 2611.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  41%|████      | 31081/76334 [00:12<00:17, 2583.57 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  41%|████      | 31357/76334 [00:12<00:18, 2485.66 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  41%|████▏     | 31619/76334 [00:12<00:17, 2495.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  42%|████▏     | 31899/76334 [00:13<00:17, 2573.76 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  42%|████▏     | 32188/76334 [00:13<00:16, 2629.42 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  43%|████▎     | 32452/76334 [00:13<00:18, 2394.45 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  43%|████▎     | 32704/76334 [00:13<00:19, 2244.02 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  43%|████▎     | 32945/76334 [00:13<00:19, 2269.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  44%|████▎     | 33238/76334 [00:13<00:17, 2445.90 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  44%|████▍     | 33516/76334 [00:13<00:17, 2508.42 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  44%|████▍     | 33786/76334 [00:13<00:16, 2537.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  45%|████▍     | 34073/76334 [00:13<00:16, 2618.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  45%|████▍     | 34350/76334 [00:14<00:15, 2641.82 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  45%|████▌     | 34631/76334 [00:14<00:15, 2639.59 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  46%|████▌     | 34908/76334 [00:14<00:15, 2651.94 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  46%|████▌     | 35193/76334 [00:14<00:15, 2692.83 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  46%|████▋     | 35479/76334 [00:14<00:15, 2715.17 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  47%|████▋     | 35767/76334 [00:14<00:14, 2719.76 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  47%|████▋     | 36051/76334 [00:14<00:14, 2714.08 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  48%|████▊     | 36333/76334 [00:14<00:14, 2728.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  48%|████▊     | 36617/76334 [00:14<00:14, 2712.89 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  48%|████▊     | 36902/76334 [00:14<00:14, 2714.96 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  49%|████▊     | 37181/76334 [00:15<00:14, 2719.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  49%|████▉     | 37456/76334 [00:15<00:14, 2682.11 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  49%|████▉     | 37739/76334 [00:15<00:15, 2541.68 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  50%|████▉     | 38027/76334 [00:15<00:14, 2625.37 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  50%|█████     | 38311/76334 [00:15<00:14, 2639.37 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  51%|█████     | 38587/76334 [00:15<00:14, 2646.83 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  51%|█████     | 38864/76334 [00:15<00:14, 2657.33 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  51%|█████▏    | 39133/76334 [00:15<00:14, 2556.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  52%|█████▏    | 39392/76334 [00:15<00:14, 2524.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  52%|█████▏    | 39671/76334 [00:16<00:14, 2583.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  52%|█████▏    | 39959/76334 [00:16<00:13, 2655.75 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  53%|█████▎    | 40243/76334 [00:16<00:13, 2654.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  53%|█████▎    | 40519/76334 [00:16<00:15, 2347.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  53%|█████▎    | 40766/76334 [00:16<00:15, 2370.40 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  54%|█████▎    | 41017/76334 [00:16<00:15, 2324.81 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  54%|█████▍    | 41311/76334 [00:16<00:14, 2479.88 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  54%|█████▍    | 41600/76334 [00:16<00:13, 2566.77 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  55%|█████▍    | 41865/76334 [00:16<00:13, 2561.25 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  55%|█████▌    | 42155/76334 [00:16<00:12, 2646.36 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  56%|█████▌    | 42441/76334 [00:17<00:12, 2683.89 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  56%|█████▌    | 42729/76334 [00:17<00:12, 2717.36 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  56%|█████▋    | 43018/76334 [00:17<00:12, 2735.61 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  57%|█████▋    | 43305/76334 [00:17<00:12, 2751.73 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  57%|█████▋    | 43590/76334 [00:17<00:11, 2749.78 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  57%|█████▋    | 43879/76334 [00:17<00:11, 2766.50 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  58%|█████▊    | 44171/76334 [00:17<00:11, 2717.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  58%|█████▊    | 44444/76334 [00:17<00:11, 2701.12 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  59%|█████▊    | 44730/76334 [00:17<00:11, 2670.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  59%|█████▉    | 44998/76334 [00:18<00:11, 2656.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  59%|█████▉    | 45269/76334 [00:18<00:11, 2655.94 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  60%|█████▉    | 45540/76334 [00:18<00:11, 2610.91 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  60%|██████    | 45806/76334 [00:18<00:11, 2610.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  60%|██████    | 46078/76334 [00:18<00:11, 2606.79 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  61%|██████    | 46340/76334 [00:18<00:11, 2606.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  61%|██████    | 46605/76334 [00:18<00:11, 2587.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  61%|██████▏   | 46873/76334 [00:18<00:11, 2613.29 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  62%|██████▏   | 47148/76334 [00:18<00:11, 2622.72 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  62%|██████▏   | 47413/76334 [00:18<00:11, 2614.36 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  62%|██████▏   | 47685/76334 [00:19<00:10, 2628.98 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  63%|██████▎   | 47951/76334 [00:19<00:10, 2628.84 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  63%|██████▎   | 48225/76334 [00:19<00:11, 2519.52 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  64%|██████▎   | 48483/76334 [00:19<00:11, 2418.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  64%|██████▍   | 48727/76334 [00:19<00:12, 2267.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  64%|██████▍   | 48994/76334 [00:19<00:11, 2357.05 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  65%|██████▍   | 49273/76334 [00:19<00:11, 2449.41 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  65%|██████▍   | 49568/76334 [00:19<00:10, 2565.52 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  65%|██████▌   | 49864/76334 [00:19<00:10, 2639.95 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  66%|██████▌   | 50139/76334 [00:20<00:09, 2656.79 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  66%|██████▌   | 50416/76334 [00:20<00:09, 2682.10 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  66%|██████▋   | 50702/76334 [00:20<00:09, 2699.48 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  67%|██████▋   | 51003/76334 [00:20<00:09, 2763.41 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  67%|██████▋   | 51290/76334 [00:20<00:09, 2754.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  68%|██████▊   | 51580/76334 [00:20<00:09, 2682.68 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  68%|██████▊   | 51864/76334 [00:20<00:09, 2688.89 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  68%|██████▊   | 52147/76334 [00:20<00:08, 2726.97 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  69%|██████▊   | 52439/76334 [00:20<00:09, 2654.48 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  69%|██████▉   | 52716/76334 [00:21<00:08, 2633.68 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  69%|██████▉   | 52989/76334 [00:21<00:08, 2640.32 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  70%|██████▉   | 53276/76334 [00:21<00:08, 2661.35 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  70%|███████   | 53548/76334 [00:21<00:08, 2620.19 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  70%|███████   | 53814/76334 [00:21<00:08, 2577.36 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  71%|███████   | 54080/76334 [00:21<00:08, 2598.52 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  71%|███████   | 54363/76334 [00:21<00:08, 2635.99 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  72%|███████▏  | 54660/76334 [00:21<00:07, 2717.35 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  72%|███████▏  | 54948/76334 [00:21<00:07, 2677.50 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  72%|███████▏  | 55234/76334 [00:21<00:07, 2695.99 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  73%|███████▎  | 55504/76334 [00:22<00:08, 2594.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  73%|███████▎  | 55772/76334 [00:22<00:08, 2565.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  73%|███████▎  | 56056/76334 [00:22<00:07, 2603.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  74%|███████▍  | 56322/76334 [00:22<00:08, 2360.83 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  74%|███████▍  | 56570/76334 [00:22<00:08, 2358.94 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  74%|███████▍  | 56813/76334 [00:22<00:08, 2262.76 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  75%|███████▍  | 57085/76334 [00:22<00:08, 2350.98 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  75%|███████▌  | 57354/76334 [00:22<00:07, 2415.61 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  75%|███████▌  | 57631/76334 [00:22<00:07, 2481.12 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  76%|███████▌  | 57906/76334 [00:23<00:07, 2530.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  76%|███████▌  | 58173/76334 [00:23<00:07, 2553.11 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  77%|███████▋  | 58448/76334 [00:23<00:06, 2582.47 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  77%|███████▋  | 58726/76334 [00:23<00:06, 2625.42 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  77%|███████▋  | 59012/76334 [00:23<00:06, 2687.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  78%|███████▊  | 59295/76334 [00:23<00:06, 2692.93 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  78%|███████▊  | 59574/76334 [00:23<00:06, 2684.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  78%|███████▊  | 59854/76334 [00:23<00:06, 2695.87 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  79%|███████▉  | 60141/76334 [00:23<00:05, 2714.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  79%|███████▉  | 60423/76334 [00:23<00:05, 2727.53 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  80%|███████▉  | 60698/76334 [00:24<00:05, 2730.40 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  80%|███████▉  | 60975/76334 [00:24<00:05, 2718.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  80%|████████  | 61258/76334 [00:24<00:05, 2729.98 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  81%|████████  | 61539/76334 [00:24<00:05, 2712.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  81%|████████  | 61828/76334 [00:24<00:05, 2711.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  81%|████████▏ | 62100/76334 [00:24<00:05, 2655.83 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  82%|████████▏ | 62372/76334 [00:24<00:05, 2650.80 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  82%|████████▏ | 62665/76334 [00:24<00:05, 2708.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  82%|████████▏ | 62940/76334 [00:24<00:04, 2696.17 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  83%|████████▎ | 63214/76334 [00:25<00:04, 2705.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  83%|████████▎ | 63508/76334 [00:25<00:04, 2767.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  84%|████████▎ | 63797/76334 [00:25<00:05, 2446.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  84%|████████▍ | 64052/76334 [00:25<00:05, 2435.03 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  84%|████████▍ | 64305/76334 [00:25<00:04, 2432.42 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  85%|████████▍ | 64557/76334 [00:25<00:05, 2296.61 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  85%|████████▍ | 64812/76334 [00:25<00:04, 2337.89 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  85%|████████▌ | 65052/76334 [00:25<00:04, 2354.48 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  86%|████████▌ | 65341/76334 [00:25<00:04, 2480.50 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  86%|████████▌ | 65626/76334 [00:26<00:04, 2557.37 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  86%|████████▋ | 65908/76334 [00:26<00:04, 2594.87 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  87%|████████▋ | 66180/76334 [00:26<00:03, 2624.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  87%|████████▋ | 66467/76334 [00:26<00:03, 2653.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  87%|████████▋ | 66746/76334 [00:26<00:03, 2651.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  88%|████████▊ | 67033/76334 [00:26<00:03, 2686.21 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  88%|████████▊ | 67320/76334 [00:26<00:03, 2730.76 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  89%|████████▊ | 67608/76334 [00:26<00:03, 2696.27 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  89%|████████▉ | 67893/76334 [00:26<00:03, 2712.05 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  89%|████████▉ | 68184/76334 [00:26<00:02, 2753.38 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  90%|████████▉ | 68466/76334 [00:27<00:02, 2756.83 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  90%|█████████ | 68750/76334 [00:27<00:02, 2758.71 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  90%|█████████ | 69034/76334 [00:27<00:02, 2760.24 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  91%|█████████ | 69318/76334 [00:27<00:02, 2766.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  91%|█████████ | 69597/76334 [00:27<00:02, 2743.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  92%|█████████▏| 69876/76334 [00:27<00:02, 2609.65 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  92%|█████████▏| 70142/76334 [00:27<00:02, 2602.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  92%|█████████▏| 70416/76334 [00:27<00:02, 2600.17 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  93%|█████████▎| 70680/76334 [00:27<00:02, 2589.53 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  93%|█████████▎| 70972/76334 [00:28<00:02, 2634.01 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  93%|█████████▎| 71256/76334 [00:28<00:01, 2652.47 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  94%|█████████▎| 71553/76334 [00:28<00:01, 2729.40 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  94%|█████████▍| 71834/76334 [00:28<00:01, 2601.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  94%|█████████▍| 72106/76334 [00:28<00:01, 2503.10 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  95%|█████████▍| 72365/76334 [00:28<00:01, 2352.36 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  95%|█████████▌| 72605/76334 [00:28<00:01, 2137.67 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  95%|█████████▌| 72867/76334 [00:28<00:01, 2230.77 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  96%|█████████▌| 73158/76334 [00:28<00:01, 2389.96 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  96%|█████████▌| 73446/76334 [00:29<00:01, 2510.83 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  97%|█████████▋| 73736/76334 [00:29<00:01, 2596.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  97%|█████████▋| 74002/76334 [00:29<00:00, 2588.50 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  97%|█████████▋| 74271/76334 [00:29<00:00, 2582.52 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  98%|█████████▊| 74545/76334 [00:29<00:00, 2599.30 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  98%|█████████▊| 74829/76334 [00:29<00:00, 2566.05 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  98%|█████████▊| 75095/76334 [00:29<00:00, 2561.53 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  99%|█████████▊| 75365/76334 [00:29<00:00, 2574.54 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  99%|█████████▉| 75637/76334 [00:29<00:00, 2597.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  99%|█████████▉| 75913/76334 [00:30<00:00, 2374.01 examples/s]\n",
      "Tokenizing Prompts (num_proc=8): 100%|█████████▉| 76157/76334 [00:30<00:00, 2279.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8): 100%|██████████| 76334/76334 [00:30<00:00, 2508.59 examples/s]\n",
      "[2024-07-08 18:11:42,705] [INFO] [axolotl.load_tokenized_prepared_datasets:414] [PID:436] [RANK:0] merging datasets#033[39m\n",
      "[2024-07-08 18:11:42,708] [INFO] [axolotl.process_datasets_for_packing:195] [PID:436] [RANK:0] dropping attention_mask column#033[39m\n",
      "Dropping Long Sequences (num_proc=8):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Dropping Long Sequences (num_proc=8):   1%|▏         | 1000/76334 [00:00<00:32, 2347.99 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  12%|█▏        | 9000/76334 [00:00<00:05, 12923.38 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  22%|██▏       | 17000/76334 [00:01<00:03, 16482.90 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  33%|███▎      | 25000/76334 [00:01<00:02, 18384.73 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  43%|████▎     | 33000/76334 [00:01<00:02, 19400.57 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  54%|█████▎    | 41000/76334 [00:02<00:01, 19658.77 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  64%|██████▍   | 49000/76334 [00:02<00:01, 20319.15 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  75%|███████▍  | 57000/76334 [00:03<00:00, 20665.83 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  85%|████████▌ | 65000/76334 [00:03<00:00, 21042.05 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  95%|█████████▌| 72541/76334 [00:03<00:00, 24363.12 examples/s]\n",
      "Dropping Long Sequences (num_proc=8): 100%|██████████| 76334/76334 [00:03<00:00, 20095.77 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   1%|          | 536/76334 [00:00<00:14, 5119.52 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   4%|▍         | 3433/76334 [00:00<00:03, 18734.86 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   8%|▊         | 5815/76334 [00:00<00:03, 20978.47 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  10%|█         | 7979/76334 [00:00<00:04, 15870.12 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  14%|█▎        | 10492/76334 [00:00<00:03, 18382.62 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  17%|█▋        | 12965/76334 [00:00<00:03, 20223.69 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  20%|██        | 15457/76334 [00:00<00:02, 21584.23 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  23%|██▎       | 17795/76334 [00:00<00:03, 17804.10 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  26%|██▋       | 20228/76334 [00:01<00:02, 19445.61 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  30%|██▉       | 22681/76334 [00:01<00:02, 20782.13 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  33%|███▎      | 24938/76334 [00:01<00:02, 17798.96 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  36%|███▌      | 27493/76334 [00:01<00:02, 19684.16 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  39%|███▉      | 30006/76334 [00:01<00:02, 21097.99 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  42%|████▏     | 32343/76334 [00:01<00:02, 18527.68 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  45%|████▌     | 34703/76334 [00:01<00:02, 19771.78 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  49%|████▊     | 37189/76334 [00:01<00:01, 21077.89 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  52%|█████▏    | 39456/76334 [00:02<00:01, 20196.45 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  55%|█████▍    | 41634/76334 [00:02<00:01, 19206.44 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  58%|█████▊    | 44129/76334 [00:02<00:01, 20692.16 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  61%|██████    | 46606/76334 [00:02<00:01, 21780.62 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  64%|██████▍   | 48854/76334 [00:02<00:01, 19049.18 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  67%|██████▋   | 51072/76334 [00:02<00:01, 19841.92 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  70%|███████   | 53494/76334 [00:02<00:01, 21008.95 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  73%|███████▎  | 55669/76334 [00:02<00:01, 19247.54 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  76%|███████▌  | 57766/76334 [00:02<00:00, 19103.87 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  79%|███████▉  | 60215/76334 [00:03<00:00, 20544.04 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  82%|████████▏ | 62449/76334 [00:03<00:00, 20358.56 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  85%|████████▍ | 64551/76334 [00:03<00:00, 19068.27 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  88%|████████▊ | 66883/76334 [00:03<00:00, 19330.90 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  91%|█████████ | 69339/76334 [00:03<00:00, 20705.71 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  94%|█████████▍| 71611/76334 [00:03<00:00, 19696.51 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  97%|█████████▋| 73698/76334 [00:03<00:00, 19770.19 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  99%|█████████▉| 75708/76334 [00:03<00:00, 16996.45 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8): 100%|██████████| 76334/76334 [00:04<00:00, 18914.35 examples/s]\n",
      "NCCL version 2.21.5+cuda12.1\n",
      "algo-1:436:638 [0] nccl_net_ofi_create_plugin:204 NCCL WARN NET/OFI Failed to initialize sendrecv protocol\n",
      "algo-1:436:638 [0] nccl_net_ofi_create_plugin:257 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "algo-3:435:490 [0] nccl_net_ofi_create_plugin:204 NCCL WARN NET/OFI Failed to initialize sendrecv protocol\n",
      "algo-3:435:490 [0] nccl_net_ofi_create_plugin:257 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "algo-4:435:490 [0] nccl_net_ofi_create_plugin:204 NCCL WARN NET/OFI Failed to initialize sendrecv protocol\n",
      "algo-4:435:490 [0] nccl_net_ofi_create_plugin:257 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "[2024-07-08 18:11:51,500] [INFO] [axolotl.load_tokenized_prepared_datasets:183] [PID:435] [RANK:0] Unable to find prepared dataset in last_run_prepared/515d28cedb8f11b4423ad59630e8364d#033[39m\n",
      "[2024-07-08 18:11:51,501] [INFO] [axolotl.load_tokenized_prepared_datasets:184] [PID:435] [RANK:0] Loading raw datasets...#033[39m\n",
      "#033[33m[2024-07-08 18:11:51,501] [WARNING] [axolotl.load_tokenized_prepared_datasets:186] [PID:435] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.#033[39m\n",
      "[2024-07-08 18:11:51,501] [INFO] [axolotl.load_tokenized_prepared_datasets:193] [PID:435] [RANK:0] No seed provided, using default seed of 42#033[39m\n",
      "algo-2:435:490 [0] nccl_net_ofi_create_plugin:204 NCCL WARN NET/OFI Failed to initialize sendrecv protocol\n",
      "algo-2:435:490 [0] nccl_net_ofi_create_plugin:257 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "[2024-07-08 18:11:51,500] [INFO] [axolotl.load_tokenized_prepared_datasets:183] [PID:435] [RANK:0] Unable to find prepared dataset in last_run_prepared/515d28cedb8f11b4423ad59630e8364d#033[39m\n",
      "[2024-07-08 18:11:51,500] [INFO] [axolotl.load_tokenized_prepared_datasets:184] [PID:435] [RANK:0] Loading raw datasets...#033[39m\n",
      "#033[33m[2024-07-08 18:11:51,500] [WARNING] [axolotl.load_tokenized_prepared_datasets:186] [PID:435] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.#033[39m\n",
      "[2024-07-08 18:11:51,500] [INFO] [axolotl.load_tokenized_prepared_datasets:193] [PID:435] [RANK:0] No seed provided, using default seed of 42#033[39m\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "[2024-07-08 18:11:51,499] [INFO] [axolotl.load_tokenized_prepared_datasets:427] [PID:436] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/515d28cedb8f11b4423ad59630e8364d#033[39m\n",
      "Saving the dataset (0/1 shards):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Saving the dataset (0/1 shards):  34%|███▍      | 26000/76334 [00:00<00:00, 248655.63 examples/s]\n",
      "Saving the dataset (0/1 shards):  68%|██████▊   | 52000/76334 [00:00<00:00, 252526.70 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 76334/76334 [00:00<00:00, 252526.70 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 76334/76334 [00:00<00:00, 252943.67 examples/s]\n",
      "[2024-07-08 18:11:51,500] [INFO] [axolotl.load_tokenized_prepared_datasets:183] [PID:435] [RANK:0] Unable to find prepared dataset in last_run_prepared/515d28cedb8f11b4423ad59630e8364d#033[39m\n",
      "[2024-07-08 18:11:51,500] [INFO] [axolotl.load_tokenized_prepared_datasets:184] [PID:435] [RANK:0] Loading raw datasets...#033[39m\n",
      "#033[33m[2024-07-08 18:11:51,500] [WARNING] [axolotl.load_tokenized_prepared_datasets:186] [PID:435] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.#033[39m\n",
      "[2024-07-08 18:11:51,500] [INFO] [axolotl.load_tokenized_prepared_datasets:193] [PID:435] [RANK:0] No seed provided, using default seed of 42#033[39m\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 76334 examples [00:13, 5833.94 examples/s]\n",
      "Generating train split: 76334 examples [00:13, 5812.34 examples/s]\n",
      "[2024-07-08 18:12:04,698] [INFO] [axolotl.get_dataset_wrapper:540] [PID:435] [RANK:0] Loading dataset with base_type: sharegpt.load_role and prompt_style: None#033[39m\n",
      "Tokenizing Prompts (num_proc=8):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   0%|          | 15/76334 [00:00<15:47, 80.54 examples/s]\n",
      "Generating train split: 76334 examples [00:13, 5665.50 examples/s]\n",
      "Generating train split: 76334 examples [00:13, 5643.39 examples/s]\n",
      "[2024-07-08 18:12:05,113] [INFO] [axolotl.get_dataset_wrapper:540] [PID:435] [RANK:0] Loading dataset with base_type: sharegpt.load_role and prompt_style: None#033[39m\n",
      "Tokenizing Prompts (num_proc=8):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Generating train split: 76334 examples [00:13, 5812.57 examples/s]\n",
      "Generating train split: 76334 examples [00:13, 5790.37 examples/s]\n",
      "[2024-07-08 18:12:04,743] [INFO] [axolotl.get_dataset_wrapper:540] [PID:435] [RANK:0] Loading dataset with base_type: sharegpt.load_role and prompt_style: None#033[39m\n",
      "Tokenizing Prompts (num_proc=8):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   0%|          | 19/76334 [00:00<12:40, 100.31 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   0%|          | 328/76334 [00:00<00:56, 1353.20 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   1%|          | 629/76334 [00:00<00:39, 1912.03 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   1%|          | 933/76334 [00:00<00:32, 2291.37 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   0%|          | 18/76334 [00:00<12:25, 102.37 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   0%|          | 238/76334 [00:00<01:13, 1042.26 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   1%|          | 525/76334 [00:00<00:43, 1735.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   1%|          | 811/76334 [00:00<00:35, 2108.03 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   1%|▏         | 1099/76334 [00:00<00:31, 2356.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   2%|▏         | 1358/76334 [00:00<00:30, 2421.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   2%|▏         | 1629/76334 [00:00<00:30, 2472.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   2%|▏         | 1900/76334 [00:00<00:29, 2539.69 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   3%|▎         | 2163/76334 [00:00<00:29, 2535.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   0%|          | 261/76334 [00:00<01:08, 1104.99 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   1%|          | 536/76334 [00:00<00:43, 1728.67 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   1%|          | 834/76334 [00:00<00:35, 2152.08 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   1%|▏         | 1110/76334 [00:00<00:32, 2344.33 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   2%|▏         | 1401/76334 [00:00<00:30, 2479.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   2%|▏         | 1684/76334 [00:00<00:28, 2575.67 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   3%|▎         | 1958/76334 [00:00<00:28, 2598.22 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   3%|▎         | 2228/76334 [00:01<00:28, 2600.24 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   3%|▎         | 2505/76334 [00:01<00:28, 2604.92 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   4%|▎         | 2800/76334 [00:01<00:27, 2699.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   4%|▍         | 3081/76334 [00:01<00:27, 2707.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   4%|▍         | 3375/76334 [00:01<00:26, 2745.35 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   5%|▍         | 3663/76334 [00:01<00:26, 2749.52 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   2%|▏         | 1223/76334 [00:00<00:30, 2472.35 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   2%|▏         | 1512/76334 [00:00<00:28, 2590.08 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   2%|▏         | 1801/76334 [00:00<00:28, 2647.92 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   3%|▎         | 2087/76334 [00:00<00:28, 2647.33 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   3%|▎         | 2358/76334 [00:01<00:27, 2658.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   3%|▎         | 2653/76334 [00:01<00:26, 2733.22 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   4%|▍         | 2932/76334 [00:01<00:26, 2732.90 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   4%|▍         | 3220/76334 [00:01<00:26, 2747.13 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   5%|▍         | 3497/76334 [00:01<00:26, 2748.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   5%|▍         | 3785/76334 [00:01<00:26, 2752.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   3%|▎         | 2432/76334 [00:01<00:28, 2565.67 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   4%|▎         | 2721/76334 [00:01<00:27, 2644.61 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   4%|▍         | 3007/76334 [00:01<00:27, 2678.66 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   4%|▍         | 3290/76334 [00:01<00:27, 2673.81 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   5%|▍         | 3562/76334 [00:01<00:27, 2664.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   5%|▌         | 3848/76334 [00:01<00:27, 2649.69 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   5%|▌         | 4116/76334 [00:01<00:27, 2603.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   6%|▌         | 4389/76334 [00:01<00:27, 2605.40 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   6%|▌         | 4667/76334 [00:01<00:27, 2626.06 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   6%|▋         | 4931/76334 [00:02<00:27, 2595.48 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   5%|▌         | 4073/76334 [00:01<00:26, 2760.34 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   6%|▌         | 4361/76334 [00:01<00:26, 2754.55 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   6%|▌         | 4651/76334 [00:01<00:25, 2778.20 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   6%|▋         | 4939/76334 [00:01<00:25, 2792.35 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   7%|▋         | 5230/76334 [00:02<00:25, 2808.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   7%|▋         | 5522/76334 [00:02<00:25, 2777.54 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   8%|▊         | 5802/76334 [00:02<00:26, 2705.56 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   8%|▊         | 6086/76334 [00:02<00:26, 2699.80 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   8%|▊         | 6361/76334 [00:02<00:26, 2689.46 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   9%|▊         | 6633/76334 [00:02<00:26, 2668.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   5%|▌         | 3952/76334 [00:01<00:26, 2763.04 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   6%|▌         | 4248/76334 [00:01<00:26, 2741.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   6%|▌         | 4531/76334 [00:01<00:26, 2754.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   6%|▋         | 4809/76334 [00:01<00:26, 2746.19 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   7%|▋         | 5092/76334 [00:02<00:25, 2745.22 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   7%|▋         | 5369/76334 [00:02<00:26, 2719.76 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   7%|▋         | 5652/76334 [00:02<00:26, 2673.32 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   8%|▊         | 5932/76334 [00:02<00:26, 2658.89 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   8%|▊         | 6205/76334 [00:02<00:26, 2664.53 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   8%|▊         | 6472/76334 [00:02<00:26, 2651.77 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   7%|▋         | 5211/76334 [00:02<00:26, 2639.84 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   7%|▋         | 5483/76334 [00:02<00:26, 2630.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   8%|▊         | 5758/76334 [00:02<00:26, 2644.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   8%|▊         | 6028/76334 [00:02<00:26, 2628.29 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   8%|▊         | 6297/76334 [00:02<00:26, 2605.08 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   9%|▊         | 6577/76334 [00:02<00:26, 2657.89 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   9%|▉         | 6852/76334 [00:02<00:26, 2593.05 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   9%|▉         | 7132/76334 [00:02<00:26, 2603.57 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  10%|▉         | 7394/76334 [00:02<00:26, 2593.00 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   9%|▉         | 6910/76334 [00:02<00:26, 2650.77 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   9%|▉         | 7187/76334 [00:02<00:25, 2674.32 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  10%|▉         | 7458/76334 [00:02<00:25, 2657.63 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  10%|█         | 7734/76334 [00:03<00:26, 2598.84 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  10%|█         | 8010/76334 [00:03<00:31, 2143.24 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  11%|█         | 8244/76334 [00:03<00:31, 2136.56 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  11%|█         | 8518/76334 [00:03<00:29, 2277.01 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  12%|█▏        | 8808/76334 [00:03<00:27, 2421.43 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   9%|▉         | 6751/76334 [00:02<00:26, 2653.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):   9%|▉         | 7034/76334 [00:02<00:25, 2678.02 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  10%|▉         | 7310/76334 [00:02<00:25, 2676.83 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  10%|▉         | 7581/76334 [00:02<00:25, 2644.91 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  10%|█         | 7848/76334 [00:03<00:26, 2589.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  11%|█         | 8120/76334 [00:03<00:34, 1994.06 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  11%|█         | 8409/76334 [00:03<00:31, 2175.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  11%|█▏        | 8708/76334 [00:03<00:28, 2361.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  12%|█▏        | 8990/76334 [00:03<00:27, 2455.10 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  10%|█         | 7670/76334 [00:03<00:26, 2581.92 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  10%|█         | 7934/76334 [00:03<00:32, 2134.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  11%|█         | 8165/76334 [00:03<00:33, 2034.12 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  11%|█         | 8405/76334 [00:03<00:32, 2112.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  11%|█▏        | 8686/76334 [00:03<00:29, 2274.42 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  12%|█▏        | 8971/76334 [00:03<00:28, 2394.70 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  12%|█▏        | 9226/76334 [00:03<00:27, 2401.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  12%|█▏        | 9509/76334 [00:03<00:26, 2503.06 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  13%|█▎        | 9768/76334 [00:04<00:26, 2522.95 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  12%|█▏        | 9290/76334 [00:03<00:26, 2565.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  13%|█▎        | 9581/76334 [00:03<00:25, 2638.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  13%|█▎        | 9872/76334 [00:03<00:24, 2678.37 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  13%|█▎        | 10165/76334 [00:04<00:24, 2667.81 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  14%|█▎        | 10463/76334 [00:04<00:24, 2739.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  14%|█▍        | 10747/76334 [00:04<00:24, 2700.76 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  14%|█▍        | 11031/76334 [00:04<00:24, 2676.22 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  15%|█▍        | 11317/76334 [00:04<00:24, 2690.95 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  15%|█▌        | 11607/76334 [00:04<00:23, 2729.77 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  12%|█▏        | 9099/76334 [00:03<00:26, 2533.54 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  12%|█▏        | 9365/76334 [00:03<00:26, 2553.57 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  13%|█▎        | 9634/76334 [00:03<00:25, 2582.08 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  13%|█▎        | 9899/76334 [00:03<00:25, 2598.71 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  13%|█▎        | 10191/76334 [00:04<00:24, 2659.72 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  14%|█▎        | 10490/76334 [00:04<00:24, 2709.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  14%|█▍        | 10780/76334 [00:04<00:23, 2751.88 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  15%|█▍        | 11072/76334 [00:04<00:23, 2747.26 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  15%|█▍        | 11366/76334 [00:04<00:23, 2755.28 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  15%|█▌        | 11650/76334 [00:04<00:23, 2760.02 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  16%|█▌        | 11929/76334 [00:04<00:23, 2750.93 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  13%|█▎        | 10041/76334 [00:04<00:25, 2561.54 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  14%|█▎        | 10319/76334 [00:04<00:25, 2596.44 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  14%|█▍        | 10601/76334 [00:04<00:24, 2649.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  14%|█▍        | 10884/76334 [00:04<00:24, 2691.38 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  15%|█▍        | 11157/76334 [00:04<00:25, 2596.71 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  15%|█▍        | 11427/76334 [00:04<00:24, 2619.97 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  15%|█▌        | 11707/76334 [00:04<00:24, 2634.13 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  16%|█▌        | 11988/76334 [00:04<00:24, 2599.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  16%|█▌        | 12264/76334 [00:04<00:24, 2602.24 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  16%|█▋        | 12534/76334 [00:05<00:24, 2595.44 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  16%|█▌        | 11896/76334 [00:04<00:23, 2758.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  16%|█▌        | 12175/76334 [00:04<00:23, 2716.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  16%|█▋        | 12457/76334 [00:04<00:23, 2715.99 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  17%|█▋        | 12735/76334 [00:04<00:23, 2714.01 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  17%|█▋        | 13022/76334 [00:05<00:23, 2711.78 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  17%|█▋        | 13300/76334 [00:05<00:23, 2703.71 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  18%|█▊        | 13582/76334 [00:05<00:23, 2687.66 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  18%|█▊        | 13864/76334 [00:05<00:23, 2698.81 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  19%|█▊        | 14135/76334 [00:05<00:23, 2681.80 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  19%|█▉        | 14414/76334 [00:05<00:23, 2675.80 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  16%|█▌        | 12217/76334 [00:04<00:23, 2753.33 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  16%|█▋        | 12499/76334 [00:04<00:23, 2723.35 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  17%|█▋        | 12786/76334 [00:04<00:23, 2689.53 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  17%|█▋        | 13065/76334 [00:05<00:23, 2694.22 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  17%|█▋        | 13341/76334 [00:05<00:23, 2684.69 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  18%|█▊        | 13616/76334 [00:05<00:23, 2656.59 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  18%|█▊        | 13893/76334 [00:05<00:23, 2663.70 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  19%|█▊        | 14182/76334 [00:05<00:23, 2701.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  19%|█▉        | 14460/76334 [00:05<00:22, 2693.13 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  19%|█▉        | 14740/76334 [00:05<00:22, 2720.06 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  17%|█▋        | 12825/76334 [00:05<00:24, 2637.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  17%|█▋        | 13093/76334 [00:05<00:24, 2617.80 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  18%|█▊        | 13366/76334 [00:05<00:24, 2620.52 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  18%|█▊        | 13640/76334 [00:05<00:23, 2614.89 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  18%|█▊        | 13915/76334 [00:05<00:23, 2623.00 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  19%|█▊        | 14184/76334 [00:05<00:23, 2629.56 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  19%|█▉        | 14455/76334 [00:05<00:23, 2632.24 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  19%|█▉        | 14727/76334 [00:05<00:23, 2635.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  20%|█▉        | 14994/76334 [00:05<00:23, 2621.03 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  20%|██        | 15273/76334 [00:06<00:23, 2652.48 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  19%|█▉        | 14696/76334 [00:05<00:22, 2709.72 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  20%|█▉        | 14987/76334 [00:05<00:22, 2744.47 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  20%|█▉        | 15264/76334 [00:05<00:22, 2724.87 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  20%|██        | 15552/76334 [00:06<00:22, 2757.02 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  21%|██        | 15833/76334 [00:06<00:24, 2441.70 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  21%|██        | 16094/76334 [00:06<00:27, 2167.73 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  21%|██▏       | 16334/76334 [00:06<00:28, 2135.28 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  22%|██▏       | 16606/76334 [00:06<00:26, 2272.92 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  22%|██▏       | 16878/76334 [00:06<00:24, 2386.82 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  20%|█▉        | 15021/76334 [00:05<00:22, 2720.26 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  20%|██        | 15301/76334 [00:05<00:22, 2708.99 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  20%|██        | 15577/76334 [00:06<00:23, 2548.66 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  21%|██        | 15876/76334 [00:06<00:22, 2657.75 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  21%|██        | 16148/76334 [00:06<00:29, 2049.68 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  21%|██▏       | 16387/76334 [00:06<00:28, 2103.50 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  22%|██▏       | 16655/76334 [00:06<00:26, 2242.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  22%|██▏       | 16916/76334 [00:06<00:25, 2326.27 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  20%|██        | 15554/76334 [00:06<00:22, 2658.30 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  21%|██        | 15824/76334 [00:06<00:24, 2424.38 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  21%|██        | 16076/76334 [00:06<00:28, 2147.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  21%|██▏       | 16311/76334 [00:06<00:29, 2043.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  22%|██▏       | 16565/76334 [00:06<00:27, 2153.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  22%|██▏       | 16842/76334 [00:06<00:25, 2300.80 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  22%|██▏       | 17136/76334 [00:06<00:24, 2379.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  23%|██▎       | 17403/76334 [00:07<00:24, 2453.82 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  22%|██▏       | 17154/76334 [00:06<00:23, 2477.98 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  23%|██▎       | 17437/76334 [00:06<00:22, 2561.13 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  23%|██▎       | 17713/76334 [00:06<00:22, 2601.79 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  24%|██▎       | 17993/76334 [00:07<00:22, 2632.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  24%|██▍       | 18279/76334 [00:07<00:21, 2674.53 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  24%|██▍       | 18555/76334 [00:07<00:21, 2673.11 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  25%|██▍       | 18824/76334 [00:07<00:21, 2643.40 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  25%|██▌       | 19097/76334 [00:07<00:21, 2627.13 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  25%|██▌       | 19363/76334 [00:07<00:21, 2614.21 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  23%|██▎       | 17218/76334 [00:06<00:23, 2496.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  23%|██▎       | 17483/76334 [00:06<00:23, 2506.92 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  23%|██▎       | 17750/76334 [00:06<00:23, 2543.87 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  24%|██▎       | 18035/76334 [00:07<00:22, 2621.63 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  24%|██▍       | 18322/76334 [00:07<00:21, 2664.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  24%|██▍       | 18601/76334 [00:07<00:21, 2690.53 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  25%|██▍       | 18880/76334 [00:07<00:21, 2683.47 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  25%|██▌       | 19156/76334 [00:07<00:21, 2664.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  25%|██▌       | 19434/76334 [00:07<00:21, 2676.55 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  26%|██▌       | 19714/76334 [00:07<00:20, 2698.79 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  26%|██▌       | 19637/76334 [00:07<00:21, 2635.41 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  26%|██▌       | 19926/76334 [00:07<00:21, 2664.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  26%|██▋       | 20205/76334 [00:07<00:21, 2665.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  27%|██▋       | 20484/76334 [00:07<00:20, 2669.59 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  23%|██▎       | 17671/76334 [00:07<00:23, 2495.13 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  23%|██▎       | 17933/76334 [00:07<00:23, 2505.05 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  24%|██▍       | 18215/76334 [00:07<00:22, 2584.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  24%|██▍       | 18483/76334 [00:07<00:22, 2604.19 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  25%|██▍       | 18751/76334 [00:07<00:22, 2582.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  25%|██▍       | 19021/76334 [00:07<00:22, 2561.25 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  25%|██▌       | 19302/76334 [00:07<00:21, 2614.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  26%|██▌       | 19573/76334 [00:07<00:21, 2612.19 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  26%|██▌       | 19856/76334 [00:07<00:21, 2669.47 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  26%|██▋       | 20130/76334 [00:08<00:21, 2666.34 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  26%|██▌       | 20000/76334 [00:07<00:20, 2700.92 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  27%|██▋       | 20275/76334 [00:07<00:20, 2683.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  27%|██▋       | 20548/76334 [00:07<00:20, 2657.30 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  27%|██▋       | 20843/76334 [00:08<00:20, 2730.28 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  28%|██▊       | 21132/76334 [00:08<00:20, 2726.55 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  28%|██▊       | 21405/76334 [00:08<00:20, 2719.38 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  28%|██▊       | 21692/76334 [00:08<00:20, 2721.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  29%|██▉       | 21978/76334 [00:08<00:20, 2703.21 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  29%|██▉       | 22260/76334 [00:08<00:20, 2698.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  30%|██▉       | 22537/76334 [00:08<00:19, 2689.91 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  30%|██▉       | 22810/76334 [00:08<00:20, 2638.96 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  27%|██▋       | 20758/76334 [00:08<00:20, 2658.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  28%|██▊       | 21043/76334 [00:08<00:20, 2695.73 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  28%|██▊       | 21318/76334 [00:08<00:20, 2706.93 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  28%|██▊       | 21598/76334 [00:08<00:20, 2703.19 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  29%|██▊       | 21874/76334 [00:08<00:20, 2660.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  29%|██▉       | 22163/76334 [00:08<00:19, 2712.65 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  29%|██▉       | 22446/76334 [00:08<00:19, 2729.12 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  30%|██▉       | 22722/76334 [00:08<00:20, 2670.78 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  30%|███       | 22998/76334 [00:08<00:19, 2683.67 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  27%|██▋       | 20405/76334 [00:08<00:21, 2601.96 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  27%|██▋       | 20683/76334 [00:08<00:21, 2602.78 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  27%|██▋       | 20958/76334 [00:08<00:21, 2626.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  28%|██▊       | 21242/76334 [00:08<00:20, 2634.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  28%|██▊       | 21517/76334 [00:08<00:20, 2640.36 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  29%|██▊       | 21794/76334 [00:08<00:20, 2656.72 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  29%|██▉       | 22070/76334 [00:08<00:20, 2657.80 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  29%|██▉       | 22346/76334 [00:08<00:20, 2635.38 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  30%|██▉       | 22623/76334 [00:09<00:20, 2609.88 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  30%|██▉       | 22888/76334 [00:09<00:20, 2585.04 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  30%|███       | 23085/76334 [00:08<00:20, 2642.59 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  31%|███       | 23350/76334 [00:09<00:20, 2627.90 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  31%|███       | 23632/76334 [00:09<00:20, 2633.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  31%|███▏      | 23899/76334 [00:09<00:24, 2182.03 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  32%|███▏      | 24138/76334 [00:09<00:23, 2214.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  32%|███▏      | 24376/76334 [00:09<00:23, 2167.27 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  32%|███▏      | 24646/76334 [00:09<00:22, 2270.30 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  33%|███▎      | 24928/76334 [00:09<00:21, 2412.17 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  33%|███▎      | 25208/76334 [00:09<00:20, 2504.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  33%|███▎      | 25483/76334 [00:09<00:19, 2555.84 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  30%|███       | 23275/76334 [00:09<00:20, 2610.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  31%|███       | 23559/76334 [00:09<00:19, 2640.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  31%|███       | 23832/76334 [00:09<00:22, 2377.56 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  32%|███▏      | 24075/76334 [00:09<00:24, 2139.18 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  32%|███▏      | 24309/76334 [00:09<00:25, 2035.47 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  32%|███▏      | 24594/76334 [00:09<00:23, 2232.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  33%|███▎      | 24879/76334 [00:09<00:21, 2372.18 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  33%|███▎      | 25182/76334 [00:09<00:20, 2544.27 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  33%|███▎      | 25461/76334 [00:09<00:19, 2588.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  34%|███▎      | 25745/76334 [00:10<00:19, 2642.50 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  30%|███       | 23162/76334 [00:09<00:21, 2495.70 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  31%|███       | 23415/76334 [00:09<00:21, 2490.97 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  31%|███       | 23666/76334 [00:09<00:21, 2485.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  31%|███▏      | 23918/76334 [00:09<00:24, 2138.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  32%|███▏      | 24143/76334 [00:09<00:26, 1994.03 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  32%|███▏      | 24386/76334 [00:09<00:24, 2097.41 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  32%|███▏      | 24649/76334 [00:09<00:23, 2225.79 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  33%|███▎      | 24921/76334 [00:10<00:22, 2335.84 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  33%|███▎      | 25198/76334 [00:10<00:20, 2440.81 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  34%|███▎      | 25757/76334 [00:10<00:19, 2588.91 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  34%|███▍      | 26035/76334 [00:10<00:19, 2621.30 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  34%|███▍      | 26333/76334 [00:10<00:18, 2700.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  35%|███▍      | 26619/76334 [00:10<00:18, 2715.36 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  35%|███▌      | 26917/76334 [00:10<00:17, 2762.70 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  36%|███▌      | 27205/76334 [00:10<00:17, 2764.61 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  36%|███▌      | 27482/76334 [00:10<00:17, 2753.93 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  36%|███▋      | 27758/76334 [00:10<00:17, 2733.65 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  34%|███▍      | 26015/76334 [00:10<00:19, 2613.50 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  34%|███▍      | 26299/76334 [00:10<00:18, 2654.03 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  35%|███▍      | 26577/76334 [00:10<00:18, 2684.37 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  35%|███▌      | 26863/76334 [00:10<00:18, 2715.88 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  36%|███▌      | 27141/76334 [00:10<00:18, 2720.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  36%|███▌      | 27450/76334 [00:10<00:17, 2818.17 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  36%|███▋      | 27745/76334 [00:10<00:17, 2818.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  37%|███▋      | 28033/76334 [00:10<00:17, 2729.66 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  37%|███▋      | 28320/76334 [00:11<00:17, 2744.76 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  37%|███▋      | 28039/76334 [00:10<00:17, 2745.32 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  37%|███▋      | 28314/76334 [00:10<00:17, 2714.32 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  37%|███▋      | 28607/76334 [00:11<00:17, 2750.41 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  38%|███▊      | 28883/76334 [00:11<00:17, 2732.71 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  38%|███▊      | 29170/76334 [00:11<00:17, 2742.45 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  33%|███▎      | 25476/76334 [00:10<00:20, 2470.87 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  34%|███▎      | 25750/76334 [00:10<00:19, 2531.65 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  34%|███▍      | 26021/76334 [00:10<00:19, 2554.27 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  34%|███▍      | 26312/76334 [00:10<00:18, 2643.43 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  35%|███▍      | 26587/76334 [00:10<00:18, 2625.26 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  35%|███▌      | 26873/76334 [00:10<00:18, 2674.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  36%|███▌      | 27154/76334 [00:10<00:18, 2674.57 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  36%|███▌      | 27423/76334 [00:10<00:18, 2664.04 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  36%|███▋      | 27706/76334 [00:11<00:18, 2668.13 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  37%|███▋      | 27985/76334 [00:11<00:18, 2685.15 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  37%|███▋      | 28260/76334 [00:11<00:18, 2589.55 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  39%|███▊      | 29468/76334 [00:11<00:16, 2790.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  39%|███▉      | 29750/76334 [00:11<00:17, 2711.83 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  39%|███▉      | 30027/76334 [00:11<00:17, 2719.33 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  40%|███▉      | 30309/76334 [00:11<00:16, 2717.52 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  40%|████      | 30588/76334 [00:11<00:17, 2639.88 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  40%|████      | 30862/76334 [00:11<00:17, 2592.42 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  41%|████      | 31122/76334 [00:12<00:17, 2582.21 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  41%|████      | 31399/76334 [00:12<00:17, 2612.90 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  42%|████▏     | 31686/76334 [00:12<00:16, 2649.98 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  42%|████▏     | 31962/76334 [00:12<00:20, 2130.11 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  42%|████▏     | 32195/76334 [00:12<00:20, 2162.93 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  37%|███▋      | 28600/76334 [00:11<00:17, 2687.13 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  38%|███▊      | 28888/76334 [00:11<00:17, 2731.94 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  38%|███▊      | 29175/76334 [00:11<00:17, 2726.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  39%|███▊      | 29458/76334 [00:11<00:17, 2739.40 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  39%|███▉      | 29740/76334 [00:11<00:17, 2721.01 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  39%|███▉      | 30038/76334 [00:11<00:16, 2775.97 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  40%|███▉      | 30318/76334 [00:11<00:17, 2658.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  40%|████      | 30600/76334 [00:11<00:17, 2646.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  40%|████      | 30866/76334 [00:11<00:17, 2642.30 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  41%|████      | 31145/76334 [00:12<00:17, 2651.90 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  41%|████      | 31420/76334 [00:12<00:16, 2666.69 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  37%|███▋      | 28543/76334 [00:11<00:18, 2633.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  38%|███▊      | 28830/76334 [00:11<00:17, 2672.76 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  38%|███▊      | 29101/76334 [00:11<00:17, 2677.28 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  38%|███▊      | 29380/76334 [00:11<00:17, 2678.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  39%|███▉      | 29652/76334 [00:11<00:17, 2667.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  39%|███▉      | 29922/76334 [00:11<00:17, 2657.41 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  40%|███▉      | 30203/76334 [00:12<00:17, 2609.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  40%|███▉      | 30467/76334 [00:12<00:17, 2605.98 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  40%|████      | 30739/76334 [00:12<00:18, 2477.69 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  41%|████      | 30996/76334 [00:12<00:18, 2491.96 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  42%|████▏     | 31697/76334 [00:12<00:17, 2558.67 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  42%|████▏     | 31962/76334 [00:12<00:19, 2261.22 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  42%|████▏     | 32195/76334 [00:12<00:20, 2171.34 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  42%|████▏     | 32423/76334 [00:12<00:20, 2182.30 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  43%|████▎     | 32709/76334 [00:12<00:18, 2335.08 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  43%|████▎     | 32999/76334 [00:12<00:17, 2480.78 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  44%|████▎     | 33287/76334 [00:12<00:16, 2571.75 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  44%|████▍     | 33574/76334 [00:13<00:16, 2625.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  43%|████▎     | 32464/76334 [00:12<00:19, 2290.96 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  43%|████▎     | 32729/76334 [00:12<00:18, 2381.90 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  43%|████▎     | 33020/76334 [00:12<00:17, 2518.90 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  44%|████▎     | 33304/76334 [00:12<00:16, 2607.02 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  44%|████▍     | 33575/76334 [00:13<00:16, 2605.08 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  44%|████▍     | 33847/76334 [00:13<00:16, 2629.83 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  45%|████▍     | 34132/76334 [00:13<00:15, 2683.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  45%|████▌     | 34421/76334 [00:13<00:15, 2717.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  45%|████▌     | 34696/76334 [00:13<00:15, 2698.29 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  46%|████▌     | 34979/76334 [00:13<00:15, 2723.05 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  41%|████      | 31253/76334 [00:12<00:17, 2509.38 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  41%|████▏     | 31510/76334 [00:12<00:18, 2486.06 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  42%|████▏     | 31761/76334 [00:12<00:18, 2432.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  42%|████▏     | 32020/76334 [00:12<00:20, 2201.97 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  42%|████▏     | 32248/76334 [00:12<00:21, 2081.59 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  43%|████▎     | 32467/76334 [00:13<00:20, 2099.82 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  43%|████▎     | 32748/76334 [00:13<00:19, 2275.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  43%|████▎     | 33023/76334 [00:13<00:18, 2366.17 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  44%|████▎     | 33304/76334 [00:13<00:17, 2476.06 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  44%|████▍     | 33855/76334 [00:13<00:15, 2659.28 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  45%|████▍     | 34137/76334 [00:13<00:15, 2678.83 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  45%|████▌     | 34420/76334 [00:13<00:15, 2694.72 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  45%|████▌     | 34708/76334 [00:13<00:15, 2711.93 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  46%|████▌     | 34997/76334 [00:13<00:15, 2749.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  46%|████▌     | 35280/76334 [00:13<00:15, 2702.31 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  47%|████▋     | 35567/76334 [00:13<00:14, 2731.40 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  47%|████▋     | 35841/76334 [00:13<00:14, 2709.32 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  47%|████▋     | 36125/76334 [00:13<00:14, 2714.35 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  48%|████▊     | 36397/76334 [00:14<00:14, 2701.13 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  46%|████▌     | 35263/76334 [00:13<00:14, 2748.22 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  47%|████▋     | 35540/76334 [00:13<00:14, 2721.97 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  47%|████▋     | 35817/76334 [00:13<00:14, 2721.79 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  47%|████▋     | 36098/76334 [00:13<00:14, 2721.35 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  48%|████▊     | 36378/76334 [00:14<00:14, 2698.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  48%|████▊     | 36659/76334 [00:14<00:14, 2679.11 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  48%|████▊     | 36931/76334 [00:14<00:14, 2651.40 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  49%|████▊     | 37212/76334 [00:14<00:14, 2684.63 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  49%|████▉     | 37498/76334 [00:14<00:14, 2721.95 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  44%|████▍     | 33569/76334 [00:13<00:17, 2511.02 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  44%|████▍     | 33843/76334 [00:13<00:16, 2546.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  45%|████▍     | 34126/76334 [00:13<00:16, 2588.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  45%|████▌     | 34397/76334 [00:13<00:16, 2596.93 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  45%|████▌     | 34670/76334 [00:13<00:15, 2631.34 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  46%|████▌     | 34944/76334 [00:13<00:15, 2632.84 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  46%|████▌     | 35223/76334 [00:14<00:15, 2580.66 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  47%|████▋     | 35498/76334 [00:14<00:15, 2601.18 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  47%|████▋     | 35765/76334 [00:14<00:15, 2561.32 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  47%|████▋     | 36037/76334 [00:14<00:15, 2594.25 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  48%|████▊     | 36674/76334 [00:14<00:14, 2683.70 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  48%|████▊     | 36943/76334 [00:14<00:14, 2665.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  49%|████▉     | 37234/76334 [00:14<00:14, 2699.61 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  49%|████▉     | 37510/76334 [00:14<00:14, 2711.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  49%|████▉     | 37784/76334 [00:14<00:14, 2698.00 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  50%|████▉     | 38059/76334 [00:14<00:14, 2657.53 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  50%|█████     | 38344/76334 [00:14<00:14, 2684.44 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  51%|█████     | 38616/76334 [00:14<00:14, 2663.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  51%|█████     | 38892/76334 [00:15<00:14, 2664.27 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  51%|█████▏    | 39173/76334 [00:15<00:13, 2664.78 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  49%|████▉     | 37777/76334 [00:14<00:14, 2703.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  50%|████▉     | 38061/76334 [00:14<00:14, 2694.42 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  50%|█████     | 38334/76334 [00:14<00:14, 2683.79 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  51%|█████     | 38611/76334 [00:14<00:14, 2687.34 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  51%|█████     | 38890/76334 [00:14<00:13, 2696.44 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  51%|█████▏    | 39169/76334 [00:15<00:13, 2700.29 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  52%|█████▏    | 39441/76334 [00:15<00:13, 2657.10 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  52%|█████▏    | 39708/76334 [00:15<00:15, 2365.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  52%|█████▏    | 39953/76334 [00:15<00:16, 2266.12 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  53%|█████▎    | 40217/76334 [00:15<00:15, 2353.93 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  48%|████▊     | 36311/76334 [00:14<00:15, 2619.04 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  48%|████▊     | 36592/76334 [00:14<00:15, 2555.13 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  48%|████▊     | 36859/76334 [00:14<00:15, 2539.35 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  49%|████▊     | 37138/76334 [00:14<00:15, 2601.44 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  49%|████▉     | 37421/76334 [00:14<00:14, 2616.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  49%|████▉     | 37704/76334 [00:15<00:14, 2675.27 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  50%|████▉     | 37978/76334 [00:15<00:14, 2633.46 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  50%|█████     | 38255/76334 [00:15<00:14, 2649.71 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  50%|█████     | 38530/76334 [00:15<00:14, 2636.73 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  51%|█████     | 38796/76334 [00:15<00:14, 2606.44 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  51%|█████     | 39065/76334 [00:15<00:14, 2593.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  52%|█████▏    | 39326/76334 [00:15<00:14, 2581.37 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  52%|█████▏    | 39587/76334 [00:15<00:14, 2546.20 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  52%|█████▏    | 39859/76334 [00:15<00:16, 2277.87 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  53%|█████▎    | 40110/76334 [00:16<00:15, 2300.92 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  53%|█████▎    | 40356/76334 [00:16<00:17, 2078.21 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  53%|█████▎    | 40639/76334 [00:16<00:16, 2230.63 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  54%|█████▎    | 40899/76334 [00:16<00:15, 2289.41 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  54%|█████▍    | 41176/76334 [00:16<00:14, 2395.94 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  54%|█████▍    | 41459/76334 [00:16<00:13, 2492.21 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  55%|█████▍    | 41733/76334 [00:16<00:13, 2555.97 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  55%|█████▌    | 42017/76334 [00:16<00:13, 2611.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  55%|█████▌    | 42284/76334 [00:16<00:13, 2616.76 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  56%|█████▌    | 42555/76334 [00:17<00:12, 2624.36 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  56%|█████▌    | 42850/76334 [00:17<00:12, 2703.63 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  57%|█████▋    | 43138/76334 [00:17<00:12, 2732.61 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  57%|█████▋    | 43417/76334 [00:17<00:12, 2591.21 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  57%|█████▋    | 43692/76334 [00:17<00:12, 2585.90 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  58%|█████▊    | 43956/76334 [00:17<00:12, 2588.87 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  58%|█████▊    | 44227/76334 [00:17<00:12, 2586.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  58%|█████▊    | 44512/76334 [00:17<00:11, 2658.65 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  59%|█████▊    | 44787/76334 [00:17<00:11, 2675.99 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  59%|█████▉    | 45060/76334 [00:17<00:11, 2622.77 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  59%|█████▉    | 45338/76334 [00:18<00:11, 2594.02 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  60%|█████▉    | 45602/76334 [00:18<00:11, 2579.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  60%|██████    | 45873/76334 [00:18<00:11, 2559.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  60%|██████    | 46133/76334 [00:18<00:11, 2535.00 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  61%|██████    | 46407/76334 [00:18<00:11, 2540.68 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  61%|██████    | 46686/76334 [00:18<00:11, 2608.22 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  62%|██████▏   | 46957/76334 [00:18<00:11, 2599.93 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  62%|██████▏   | 47228/76334 [00:18<00:11, 2615.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  62%|██████▏   | 47501/76334 [00:18<00:11, 2594.08 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  63%|██████▎   | 47771/76334 [00:19<00:11, 2488.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  63%|██████▎   | 48033/76334 [00:19<00:12, 2261.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  63%|██████▎   | 48275/76334 [00:19<00:13, 2014.47 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  64%|██████▎   | 48507/76334 [00:19<00:13, 2089.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  52%|█████▏    | 39470/76334 [00:15<00:13, 2735.52 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  52%|█████▏    | 39746/76334 [00:15<00:14, 2505.71 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  52%|█████▏    | 40011/76334 [00:15<00:14, 2530.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  53%|█████▎    | 40275/76334 [00:15<00:16, 2225.72 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  53%|█████▎    | 40517/76334 [00:15<00:15, 2258.45 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  53%|█████▎    | 40804/76334 [00:15<00:14, 2391.55 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  54%|█████▍    | 41085/76334 [00:15<00:14, 2473.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  54%|█████▍    | 41377/76334 [00:16<00:13, 2580.15 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  55%|█████▍    | 41656/76334 [00:16<00:13, 2579.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  53%|█████▎    | 40460/76334 [00:15<00:16, 2203.45 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  53%|█████▎    | 40731/76334 [00:15<00:15, 2308.83 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  54%|█████▎    | 41003/76334 [00:15<00:14, 2386.16 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  54%|█████▍    | 41279/76334 [00:15<00:14, 2482.32 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  54%|█████▍    | 41572/76334 [00:16<00:13, 2585.32 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  55%|█████▍    | 41841/76334 [00:16<00:13, 2588.57 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  55%|█████▌    | 42135/76334 [00:16<00:12, 2650.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  56%|█████▌    | 42403/76334 [00:16<00:12, 2629.33 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  56%|█████▌    | 42693/76334 [00:16<00:12, 2683.99 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  55%|█████▍    | 41935/76334 [00:16<00:13, 2620.81 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  55%|█████▌    | 42234/76334 [00:16<00:12, 2700.96 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  56%|█████▌    | 42523/76334 [00:16<00:12, 2716.81 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  56%|█████▌    | 42815/76334 [00:16<00:12, 2738.45 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  56%|█████▋    | 43115/76334 [00:16<00:11, 2778.29 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  57%|█████▋    | 43402/76334 [00:16<00:11, 2792.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  57%|█████▋    | 43694/76334 [00:16<00:11, 2755.19 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  58%|█████▊    | 43982/76334 [00:16<00:11, 2738.21 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  58%|█████▊    | 44261/76334 [00:17<00:11, 2736.20 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  56%|█████▋    | 42989/76334 [00:16<00:12, 2753.17 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  57%|█████▋    | 43283/76334 [00:16<00:11, 2788.84 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  57%|█████▋    | 43565/76334 [00:16<00:11, 2791.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  57%|█████▋    | 43846/76334 [00:16<00:11, 2741.68 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  58%|█████▊    | 44124/76334 [00:17<00:11, 2700.50 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  58%|█████▊    | 44397/76334 [00:17<00:11, 2688.34 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  59%|█████▊    | 44671/76334 [00:17<00:11, 2673.92 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  59%|█████▉    | 44945/76334 [00:17<00:11, 2689.45 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  59%|█████▉    | 45223/76334 [00:17<00:11, 2687.76 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  60%|█████▉    | 45509/76334 [00:17<00:11, 2729.47 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  58%|█████▊    | 44543/76334 [00:17<00:11, 2734.05 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  59%|█████▊    | 44818/76334 [00:17<00:11, 2689.92 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  59%|█████▉    | 45093/76334 [00:17<00:11, 2657.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  59%|█████▉    | 45370/76334 [00:17<00:11, 2672.68 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  60%|█████▉    | 45651/76334 [00:17<00:11, 2662.33 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  60%|██████    | 45923/76334 [00:17<00:11, 2655.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  61%|██████    | 46204/76334 [00:17<00:11, 2612.31 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  61%|██████    | 46483/76334 [00:17<00:11, 2646.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  61%|██████▏   | 46763/76334 [00:18<00:11, 2661.89 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  62%|██████▏   | 47035/76334 [00:18<00:11, 2650.27 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  62%|██████▏   | 47304/76334 [00:18<00:11, 2634.34 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  60%|█████▉    | 45794/76334 [00:17<00:11, 2615.35 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  60%|██████    | 46061/76334 [00:17<00:11, 2615.27 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  61%|██████    | 46345/76334 [00:17<00:11, 2629.88 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  61%|██████    | 46632/76334 [00:17<00:11, 2661.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  61%|██████▏   | 46921/76334 [00:18<00:10, 2681.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  62%|██████▏   | 47198/76334 [00:18<00:10, 2675.94 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  62%|██████▏   | 47476/76334 [00:18<00:11, 2433.88 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  63%|██████▎   | 47736/76334 [00:18<00:11, 2438.21 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  63%|██████▎   | 48000/76334 [00:18<00:12, 2293.25 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  62%|██████▏   | 47573/76334 [00:18<00:11, 2546.84 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  63%|██████▎   | 47830/76334 [00:18<00:11, 2419.63 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  63%|██████▎   | 48083/76334 [00:18<00:11, 2411.70 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  63%|██████▎   | 48330/76334 [00:18<00:11, 2422.35 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  64%|██████▎   | 48577/76334 [00:18<00:12, 2297.93 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  64%|██████▍   | 48821/76334 [00:18<00:12, 2284.69 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  64%|██████▍   | 49103/76334 [00:19<00:11, 2421.79 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  65%|██████▍   | 49388/76334 [00:19<00:10, 2529.25 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  65%|██████▌   | 49669/76334 [00:19<00:10, 2589.91 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  63%|██████▎   | 48249/76334 [00:18<00:12, 2231.30 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  64%|██████▎   | 48485/76334 [00:18<00:12, 2239.71 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  64%|██████▍   | 48730/76334 [00:18<00:12, 2277.19 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  64%|██████▍   | 49014/76334 [00:18<00:11, 2427.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  65%|██████▍   | 49300/76334 [00:19<00:10, 2548.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  65%|██████▍   | 49572/76334 [00:19<00:10, 2588.95 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  65%|██████▌   | 49871/76334 [00:19<00:09, 2688.81 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  66%|██████▌   | 50156/76334 [00:19<00:09, 2712.57 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  66%|██████▌   | 50446/76334 [00:19<00:09, 2666.21 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  66%|██████▋   | 50734/76334 [00:19<00:09, 2711.99 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  67%|██████▋   | 51032/76334 [00:19<00:09, 2740.34 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  67%|██████▋   | 51311/76334 [00:19<00:09, 2742.84 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  68%|██████▊   | 51594/76334 [00:19<00:09, 2739.65 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  68%|██████▊   | 51873/76334 [00:20<00:09, 2692.22 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  68%|██████▊   | 52144/76334 [00:20<00:09, 2671.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  69%|██████▊   | 52419/76334 [00:20<00:09, 2636.59 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  69%|██████▉   | 52694/76334 [00:20<00:08, 2642.42 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  69%|██████▉   | 52961/76334 [00:20<00:08, 2636.71 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  70%|██████▉   | 53237/76334 [00:20<00:08, 2647.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  65%|██████▌   | 49964/76334 [00:19<00:09, 2683.78 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  66%|██████▌   | 50243/76334 [00:19<00:09, 2683.43 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  66%|██████▌   | 50525/76334 [00:19<00:09, 2705.20 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  67%|██████▋   | 50820/76334 [00:19<00:09, 2752.15 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  67%|██████▋   | 51113/76334 [00:19<00:09, 2758.90 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  67%|██████▋   | 51393/76334 [00:19<00:09, 2702.59 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  68%|██████▊   | 51668/76334 [00:19<00:09, 2654.26 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  68%|██████▊   | 51940/76334 [00:20<00:09, 2574.99 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  68%|██████▊   | 52220/76334 [00:20<00:09, 2626.38 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  69%|██████▉   | 52507/76334 [00:20<00:09, 2638.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  69%|██████▉   | 52773/76334 [00:20<00:08, 2618.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  69%|██████▉   | 53052/76334 [00:20<00:08, 2649.27 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  70%|██████▉   | 53338/76334 [00:20<00:08, 2633.91 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  70%|███████   | 53618/76334 [00:20<00:08, 2673.79 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  64%|██████▍   | 48774/76334 [00:19<00:12, 2224.71 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  64%|██████▍   | 49043/76334 [00:19<00:11, 2327.77 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  65%|██████▍   | 49309/76334 [00:19<00:11, 2406.95 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  65%|██████▍   | 49586/76334 [00:19<00:10, 2481.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  65%|██████▌   | 49878/76334 [00:19<00:10, 2565.76 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  66%|██████▌   | 50170/76334 [00:20<00:09, 2659.50 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  66%|██████▌   | 50457/76334 [00:20<00:09, 2650.96 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  66%|██████▋   | 50739/76334 [00:20<00:09, 2687.46 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  67%|██████▋   | 51015/76334 [00:20<00:09, 2688.31 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  67%|██████▋   | 51301/76334 [00:20<00:09, 2719.22 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  70%|███████   | 53520/76334 [00:20<00:08, 2677.31 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  70%|███████   | 53806/76334 [00:20<00:08, 2686.56 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  71%|███████   | 54089/76334 [00:20<00:08, 2694.66 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  71%|███████   | 54380/76334 [00:20<00:08, 2731.24 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  72%|███████▏  | 54664/76334 [00:21<00:07, 2751.81 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  72%|███████▏  | 54952/76334 [00:21<00:07, 2732.91 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  72%|███████▏  | 55227/76334 [00:21<00:07, 2713.37 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  73%|███████▎  | 55503/76334 [00:21<00:08, 2423.55 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  73%|███████▎  | 55759/76334 [00:21<00:08, 2426.25 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  71%|███████   | 53912/76334 [00:20<00:08, 2733.29 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  71%|███████   | 54189/76334 [00:20<00:08, 2728.01 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  71%|███████▏  | 54463/76334 [00:21<00:08, 2689.77 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  72%|███████▏  | 54743/76334 [00:21<00:08, 2694.61 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  72%|███████▏  | 55013/76334 [00:21<00:07, 2669.96 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  72%|███████▏  | 55289/76334 [00:21<00:07, 2687.87 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  73%|███████▎  | 55564/76334 [00:21<00:08, 2386.20 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  73%|███████▎  | 55812/76334 [00:21<00:08, 2361.19 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  73%|███████▎  | 56066/76334 [00:21<00:08, 2398.04 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  68%|██████▊   | 51585/76334 [00:20<00:09, 2635.20 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  68%|██████▊   | 51867/76334 [00:20<00:09, 2646.61 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  68%|██████▊   | 52144/76334 [00:20<00:09, 2540.06 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  69%|██████▊   | 52415/76334 [00:20<00:09, 2542.84 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  69%|██████▉   | 52688/76334 [00:21<00:09, 2575.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  69%|██████▉   | 52950/76334 [00:21<00:09, 2558.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  70%|██████▉   | 53227/76334 [00:21<00:08, 2596.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  70%|███████   | 53490/76334 [00:21<00:08, 2592.31 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  70%|███████   | 53764/76334 [00:21<00:08, 2602.40 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  71%|███████   | 54048/76334 [00:21<00:08, 2660.33 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  73%|███████▎  | 56012/76334 [00:21<00:08, 2371.08 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  74%|███████▎  | 56258/76334 [00:21<00:08, 2368.52 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  74%|███████▍  | 56505/76334 [00:21<00:09, 2118.12 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  74%|███████▍  | 56776/76334 [00:21<00:08, 2244.42 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  75%|███████▍  | 57059/76334 [00:22<00:08, 2393.90 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  75%|███████▌  | 57349/76334 [00:22<00:07, 2505.48 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  75%|███████▌  | 57631/76334 [00:22<00:07, 2556.13 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  76%|███████▌  | 57904/76334 [00:22<00:07, 2577.91 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  76%|███████▌  | 58174/76334 [00:22<00:06, 2601.53 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  77%|███████▋  | 58459/76334 [00:22<00:06, 2653.72 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  74%|███████▍  | 56310/76334 [00:21<00:08, 2361.54 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  74%|███████▍  | 56573/76334 [00:21<00:08, 2406.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  74%|███████▍  | 56818/76334 [00:21<00:08, 2369.91 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  75%|███████▍  | 57082/76334 [00:22<00:07, 2427.78 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  75%|███████▌  | 57344/76334 [00:22<00:07, 2475.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  76%|███████▌  | 57634/76334 [00:22<00:07, 2581.65 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  76%|███████▌  | 57919/76334 [00:22<00:07, 2614.42 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  76%|███████▋  | 58209/76334 [00:22<00:06, 2671.56 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  77%|███████▋  | 58487/76334 [00:22<00:06, 2695.24 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  77%|███████▋  | 58774/76334 [00:22<00:06, 2678.80 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  71%|███████   | 54318/76334 [00:21<00:08, 2653.77 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  72%|███████▏  | 54590/76334 [00:21<00:08, 2660.50 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  72%|███████▏  | 54867/76334 [00:21<00:08, 2637.82 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  72%|███████▏  | 55135/76334 [00:21<00:08, 2600.75 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  73%|███████▎  | 55414/76334 [00:22<00:07, 2640.45 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  73%|███████▎  | 55690/76334 [00:22<00:08, 2478.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  73%|███████▎  | 55956/76334 [00:22<00:09, 2255.10 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  74%|███████▎  | 56199/76334 [00:22<00:09, 2076.99 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  74%|███████▍  | 56454/76334 [00:22<00:09, 2163.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  77%|███████▋  | 59045/76334 [00:22<00:06, 2678.20 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  78%|███████▊  | 59323/76334 [00:22<00:06, 2701.25 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  78%|███████▊  | 59595/76334 [00:23<00:06, 2694.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  78%|███████▊  | 59865/76334 [00:23<00:06, 2647.03 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  79%|███████▉  | 60148/76334 [00:23<00:06, 2666.17 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  79%|███████▉  | 60423/76334 [00:23<00:05, 2689.83 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  80%|███████▉  | 60699/76334 [00:23<00:05, 2677.80 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  80%|███████▉  | 60972/76334 [00:23<00:05, 2672.73 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  80%|████████  | 61253/76334 [00:23<00:05, 2668.45 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  81%|████████  | 61543/76334 [00:23<00:05, 2733.43 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  74%|███████▍  | 56710/76334 [00:22<00:08, 2233.31 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  75%|███████▍  | 56979/76334 [00:22<00:08, 2339.29 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  75%|███████▌  | 57260/76334 [00:22<00:07, 2456.21 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  75%|███████▌  | 57528/76334 [00:22<00:07, 2500.64 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  76%|███████▌  | 57797/76334 [00:23<00:07, 2554.11 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  76%|███████▌  | 58065/76334 [00:23<00:07, 2572.10 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  76%|███████▋  | 58340/76334 [00:23<00:06, 2587.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  77%|███████▋  | 58607/76334 [00:23<00:06, 2585.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  77%|███████▋  | 58883/76334 [00:23<00:06, 2577.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  77%|███████▋  | 59151/76334 [00:23<00:06, 2566.76 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  81%|████████  | 61835/76334 [00:23<00:05, 2765.10 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  81%|████████▏ | 62119/76334 [00:23<00:05, 2745.67 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  82%|████████▏ | 62397/76334 [00:24<00:05, 2710.65 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  82%|████████▏ | 62674/76334 [00:24<00:05, 2672.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  82%|████████▏ | 62963/76334 [00:24<00:04, 2710.54 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  83%|████████▎ | 63236/76334 [00:24<00:05, 2616.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  83%|████████▎ | 63508/76334 [00:24<00:05, 2462.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  84%|████████▎ | 63765/76334 [00:24<00:05, 2424.19 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  84%|████████▍ | 64035/76334 [00:24<00:04, 2483.87 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  78%|███████▊  | 59421/76334 [00:23<00:06, 2569.83 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  78%|███████▊  | 59695/76334 [00:23<00:06, 2589.10 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  79%|███████▊  | 59966/76334 [00:23<00:06, 2607.91 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  79%|███████▉  | 60245/76334 [00:24<00:06, 2623.05 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  79%|███████▉  | 60511/76334 [00:24<00:06, 2623.59 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  80%|███████▉  | 60776/76334 [00:24<00:05, 2629.89 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  80%|███████▉  | 61050/76334 [00:24<00:05, 2632.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  80%|████████  | 61320/76334 [00:24<00:05, 2604.55 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  81%|████████  | 61595/76334 [00:24<00:05, 2615.05 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  81%|████████  | 61862/76334 [00:24<00:05, 2571.36 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  77%|███████▋  | 58752/76334 [00:22<00:06, 2699.92 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  77%|███████▋  | 59047/76334 [00:22<00:06, 2727.77 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  78%|███████▊  | 59335/76334 [00:22<00:06, 2739.10 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  78%|███████▊  | 59620/76334 [00:23<00:06, 2758.63 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  78%|███████▊  | 59903/76334 [00:23<00:06, 2730.69 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  79%|███████▉  | 60188/76334 [00:23<00:05, 2735.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  79%|███████▉  | 60463/76334 [00:23<00:05, 2729.06 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  80%|███████▉  | 60744/76334 [00:23<00:05, 2690.91 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  80%|███████▉  | 61022/76334 [00:23<00:05, 2682.98 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  80%|████████  | 61304/76334 [00:23<00:05, 2701.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  81%|████████  | 61587/76334 [00:23<00:05, 2714.38 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  81%|████████  | 61876/76334 [00:23<00:05, 2731.52 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  81%|████████▏ | 62165/76334 [00:23<00:05, 2763.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  82%|████████▏ | 62454/76334 [00:24<00:05, 2756.89 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  82%|████████▏ | 62738/76334 [00:24<00:04, 2729.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  83%|████████▎ | 63022/76334 [00:24<00:04, 2681.73 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  83%|████████▎ | 63296/76334 [00:24<00:05, 2539.35 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  83%|████████▎ | 63561/76334 [00:24<00:05, 2505.04 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  84%|████████▎ | 63813/76334 [00:24<00:05, 2410.32 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  84%|████████▍ | 64063/76334 [00:24<00:05, 2422.50 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  84%|████████▍ | 64308/76334 [00:24<00:05, 2400.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  85%|████████▍ | 64554/76334 [00:24<00:05, 2146.79 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  85%|████████▍ | 64838/76334 [00:25<00:04, 2308.87 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  85%|████████▌ | 65106/76334 [00:25<00:04, 2395.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  86%|████████▌ | 65383/76334 [00:25<00:04, 2494.17 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  86%|████████▌ | 65640/76334 [00:25<00:04, 2496.24 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  86%|████████▋ | 65916/76334 [00:25<00:04, 2566.20 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  87%|████████▋ | 66183/76334 [00:25<00:03, 2581.44 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  84%|████████▍ | 64287/76334 [00:24<00:05, 2394.99 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  85%|████████▍ | 64531/76334 [00:24<00:05, 2345.10 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  85%|████████▍ | 64774/76334 [00:25<00:04, 2356.57 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  85%|████████▌ | 65019/76334 [00:25<00:04, 2355.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  86%|████████▌ | 65271/76334 [00:25<00:04, 2392.44 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  86%|████████▌ | 65557/76334 [00:25<00:04, 2523.38 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  86%|████████▋ | 65850/76334 [00:25<00:04, 2617.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  87%|████████▋ | 66117/76334 [00:25<00:03, 2615.67 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  87%|████████▋ | 66400/76334 [00:25<00:03, 2655.18 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  87%|████████▋ | 66695/76334 [00:25<00:03, 2724.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  81%|████████▏ | 62129/76334 [00:24<00:05, 2562.26 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  82%|████████▏ | 62410/76334 [00:24<00:05, 2601.17 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  82%|████████▏ | 62681/76334 [00:24<00:05, 2594.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  82%|████████▏ | 62941/76334 [00:25<00:05, 2573.42 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  83%|████████▎ | 63199/76334 [00:25<00:05, 2567.67 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  83%|████████▎ | 63464/76334 [00:25<00:05, 2532.06 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  83%|████████▎ | 63728/76334 [00:25<00:05, 2325.93 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  84%|████████▍ | 63979/76334 [00:25<00:05, 2311.40 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  84%|████████▍ | 64222/76334 [00:25<00:05, 2105.76 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  84%|████████▍ | 64446/76334 [00:25<00:05, 2124.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  85%|████████▍ | 64704/76334 [00:25<00:05, 2233.11 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  85%|████████▌ | 64974/76334 [00:25<00:04, 2344.30 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  85%|████████▌ | 65230/76334 [00:26<00:04, 2394.78 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  86%|████████▌ | 65518/76334 [00:26<00:04, 2518.38 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  86%|████████▌ | 65782/76334 [00:26<00:04, 2548.17 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  87%|████████▋ | 66065/76334 [00:26<00:03, 2586.41 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  87%|████████▋ | 66332/76334 [00:26<00:03, 2599.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  87%|████████▋ | 66605/76334 [00:26<00:03, 2587.14 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  88%|████████▊ | 66873/76334 [00:26<00:03, 2603.30 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  88%|████████▊ | 67135/76334 [00:26<00:03, 2577.42 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  88%|████████▊ | 67414/76334 [00:26<00:03, 2599.65 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  89%|████████▊ | 67704/76334 [00:26<00:03, 2643.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  89%|████████▉ | 67990/76334 [00:27<00:03, 2658.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  89%|████████▉ | 68260/76334 [00:27<00:03, 2641.56 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  90%|████████▉ | 68527/76334 [00:27<00:02, 2630.29 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  90%|█████████ | 68811/76334 [00:27<00:02, 2670.43 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  91%|█████████ | 69087/76334 [00:27<00:02, 2674.93 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  91%|█████████ | 69369/76334 [00:27<00:02, 2678.62 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  91%|█████████ | 69647/76334 [00:27<00:02, 2654.96 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  92%|█████████▏| 69920/76334 [00:27<00:02, 2625.31 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  92%|█████████▏| 70208/76334 [00:27<00:02, 2671.94 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  92%|█████████▏| 70485/76334 [00:28<00:02, 2640.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  93%|█████████▎| 70758/76334 [00:28<00:02, 2623.05 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  93%|█████████▎| 71021/76334 [00:28<00:02, 2599.59 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  93%|█████████▎| 71285/76334 [00:28<00:01, 2539.61 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  94%|█████████▎| 71543/76334 [00:28<00:01, 2403.26 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  94%|█████████▍| 71801/76334 [00:28<00:01, 2408.69 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  94%|█████████▍| 72056/76334 [00:28<00:01, 2380.05 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  95%|█████████▍| 72310/76334 [00:28<00:01, 2070.17 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  95%|█████████▌| 72559/76334 [00:28<00:01, 2143.90 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  95%|█████████▌| 72823/76334 [00:29<00:01, 2269.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  96%|█████████▌| 73107/76334 [00:29<00:01, 2422.32 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  96%|█████████▌| 73382/76334 [00:29<00:01, 2470.67 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  97%|█████████▋| 73665/76334 [00:29<00:01, 2566.61 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  97%|█████████▋| 73931/76334 [00:29<00:00, 2570.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  97%|█████████▋| 74203/76334 [00:29<00:00, 2581.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  98%|█████████▊| 74464/76334 [00:29<00:00, 2560.39 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  98%|█████████▊| 74727/76334 [00:29<00:00, 2549.17 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  98%|█████████▊| 74987/76334 [00:29<00:00, 2559.54 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  99%|█████████▊| 75255/76334 [00:29<00:00, 2535.48 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  99%|█████████▉| 75529/76334 [00:30<00:00, 2527.04 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  88%|████████▊ | 66992/76334 [00:25<00:03, 2772.03 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  88%|████████▊ | 67292/76334 [00:25<00:03, 2818.65 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  89%|████████▊ | 67585/76334 [00:26<00:03, 2837.05 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  89%|████████▉ | 67870/76334 [00:26<00:03, 2798.27 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  89%|████████▉ | 68173/76334 [00:26<00:02, 2791.93 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  90%|████████▉ | 68455/76334 [00:26<00:02, 2759.98 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  90%|█████████ | 68747/76334 [00:26<00:02, 2681.09 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  90%|█████████ | 69025/76334 [00:26<00:02, 2691.67 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  91%|█████████ | 69307/76334 [00:26<00:02, 2705.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  87%|████████▋ | 66463/76334 [00:25<00:03, 2621.60 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  87%|████████▋ | 66737/76334 [00:25<00:03, 2640.06 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  88%|████████▊ | 67018/76334 [00:25<00:03, 2678.27 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  88%|████████▊ | 67296/76334 [00:26<00:03, 2684.26 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  89%|████████▊ | 67577/76334 [00:26<00:03, 2707.19 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  89%|████████▉ | 67850/76334 [00:26<00:03, 2705.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  89%|████████▉ | 68158/76334 [00:26<00:02, 2772.70 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  90%|████████▉ | 68437/76334 [00:26<00:02, 2755.82 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  90%|█████████ | 68722/76334 [00:26<00:02, 2717.45 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  90%|█████████ | 68998/76334 [00:26<00:02, 2680.41 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  91%|█████████ | 69270/76334 [00:26<00:02, 2679.99 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  91%|█████████ | 69558/76334 [00:26<00:02, 2692.19 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  91%|█████████ | 69594/76334 [00:26<00:02, 2687.80 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  92%|█████████▏| 69872/76334 [00:26<00:02, 2707.25 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  92%|█████████▏| 70169/76334 [00:27<00:02, 2779.75 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  92%|█████████▏| 70452/76334 [00:27<00:02, 2712.32 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  93%|█████████▎| 70727/76334 [00:27<00:02, 2708.74 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  93%|█████████▎| 71006/76334 [00:27<00:01, 2701.77 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  93%|█████████▎| 71285/76334 [00:27<00:02, 2472.49 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  94%|█████████▎| 71551/76334 [00:27<00:02, 2338.00 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  94%|█████████▍| 71821/76334 [00:27<00:01, 2420.40 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  94%|█████████▍| 72070/76334 [00:27<00:01, 2430.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  95%|█████████▍| 72328/76334 [00:27<00:01, 2461.20 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  95%|█████████▌| 72580/76334 [00:28<00:01, 2465.66 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  91%|█████████▏| 69841/76334 [00:26<00:02, 2677.40 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  92%|█████████▏| 70124/76334 [00:27<00:02, 2716.43 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  92%|█████████▏| 70407/76334 [00:27<00:02, 2721.04 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  93%|█████████▎| 70689/76334 [00:27<00:02, 2716.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  93%|█████████▎| 70969/76334 [00:27<00:01, 2721.11 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  93%|█████████▎| 71249/76334 [00:27<00:01, 2653.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  94%|█████████▎| 71515/76334 [00:27<00:01, 2459.86 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  94%|█████████▍| 71766/76334 [00:27<00:01, 2442.48 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  94%|█████████▍| 72022/76334 [00:27<00:01, 2381.93 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  95%|█████████▍| 72270/76334 [00:27<00:01, 2350.81 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  95%|█████████▌| 72520/76334 [00:28<00:01, 2377.94 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  95%|█████████▌| 72844/76334 [00:28<00:01, 2469.66 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  96%|█████████▌| 73106/76334 [00:28<00:01, 2464.13 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  96%|█████████▌| 73363/76334 [00:28<00:01, 2475.69 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  96%|█████████▋| 73627/76334 [00:28<00:01, 2500.12 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  97%|█████████▋| 73894/76334 [00:28<00:00, 2547.35 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  97%|█████████▋| 74189/76334 [00:28<00:00, 2654.00 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  98%|█████████▊| 74472/76334 [00:28<00:00, 2689.01 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  98%|█████████▊| 74759/76334 [00:28<00:00, 2701.00 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  98%|█████████▊| 75039/76334 [00:28<00:00, 2712.91 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  99%|█████████▊| 75311/76334 [00:29<00:00, 2688.85 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  95%|█████████▌| 72760/76334 [00:28<00:01, 2302.26 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  96%|█████████▌| 73031/76334 [00:28<00:01, 2371.50 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  96%|█████████▌| 73292/76334 [00:28<00:01, 2425.27 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  96%|█████████▋| 73594/76334 [00:28<00:01, 2564.51 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  97%|█████████▋| 73867/76334 [00:28<00:00, 2573.06 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  97%|█████████▋| 74146/76334 [00:28<00:00, 2613.07 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  97%|█████████▋| 74416/76334 [00:28<00:00, 2624.28 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  98%|█████████▊| 74710/76334 [00:28<00:00, 2692.94 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  98%|█████████▊| 74987/76334 [00:28<00:00, 2657.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  99%|█████████▊| 75254/76334 [00:29<00:00, 2641.75 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  99%|█████████▉| 75583/76334 [00:29<00:00, 2625.15 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  99%|█████████▉| 75849/76334 [00:29<00:00, 2281.18 examples/s]\n",
      "Tokenizing Prompts (num_proc=8): 100%|█████████▉| 76096/76334 [00:29<00:00, 1898.77 examples/s]\n",
      "Tokenizing Prompts (num_proc=8): 100%|█████████▉| 76322/76334 [00:29<00:00, 1726.66 examples/s]\n",
      "Tokenizing Prompts (num_proc=8): 100%|██████████| 76334/76334 [00:29<00:00, 2562.08 examples/s]\n",
      "[2024-07-08 18:12:34,923] [INFO] [axolotl.load_tokenized_prepared_datasets:414] [PID:435] [RANK:0] merging datasets#033[39m\n",
      "Tokenizing Prompts (num_proc=8):  99%|█████████▉| 75520/76334 [00:29<00:00, 2587.23 examples/s]\n",
      "Tokenizing Prompts (num_proc=8):  99%|█████████▉| 75783/76334 [00:29<00:00, 2389.83 examples/s]\n",
      "Tokenizing Prompts (num_proc=8): 100%|█████████▉| 76026/76334 [00:29<00:00, 2202.47 examples/s]\n",
      "Tokenizing Prompts (num_proc=8): 100%|█████████▉| 76274/76334 [00:29<00:00, 1984.28 examples/s]\n",
      "Tokenizing Prompts (num_proc=8): 100%|██████████| 76334/76334 [00:29<00:00, 2562.63 examples/s]\n",
      "[2024-07-08 18:12:34,933] [INFO] [axolotl.load_tokenized_prepared_datasets:414] [PID:435] [RANK:0] merging datasets#033[39m\n",
      "[2024-07-08 18:12:36,253] [DEBUG] [axolotl.calculate_total_num_steps:299] [PID:436] [RANK:0] total_num_tokens: 2_011_520#033[39m\n",
      "[2024-07-08 18:12:36,324] [DEBUG] [axolotl.calculate_total_num_steps:312] [PID:436] [RANK:0] `total_supervised_tokens: 1_767_232`#033[39m\n",
      "Tokenizing Prompts (num_proc=8):  99%|█████████▉| 75795/76334 [00:30<00:00, 2445.78 examples/s]\n",
      "Tokenizing Prompts (num_proc=8): 100%|█████████▉| 76055/76334 [00:30<00:00, 2279.04 examples/s]\n",
      "Tokenizing Prompts (num_proc=8): 100%|█████████▉| 76286/76334 [00:30<00:00, 2012.58 examples/s]\n",
      "Tokenizing Prompts (num_proc=8): 100%|██████████| 76334/76334 [00:30<00:00, 2485.48 examples/s]\n",
      "[2024-07-08 18:12:36,239] [INFO] [axolotl.load_tokenized_prepared_datasets:414] [PID:435] [RANK:0] merging datasets#033[39m\n",
      "Dropping Long Sequences (num_proc=8):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Dropping Long Sequences (num_proc=8):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Dropping Long Sequences (num_proc=8):   1%|▏         | 1000/76334 [00:00<00:30, 2457.03 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Dropping Long Sequences (num_proc=8):   1%|▏         | 1000/76334 [00:00<00:30, 2431.27 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):   1%|▏         | 1000/76334 [00:00<00:32, 2319.98 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  12%|█▏        | 9000/76334 [00:00<00:05, 13139.59 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  21%|██        | 16000/76334 [00:00<00:02, 22577.30 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  26%|██▌       | 20000/76334 [00:01<00:03, 18208.83 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  12%|█▏        | 9000/76334 [00:00<00:04, 13535.47 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  22%|██▏       | 17000/76334 [00:01<00:03, 17118.61 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  33%|███▎      | 25000/76334 [00:01<00:02, 19259.59 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  12%|█▏        | 9000/76334 [00:00<00:04, 13583.92 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  22%|██▏       | 17000/76334 [00:01<00:03, 17347.34 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  31%|███▏      | 24000/76334 [00:01<00:02, 23244.48 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  35%|███▌      | 27000/76334 [00:01<00:02, 20522.74 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  42%|████▏     | 32000/76334 [00:01<00:02, 21870.67 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  46%|████▌     | 35000/76334 [00:01<00:01, 21046.41 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  33%|███▎      | 25000/76334 [00:01<00:03, 17051.35 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  41%|████      | 31000/76334 [00:01<00:01, 23333.25 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  46%|████▌     | 35000/76334 [00:02<00:02, 18215.52 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  54%|█████▎    | 41000/76334 [00:02<00:01, 18021.38 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  43%|████▎     | 33000/76334 [00:01<00:02, 20381.06 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  54%|█████▎    | 41000/76334 [00:02<00:01, 20985.94 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  64%|██████▍   | 49000/76334 [00:02<00:01, 21597.80 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  73%|███████▎  | 56000/76334 [00:02<00:00, 27005.01 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  52%|█████▏    | 40000/76334 [00:02<00:01, 21229.74 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  56%|█████▋    | 43000/76334 [00:02<00:01, 21321.88 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  63%|██████▎   | 48000/76334 [00:02<00:01, 21572.74 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  67%|██████▋   | 51000/76334 [00:02<00:01, 21389.72 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  73%|███████▎  | 56000/76334 [00:02<00:00, 21725.27 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  63%|██████▎   | 48000/76334 [00:02<00:01, 23683.81 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  68%|██████▊   | 52000/76334 [00:02<00:01, 20354.62 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  73%|███████▎  | 56000/76334 [00:02<00:00, 23067.40 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  79%|███████▊  | 60000/76334 [00:03<00:00, 19662.35 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  84%|████████▍ | 64000/76334 [00:03<00:00, 22572.27 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  79%|███████▊  | 60000/76334 [00:02<00:00, 23405.18 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  85%|████████▌ | 65000/76334 [00:03<00:00, 20313.76 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  94%|█████████▍| 72000/76334 [00:03<00:00, 26364.91 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  99%|█████████▉| 75793/76334 [00:03<00:00, 27634.45 examples/s]\n",
      "Dropping Long Sequences (num_proc=8): 100%|██████████| 76334/76334 [00:03<00:00, 21127.31 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  77%|███████▋  | 59000/76334 [00:02<00:00, 21541.61 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  84%|████████▍ | 64000/76334 [00:03<00:00, 21425.02 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  88%|████████▊ | 67000/76334 [00:03<00:00, 21859.49 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  94%|█████████▎| 71541/76334 [00:03<00:00, 25233.46 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  98%|█████████▊| 74708/76334 [00:03<00:00, 26289.12 examples/s]\n",
      "Dropping Long Sequences (num_proc=8): 100%|██████████| 76334/76334 [00:03<00:00, 20236.10 examples/s]\n",
      "[2024-07-08 18:12:40,165] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:436] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 502880#033[39m\n",
      "[2024-07-08 18:12:40,166] [DEBUG] [axolotl.calculate_total_num_steps:364] [PID:436] [RANK:0] data_loader_len: 7#033[39m\n",
      "Dropping Long Sequences (num_proc=8):  88%|████████▊ | 67000/76334 [00:03<00:00, 18666.26 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  93%|█████████▎| 71000/76334 [00:03<00:00, 21573.15 examples/s]\n",
      "Dropping Long Sequences (num_proc=8):  99%|█████████▊| 75250/76334 [00:03<00:00, 22551.48 examples/s]\n",
      "Dropping Long Sequences (num_proc=8): 100%|██████████| 76334/76334 [00:03<00:00, 19375.50 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   0%|          | 300/76334 [00:00<00:27, 2800.77 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   4%|▍         | 2906/76334 [00:00<00:04, 15765.55 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   1%|          | 542/76334 [00:00<00:14, 5265.55 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   4%|▍         | 3106/76334 [00:00<00:04, 16975.75 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   7%|▋         | 5469/76334 [00:00<00:03, 19965.01 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  10%|▉         | 7475/76334 [00:00<00:04, 16030.87 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  13%|█▎        | 9805/76334 [00:00<00:03, 18209.43 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  16%|█▌        | 12374/76334 [00:00<00:03, 20484.06 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  20%|█▉        | 14923/76334 [00:00<00:02, 21990.66 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   0%|          | 149/76334 [00:00<00:51, 1473.97 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   3%|▎         | 2564/76334 [00:00<00:05, 14659.26 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   7%|▋         | 4979/76334 [00:00<00:03, 18939.24 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   9%|▉         | 7113/76334 [00:00<00:03, 19083.02 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  12%|█▏        | 9081/76334 [00:00<00:04, 16606.94 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  15%|█▌        | 11626/76334 [00:00<00:03, 19264.80 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  19%|█▊        | 14175/76334 [00:00<00:02, 21120.22 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   7%|▋         | 5192/76334 [00:00<00:03, 18903.12 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):   9%|▉         | 7200/76334 [00:00<00:03, 19319.43 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  12%|█▏        | 9277/76334 [00:00<00:04, 15782.88 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  15%|█▌        | 11672/76334 [00:00<00:03, 18122.94 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  18%|█▊        | 14082/76334 [00:00<00:03, 19845.91 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  21%|██        | 16162/76334 [00:00<00:03, 17383.42 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  24%|██▍       | 18402/76334 [00:01<00:03, 17853.01 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  27%|██▋       | 20786/76334 [00:01<00:02, 19431.99 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  30%|███       | 23033/76334 [00:01<00:02, 20248.60 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  23%|██▎       | 17262/76334 [00:00<00:03, 18400.11 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  26%|██▌       | 19804/76334 [00:01<00:02, 20201.58 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  29%|██▉       | 22326/76334 [00:01<00:02, 21553.16 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  32%|███▏      | 24601/76334 [00:01<00:02, 18720.30 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  36%|███▌      | 27204/76334 [00:01<00:02, 20576.24 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  39%|███▉      | 29814/76334 [00:01<00:02, 22000.71 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  42%|████▏     | 32135/76334 [00:01<00:02, 18571.76 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  45%|████▌     | 34614/76334 [00:01<00:02, 20091.22 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  49%|████▊     | 37188/76334 [00:01<00:01, 21529.10 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  21%|██▏       | 16408/76334 [00:00<00:03, 18318.66 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  25%|██▍       | 18832/76334 [00:01<00:02, 19898.27 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  28%|██▊       | 21192/76334 [00:01<00:02, 20913.81 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  31%|███       | 23372/76334 [00:01<00:02, 19663.11 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  33%|███▎      | 25536/76334 [00:01<00:02, 19255.74 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  37%|███▋      | 28106/76334 [00:01<00:02, 20981.29 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  40%|████      | 30607/76334 [00:01<00:02, 22054.66 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  43%|████▎     | 32945/76334 [00:01<00:02, 19024.38 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  46%|████▋     | 35424/76334 [00:01<00:01, 20486.77 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  33%|███▎      | 25145/76334 [00:01<00:02, 17918.50 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  36%|███▌      | 27639/76334 [00:01<00:02, 19727.01 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  39%|███▉      | 30103/76334 [00:01<00:02, 21047.40 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  43%|████▎     | 32462/76334 [00:01<00:02, 18421.71 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  46%|████▌     | 34803/76334 [00:01<00:02, 19641.53 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  49%|████▊     | 37163/76334 [00:01<00:01, 20672.99 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  52%|█████▏    | 39389/76334 [00:02<00:01, 19672.16 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  54%|█████▍    | 41433/76334 [00:02<00:01, 18224.28 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  57%|█████▋    | 43854/76334 [00:02<00:01, 19752.74 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  61%|██████    | 46248/76334 [00:02<00:01, 20687.46 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  63%|██████▎   | 48406/76334 [00:02<00:01, 18268.79 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  50%|████▉     | 37989/76334 [00:01<00:01, 21845.84 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  53%|█████▎    | 40339/76334 [00:02<00:01, 19099.50 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  56%|█████▌    | 42816/76334 [00:02<00:01, 20502.41 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  59%|█████▉    | 45401/76334 [00:02<00:01, 21903.69 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  63%|██████▎   | 47709/76334 [00:02<00:01, 20429.02 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  65%|██████▌   | 49869/76334 [00:02<00:01, 20575.97 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  69%|██████▊   | 52396/76334 [00:02<00:01, 21788.97 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  72%|███████▏  | 55033/76334 [00:02<00:00, 21473.69 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  75%|███████▌  | 57331/76334 [00:02<00:00, 19084.90 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  78%|███████▊  | 59845/76334 [00:03<00:00, 20582.93 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  82%|████████▏ | 62365/76334 [00:03<00:00, 21793.87 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  52%|█████▏    | 39555/76334 [00:01<00:01, 21457.53 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  55%|█████▍    | 41821/76334 [00:02<00:01, 19681.64 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  58%|█████▊    | 44420/76334 [00:02<00:01, 21303.31 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  61%|██████▏   | 46769/76334 [00:02<00:01, 21863.18 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  64%|██████▍   | 49047/76334 [00:02<00:01, 19134.63 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  68%|██████▊   | 51636/76334 [00:02<00:01, 20829.12 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  71%|███████   | 54143/76334 [00:02<00:01, 21961.81 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  74%|███████▍  | 56519/76334 [00:02<00:01, 18920.95 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  77%|███████▋  | 59050/76334 [00:02<00:00, 20477.56 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  81%|████████  | 61589/76334 [00:03<00:00, 21743.77 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  84%|████████▎ | 63890/76334 [00:03<00:00, 19246.00 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  87%|████████▋ | 66301/76334 [00:03<00:00, 20373.09 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  66%|██████▋   | 50694/76334 [00:02<00:01, 19432.92 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  70%|██████▉   | 53111/76334 [00:02<00:01, 20674.68 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  72%|███████▏  | 55317/76334 [00:02<00:01, 20948.12 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  75%|███████▌  | 57569/76334 [00:03<00:01, 18349.95 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  79%|███████▊  | 59995/76334 [00:03<00:00, 19862.27 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  82%|████████▏ | 62244/76334 [00:03<00:00, 20525.62 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  85%|████████▍ | 64529/76334 [00:03<00:00, 18010.58 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  88%|████████▊ | 67137/76334 [00:03<00:00, 19332.39 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  91%|█████████ | 69551/76334 [00:03<00:00, 20528.53 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  85%|████████▍ | 64674/76334 [00:03<00:00, 19012.63 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  88%|████████▊ | 67281/76334 [00:03<00:00, 20222.21 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  91%|█████████▏| 69843/76334 [00:03<00:00, 21602.62 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  95%|█████████▍| 72173/76334 [00:03<00:00, 18784.62 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  98%|█████████▊| 74548/76334 [00:03<00:00, 20003.94 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8): 100%|██████████| 76334/76334 [00:03<00:00, 19309.15 examples/s]\n",
      "[2024-07-08 18:12:44,421] [INFO] [axolotl.load_tokenized_prepared_datasets:427] [PID:435] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/515d28cedb8f11b4423ad59630e8364d#033[39m\n",
      "Saving the dataset (0/1 shards):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Saving the dataset (0/1 shards):  34%|███▍      | 26000/76334 [00:00<00:00, 236785.73 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  90%|█████████ | 68838/76334 [00:03<00:00, 21665.92 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  93%|█████████▎| 71315/76334 [00:03<00:00, 22479.96 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  96%|█████████▋| 73650/76334 [00:03<00:00, 18613.78 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8): 100%|█████████▉| 76002/76334 [00:03<00:00, 19807.76 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8): 100%|██████████| 76334/76334 [00:03<00:00, 19453.59 examples/s]\n",
      "[2024-07-08 18:12:44,231] [INFO] [axolotl.load_tokenized_prepared_datasets:427] [PID:435] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/515d28cedb8f11b4423ad59630e8364d#033[39m\n",
      "Saving the dataset (0/1 shards):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Saving the dataset (0/1 shards):  34%|███▍      | 26000/76334 [00:00<00:00, 236053.81 examples/s]\n",
      "Saving the dataset (0/1 shards):  68%|██████▊   | 52000/76334 [00:00<00:00, 242493.11 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 76334/76334 [00:00<00:00, 242493.11 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 76334/76334 [00:00<00:00, 244623.22 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  94%|█████████▍| 71690/76334 [00:03<00:00, 19854.21 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  97%|█████████▋| 73769/76334 [00:03<00:00, 18468.16 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8):  99%|█████████▉| 75824/76334 [00:03<00:00, 18737.12 examples/s]\n",
      "Add position_id column (Sample Packing) (num_proc=8): 100%|██████████| 76334/76334 [00:04<00:00, 18477.31 examples/s]\n",
      "[2024-07-08 18:12:44,761] [INFO] [axolotl.load_tokenized_prepared_datasets:427] [PID:435] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/515d28cedb8f11b4423ad59630e8364d#033[39m\n",
      "Saving the dataset (0/1 shards):   0%|          | 0/76334 [00:00<?, ? examples/s]\n",
      "Saving the dataset (0/1 shards):  30%|███       | 23000/76334 [00:00<00:00, 213291.54 examples/s]\n",
      "Saving the dataset (0/1 shards):  59%|█████▉    | 45000/76334 [00:00<00:00, 213667.80 examples/s]\n",
      "Saving the dataset (0/1 shards):  89%|████████▉ | 68000/76334 [00:00<00:00, 216367.91 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 76334/76334 [00:00<00:00, 216367.91 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 76334/76334 [00:00<00:00, 215822.40 examples/s]\n",
      "Saving the dataset (0/1 shards):  68%|██████▊   | 52000/76334 [00:00<00:00, 242983.71 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 76334/76334 [00:00<00:00, 242983.71 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 76334/76334 [00:00<00:00, 245310.14 examples/s]\n",
      "[2024-07-08 18:12:48,483] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:435] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 502880#033[39m\n",
      "[2024-07-08 18:12:48,688] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:435] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 502880#033[39m\n",
      "[2024-07-08 18:12:49,468] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:435] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 502880#033[39m\n",
      "[2024-07-08 18:12:49,543] [INFO] [axolotl.calc_sample_packing_eff_est:370] [PID:436] [RANK:0] sample_packing_eff_est across ranks: [0.9821875095367432, 0.9821875095367432, 0.9821875095367432, 0.9821875095367432]#033[39m\n",
      "[2024-07-08 18:12:49,544] [DEBUG] [axolotl.calculate_total_num_steps:382] [PID:436] [RANK:0] sample_packing_eff_est: None#033[39m\n",
      "[2024-07-08 18:12:49,544] [DEBUG] [axolotl.calculate_total_num_steps:390] [PID:436] [RANK:0] total_num_steps: 7#033[39m\n",
      "[2024-07-08 18:12:49,614] [DEBUG] [axolotl.calculate_total_num_steps:299] [PID:436] [RANK:0] total_num_tokens: 18_214_252#033[39m\n",
      "[2024-07-08 18:12:50,242] [DEBUG] [axolotl.calculate_total_num_steps:312] [PID:436] [RANK:0] `total_supervised_tokens: 16_015_852`#033[39m\n",
      "[2024-07-08 18:12:50,285] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:436] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 4553563#033[39m\n",
      "[2024-07-08 18:12:50,285] [DEBUG] [axolotl.calculate_total_num_steps:364] [PID:436] [RANK:0] data_loader_len: 68#033[39m\n",
      "[2024-07-08 18:12:50,320] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:435] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 4553563#033[39m\n",
      "[2024-07-08 18:12:50,459] [DEBUG] [axolotl.load_tokenizer:280] [PID:435] [RANK:0] EOS: 2 / </s>#033[39m\n",
      "[2024-07-08 18:12:50,459] [DEBUG] [axolotl.load_tokenizer:281] [PID:435] [RANK:0] BOS: 1 / <s>#033[39m\n",
      "[2024-07-08 18:12:50,459] [DEBUG] [axolotl.load_tokenizer:282] [PID:435] [RANK:0] PAD: 2 / </s>#033[39m\n",
      "[2024-07-08 18:12:50,459] [DEBUG] [axolotl.load_tokenizer:283] [PID:435] [RANK:0] UNK: 0 / <unk>#033[39m\n",
      "[2024-07-08 18:12:50,459] [INFO] [axolotl.load_tokenizer:294] [PID:435] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.#033[39m\n",
      "[2024-07-08 18:12:50,472] [INFO] [axolotl.load_model:413] [PID:435] [RANK:0] patching mistral with flash attention#033[39m\n",
      "[2024-07-08 18:12:50,307] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:435] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 4553563#033[39m\n",
      "[2024-07-08 18:12:50,459] [DEBUG] [axolotl.load_tokenizer:280] [PID:435] [RANK:0] EOS: 2 / </s>#033[39m\n",
      "[2024-07-08 18:12:50,459] [DEBUG] [axolotl.load_tokenizer:281] [PID:435] [RANK:0] BOS: 1 / <s>#033[39m\n",
      "[2024-07-08 18:12:50,459] [DEBUG] [axolotl.load_tokenizer:282] [PID:435] [RANK:0] PAD: 2 / </s>#033[39m\n",
      "[2024-07-08 18:12:50,459] [DEBUG] [axolotl.load_tokenizer:283] [PID:435] [RANK:0] UNK: 0 / <unk>#033[39m\n",
      "[2024-07-08 18:12:50,459] [INFO] [axolotl.load_tokenizer:294] [PID:435] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.#033[39m\n",
      "[2024-07-08 18:12:50,471] [INFO] [axolotl.load_model:413] [PID:435] [RANK:0] patching mistral with flash attention#033[39m\n",
      "[2024-07-08 18:12:50,398] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:435] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 4553563#033[39m\n",
      "[2024-07-08 18:12:50,464] [DEBUG] [axolotl.load_tokenizer:280] [PID:435] [RANK:0] EOS: 2 / </s>#033[39m\n",
      "[2024-07-08 18:12:50,464] [DEBUG] [axolotl.load_tokenizer:281] [PID:435] [RANK:0] BOS: 1 / <s>#033[39m\n",
      "[2024-07-08 18:12:50,464] [DEBUG] [axolotl.load_tokenizer:282] [PID:435] [RANK:0] PAD: 2 / </s>#033[39m\n",
      "[2024-07-08 18:12:50,464] [DEBUG] [axolotl.load_tokenizer:283] [PID:435] [RANK:0] UNK: 0 / <unk>#033[39m\n",
      "[2024-07-08 18:12:50,464] [INFO] [axolotl.load_tokenizer:294] [PID:435] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.#033[39m\n",
      "[2024-07-08 18:12:50,476] [INFO] [axolotl.load_model:413] [PID:435] [RANK:0] patching mistral with flash attention#033[39m\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "[2024-07-08 18:12:50,399] [INFO] [axolotl.calc_sample_packing_eff_est:370] [PID:436] [RANK:0] sample_packing_eff_est across ranks: [0.9881864190101624, 0.9890655875205994, 0.9890655875205994, 0.9890655875205994]#033[39m\n",
      "[2024-07-08 18:12:50,407] [DEBUG] [axolotl.calculate_total_num_steps:382] [PID:436] [RANK:0] sample_packing_eff_est: 0.99#033[39m\n",
      "[2024-07-08 18:12:50,407] [DEBUG] [axolotl.calculate_total_num_steps:390] [PID:436] [RANK:0] total_num_steps: 68#033[39m\n",
      "[2024-07-08 18:12:50,407] [DEBUG] [axolotl.train.train:56] [PID:436] [RANK:0] loading tokenizer... /opt/ml/input/data/model#033[39m\n",
      "[2024-07-08 18:12:50,458] [DEBUG] [axolotl.load_tokenizer:280] [PID:436] [RANK:0] EOS: 2 / </s>#033[39m\n",
      "[2024-07-08 18:12:50,458] [DEBUG] [axolotl.load_tokenizer:281] [PID:436] [RANK:0] BOS: 1 / <s>#033[39m\n",
      "[2024-07-08 18:12:50,458] [DEBUG] [axolotl.load_tokenizer:282] [PID:436] [RANK:0] PAD: 2 / </s>#033[39m\n",
      "[2024-07-08 18:12:50,458] [DEBUG] [axolotl.load_tokenizer:283] [PID:436] [RANK:0] UNK: 0 / <unk>#033[39m\n",
      "[2024-07-08 18:12:50,458] [INFO] [axolotl.load_tokenizer:294] [PID:436] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.#033[39m\n",
      "[2024-07-08 18:12:50,458] [DEBUG] [axolotl.train.train:85] [PID:436] [RANK:0] loading model and peft_config...#033[39m\n",
      "[2024-07-08 18:12:50,470] [INFO] [axolotl.load_model:413] [PID:436] [RANK:0] patching mistral with flash attention#033[39m\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"model\": s3_model_path, \"train\": s3_data})"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
